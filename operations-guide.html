<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">








<head>
<title>SDK Operations Guide</title>
<link rel="stylesheet" type="text/css" media="all" href="./style/layout.css" />
<link rel="shortcut icon" type="image/png" href="https://mesosphere.com/favicon.ico"/>
<!-- The Dropdown library is written by Stephen Morley, licensed CC0 1.0 Universal (Public Domain Dedication)-->
<link rel="stylesheet" type="text/css" media="all" href="./style/Dropdown.css" />
<script src="./style/Dropdown.js"></script>
<style type="text/css">
/* set the background color of menu items */
.dropdown, .dropdown ul { background: #555555; clear: both; }
/* set the background color of active items */
.dropdown li:hover > a, .dropdown li:hover > span, .dropdown li.dropdownOpen > a, .dropdown li.dropdownOpen > span { background: #af87e0; }
/* pad items, set their text color, and fade their background color */
.dropdown a, .dropdown span { padding: 0.25em 0.5em; color: white; transition: background 0.2s; }
/* show '+' on expandable items */
.dropdown span:after { content: " +"; }

/* toc style: remove extra margin between elements */
.section-nav ul { margin: 0; }
</style>
</head>

<body>
<div id="wrapper">

<a href=".">
<img style="float: left; margin-bottom: 2em" src="https://mesosphere.com/wp-content/themes/mesosphere/library/images/assets/dcos-sdk-logo.png" width="250" alt="DC/OS Software Development Kit" />
</a>
<img style="float: right" src="https://img.shields.io/badge/Status-Alpha-BF97F0.svg?style=flat-square" alt="Status: Alpha" />

<ul class="dropdown" style="clear: both">
  <li>
    <a href=".">Home</a>
  </li>
  <li>
    <span>Documentation</span>
    <ul>
      
      
      
      
      <li><a href="./operations-guide.html">SDK Operations Guide</a></li>
      
      
      
      
      
      <li><a href="./developer-guide.html">SDK Developer Guide</a></li>
      
      
      
      <li><a href="./yaml-reference.html">YAML Reference</a></li>
      
      
      
      <li><a href="./faq.html">Frequently Asked Questions</a></li>
      
      
      
      <li><a href="./glossary.html">Glossary</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      <li><a href="./reference/api">Javadoc Reference</a></li>
      <li><a href="./reference/swagger-api">REST APIs</a></li>
    </ul>
  </li>
  <li>
    <span>Tutorials</span>
    <ul>
      
      
      
      <li><a href="./tutorials/secrets-tutorial.html">Secrets Tutorial</a></li>
      
      <li><a href="./tutorials/kafka-tutorial.html">Kafka Tutorial</a></li>
      
    </ul>
  </li>
  <li>
    <span>Services</span>
    <ul>
      
      
      
      
      <li>
        
        <span>Cassandra</span>
        
        <ul>
          
          
          
          <li><a href="./services/cassandra/install.html">Installing and Customizing</a></li>
          
          
          
          <li><a href="./services/cassandra/service-settings.html">Service Settings</a></li>
          
          
          
          <li><a href="./services/cassandra/cassandra-settings.html">Cassandra Settings</a></li>
          
          
          
          <li><a href="./services/cassandra/node-settings.html">Node Settings</a></li>
          
          
          
          <li><a href="./services/cassandra/uninstall.html">Uninstall</a></li>
          
          
          
          <li><a href="./services/cassandra/quick-start.html">Quick Start</a></li>
          
          
          
          <li><a href="./services/cassandra/connecting-clients.html">Connecting Clients</a></li>
          
          
          
          <li><a href="./services/cassandra/managing.html">Managing</a></li>
          
          
          
          <li><a href="./services/cassandra/api-reference.html">API Reference</a></li>
          
          
          
          <li><a href="./services/cassandra/disaster-recovery.html">Disaster Recovery</a></li>
          
          
          
          <li><a href="./services/cassandra/troubleshooting.html">Troubleshooting</a></li>
          
          
          
          <li><a href="./services/cassandra/limitations.html">Limitations</a></li>
          
          
          
          <li><a href="./services/cassandra/supported-versions.html">Supported Versions</a></li>
          
          
          
          <li><a href="./services/cassandra/release-notes.html">Release Notes</a></li>
          
          
          
          <li><a href="./services/cassandra/upgrade.html">Upgrade</a></li>
          
          
        </ul>
      </li>
      
      <li>
        
        <span>Elastic</span>
        
        <ul>
          
          
          
          <li><a href="./services/elastic/install.html">Install and Customize</a></li>
          
          
          
          <li><a href="./services/elastic/elastic-x-pack.html">X-Pack</a></li>
          
          
          
          <li><a href="./services/elastic/custom-elasticsearch-yaml.html">Custom Elasticsearch YAML</a></li>
          
          
          
          <li><a href="./services/elastic/uninstall.html">Uninstall</a></li>
          
          
          
          <li><a href="./services/elastic/quick-start.html">Quick Start</a></li>
          
          
          
          <li><a href="./services/elastic/connecting-clients.html">Connecting Clients</a></li>
          
          
          
          <li><a href="./services/elastic/managing.html">Managing</a></li>
          
          
          
          <li><a href="./services/elastic/api-reference.html">API Reference</a></li>
          
          
          
          <li><a href="./services/elastic/disaster-recovery.html">Disaster Recovery</a></li>
          
          
          
          <li><a href="./services/elastic/troubleshooting.html">Troubleshooting</a></li>
          
          
          
          <li><a href="./services/elastic/limitations.html">Limitations</a></li>
          
          
          
          <li><a href="./services/elastic/supported-versions.html">Supported Versions</a></li>
          
          
          
          <li><a href="./services/elastic/release-notes.html">Release Notes</a></li>
          
          
          
          <li><a href="./services/elastic/upgrade.html">Upgrade</a></li>
          
          
        </ul>
      </li>
      
      <li>
        
        <span>HDFS</span>
        
        <ul>
          
          
          
          <li><a href="./services/hdfs/install.html">Install and Customize</a></li>
          
          
          
          <li><a href="./services/hdfs/kerberos.html">Kerberos</a></li>
          
          
          
          <li><a href="./services/hdfs/uninstall.html">Uninstall</a></li>
          
          
          
          <li><a href="./services/hdfs/quick-start.html">Quickstart</a></li>
          
          
          
          <li><a href="./services/hdfs/connecting-clients.html">Connecting Clients</a></li>
          
          
          
          <li><a href="./services/hdfs/managing.html">Managing</a></li>
          
          
          
          <li><a href="./services/hdfs/api-reference.html">API Reference</a></li>
          
          
          
          <li><a href="./services/hdfs/troubleshooting.html">Troubleshooting</a></li>
          
          
          
          <li><a href="./services/hdfs/limitations.html">Limitations</a></li>
          
          
          
          <li><a href="./services/hdfs/supported-versions.html">Supported Versions</a></li>
          
          
          
          <li><a href="./services/hdfs/release-notes.html">Release Notes</a></li>
          
          
          
          <li><a href="./services/hdfs/upgrade.html">Upgrade</a></li>
          
          
        </ul>
      </li>
      
      <li>
        
        <span>Kafka</span>
        
        <ul>
          
          
          
          <li><a href="./services/kafka/install.html">Install and Customize</a></li>
          
          
          
          <li><a href="./services/kafka/kerberos.html">Kerberos</a></li>
          
          
          
          <li><a href="./services/kafka/ssl-auth.html">SSL Auth</a></li>
          
          
          
          <li><a href="./services/kafka/uninstall.html">Uninstall</a></li>
          
          
          
          <li><a href="./services/kafka/quick-start.html">Quick Start</a></li>
          
          
          
          <li><a href="./services/kafka/connecting-clients.html">Connecting Clients</a></li>
          
          
          
          <li><a href="./services/kafka/managing.html">Managing</a></li>
          
          
          
          <li><a href="./services/kafka/api-reference.html">API Reference</a></li>
          
          
          
          <li><a href="./services/kafka/troubleshooting.html">Troubleshooting</a></li>
          
          
          
          <li><a href="./services/kafka/limitations.html">Limitations</a></li>
          
          
          
          <li><a href="./services/kafka/supported-versions.html">Supported Versions</a></li>
          
          
          
          <li><a href="./services/kafka/release-notes.html">Release Notes</a></li>
          
          
          
          <li><a href="./services/kafka/upgrade.html">Upgrade</a></li>
          
          
        </ul>
      </li>
      
    </ul>
  </li>
  <li><a href="https://github.com/mesosphere/dcos-commons/blob/master/CONTRIBUTING.md">Contributing</a></li>
  <li><a href="http://chat.dcos.io" target="_blank">Slack</a></li>
</ul>
<h1>SDK Operations Guide</h1>
<div id="content">

<ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#overview">Overview</a>
<ul>
<li class="toc-entry toc-h2"><a href="#components">Components</a></li>
<li class="toc-entry toc-h2"><a href="#deployment">Deployment</a>
<ul>
<li class="toc-entry toc-h3"><a href="#initial-install">Initial Install</a>
<ul>
<li class="toc-entry toc-h4"><a href="#steps-handled-by-the-dcos-cluster">Steps handled by the DC/OS cluster</a></li>
<li class="toc-entry toc-h4"><a href="#steps-handled-by-the-scheduler">Steps handled by the Scheduler</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#reconfiguration">Reconfiguration</a>
<ul>
<li class="toc-entry toc-h4"><a href="#steps-handled-by-the-dcos-cluster-1">Steps handled by the DC/OS cluster</a></li>
<li class="toc-entry toc-h4"><a href="#steps-handled-by-the-scheduler-1">Steps handled by the Scheduler</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#uninstall">Uninstall</a>
<ul>
<li class="toc-entry toc-h4"><a href="#steps-handled-by-the-cluster">Steps handled by the cluster</a></li>
<li class="toc-entry toc-h4"><a href="#steps-handled-by-the-scheduler-2">Steps handled by the Scheduler</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#offer-cycle">Offer Cycle</a></li>
<li class="toc-entry toc-h2"><a href="#pods">Pods</a></li>
<li class="toc-entry toc-h2"><a href="#plans">Plans</a>
<ul>
<li class="toc-entry toc-h3"><a href="#custom-update-plan">Custom Update Plan</a></li>
<li class="toc-entry toc-h3"><a href="#recovery-plan">Recovery Plan</a>
<ul>
<li class="toc-entry toc-h4"><a href="#permanent-and-temporary-recovery">Permanent and temporary recovery</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#persistent-volumes">Persistent Volumes</a></li>
<li class="toc-entry toc-h2"><a href="#virtual-networks">Virtual networks</a></li>
<li class="toc-entry toc-h2"><a href="#secrets">Secrets</a>
<ul>
<li class="toc-entry toc-h3"><a href="#authorization-for-secrets">Authorization for Secrets</a></li>
<li class="toc-entry toc-h3"><a href="#binary-secrets">Binary Secrets</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#placement-constraints">Placement Constraints</a>
<ul>
<li class="toc-entry toc-h3"><a href="#regions-and-zones">Regions and Zones</a>
<ul>
<li class="toc-entry toc-h4"><a href="#rack-aware-services">Rack aware services</a>
<ul>
<li class="toc-entry toc-h5"><a href="#placement-constraint-references-zones">Placement Constraint References Zones</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#updating-placement-constraints">Updating placement constraints</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#integration-with-dcos-access-controls">Integration with DC/OS access controls</a>
<ul>
<li class="toc-entry toc-h3"><a href="#interacting-with-your-foldered-service">Interacting with your foldered service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#common-operations">Common Operations</a>
<ul>
<li class="toc-entry toc-h2"><a href="#initial-service-configuration">Initial service configuration</a></li>
<li class="toc-entry toc-h2"><a href="#updating-service-configuration">Updating service configuration</a>
<ul>
<li class="toc-entry toc-h3"><a href="#enterprise-dcos-110">Enterprise DC/OS 1.10</a>
<ul>
<li class="toc-entry toc-h4"><a href="#prerequisites">Prerequisites</a>
<ul>
<li class="toc-entry toc-h5"><a href="#updating-package-version">Updating package version</a>
<ul>
<li class="toc-entry toc-h6"><a href="#viewing-available-versions">Viewing available versions</a></li>
<li class="toc-entry toc-h6"><a href="#upgrading-or-downgrading-a-service">Upgrading or downgrading a service</a></li>
</ul>
</li>
<li class="toc-entry toc-h5"><a href="#updating-configuration">Updating configuration</a>
<ul>
<li class="toc-entry toc-h6"><a href="#preparing-configuration">Preparing configuration</a></li>
<li class="toc-entry toc-h6"><a href="#starting-the-update">Starting the update</a></li>
</ul>
</li>
<li class="toc-entry toc-h5"><a href="#advanced-update-actions">Advanced update actions</a>
<ul>
<li class="toc-entry toc-h6"><a href="#monitoring-the-update">Monitoring the update</a></li>
<li class="toc-entry toc-h6"><a href="#pause">Pause</a></li>
<li class="toc-entry toc-h6"><a href="#resume">Resume</a></li>
<li class="toc-entry toc-h6"><a href="#force-complete">Force Complete</a></li>
<li class="toc-entry toc-h6"><a href="#force-restart">Force Restart</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h4"><a href="#open-source-dcos-dcos-19-and-earlier">Open Source DC/OS, DC/OS 1.9, and Earlier</a>
<ul>
<li class="toc-entry toc-h5"><a href="#finding-the-correct-environment-variable">Finding the correct environment variable</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#uninstall-1">Uninstall</a>
<ul>
<li class="toc-entry toc-h4"><a href="#dcos-110-and-newer">DC/OS 1.10 and newer</a></li>
<li class="toc-entry toc-h4"><a href="#older-versions">Older versions</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#pod-operations">Pod operations</a>
<ul>
<li class="toc-entry toc-h4"><a href="#add-or-remove-a-pod">Add or Remove a pod</a></li>
<li class="toc-entry toc-h4"><a href="#restart-a-pod">Restart a pod</a></li>
<li class="toc-entry toc-h4"><a href="#replace-a-pod">Replace a pod</a></li>
<li class="toc-entry toc-h4"><a href="#pause-a-pod">Pause a pod</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#plan-operations">Plan Operations</a>
<ul>
<li class="toc-entry toc-h4"><a href="#list">List</a></li>
<li class="toc-entry toc-h4"><a href="#status">Status</a></li>
<li class="toc-entry toc-h4"><a href="#start">Start</a></li>
<li class="toc-entry toc-h4"><a href="#stop">Stop</a></li>
<li class="toc-entry toc-h4"><a href="#pause-1">Pause</a></li>
<li class="toc-entry toc-h4"><a href="#resume-1">Resume</a></li>
<li class="toc-entry toc-h4"><a href="#force-restart-1">Force-Restart</a></li>
<li class="toc-entry toc-h4"><a href="#force-complete-1">Force-Complete</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#diagnostic-tools">Diagnostic Tools</a>
<ul>
<li class="toc-entry toc-h2"><a href="#logging">Logging</a>
<ul>
<li class="toc-entry toc-h3"><a href="#scheduler-logs">Scheduler logs</a></li>
<li class="toc-entry toc-h3"><a href="#task-logs">Task logs</a></li>
<li class="toc-entry toc-h3"><a href="#mesos-agent-logs">Mesos Agent logs</a></li>
<li class="toc-entry toc-h3"><a href="#logs-via-the-cli">Logs via the CLI</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#metrics">Metrics</a>
<ul>
<li class="toc-entry toc-h3"><a href="#dcos--111">DC/OS >= 1.11</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#running-commands-within-containers">Running commands within containers</a>
<ul>
<li class="toc-entry toc-h3"><a href="#dcos--19">DC/OS >= 1.9</a>
<ul>
<li class="toc-entry toc-h4"><a href="#prerequisites-1">Prerequisites</a></li>
<li class="toc-entry toc-h4"><a href="#using-dcos-task-exec">Using dcos task exec</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#dcos--18">DC/OS <= 1.8</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#querying-the-scheduler">Querying the Scheduler</a></li>
<li class="toc-entry toc-h2"><a href="#zookeeperexhibitor">ZooKeeper/Exhibitor</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#troubleshooting">Troubleshooting</a>
<ul>
<li class="toc-entry toc-h2"><a href="#tasks-not-deploying--resource-starvation">Tasks not deploying / Resource starvation</a></li>
<li class="toc-entry toc-h2"><a href="#accidentially-deleted-marathon-task-but-not-service">Accidentially deleted Marathon task but not service</a>
<ul>
<li class="toc-entry toc-h3"><a href="#uninstall-the-rest-of-the-service">Uninstall the rest of the service</a></li>
<li class="toc-entry toc-h3"><a href="#recover-the-scheduler">Recover the Scheduler</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#framework-has-been-removed">‘Framework has been removed’</a></li>
<li class="toc-entry toc-h2"><a href="#stuck-deployments">Stuck deployments</a>
<ul>
<li class="toc-entry toc-h3"><a href="#deleting-a-task-in-zookeeper-to-forcibly-wipe-that-task">Deleting a task in ZooKeeper to forcibly wipe that task</a></li>
<li class="toc-entry toc-h3"><a href="#oomed-task">OOMed task</a></li>
</ul>
</li>
</ul>
</li>
</ul><!-- this file just includes the per-section ops-guide files in one single page -->

<h1 id="overview">
<a id="overview" class="anchor" href="#overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overview</h1>
<h2 id="components">
<a id="components" class="anchor" href="#components" aria-hidden="true"><span class="octicon octicon-link"></span></a>Components</h2>

<p>The following components work together to deploy and maintain the service.</p>

<ul>
  <li>
    <p>Mesos</p>

    <p>Mesos is the foundation of the DC/OS cluster. Everything launched within the cluster is allocated resources and managed by Mesos. A typical Mesos cluster has one or three Masters that manage resources for the entire cluster. On DC/OS, the machines running the Mesos Masters will typically run other cluster services as well, such as Marathon and Cosmos, as local system processes. Separately from the Master machines are the Agent machines, which are where in-cluster processes are run. For more information on Mesos architecture, see the <a href="https://mesos.apache.org/documentation/latest/architecture/">Apache Mesos documentation</a>. For more information on DC/OS architecture, see the <a href="https://docs.mesosphere.com/1.9/overview/architecture/">DC/OS architecture documentation</a>.</p>
  </li>
  <li>
    <p>ZooKeeper</p>

    <p>ZooKeeper is a common foundation for DC/OS system components, like Marathon and Mesos. It provides distributed key-value storage for configuration, synchronization, name registration, and cluster state storage. DC/OS comes with ZooKeeper installed by default, typically with one instance per DC/OS master.</p>

    <p>SDK Schedulers use the default ZooKeeper instance to store persistent state across restarts (under znodes named <code class="highlighter-rouge">dcos-service-&lt;svcname&gt;</code>). This allows Schedulers to be killed at any time and continue where they left off.</p>

    <p><strong>Note:</strong> SDK Schedulers currently require ZooKeeper, but any persistent configuration storage (such as etcd) could fit this role. ZooKeeper is a convenient default because it is always present in DC/OS clusters.</p>
  </li>
  <li>
    <p>Marathon</p>

    <p>Marathon is the “init system” of a DC/OS cluster. Marathon launches tasks in the cluster and keeps them running. From the perspective of Mesos, Marathon is itself another Scheduler running its own tasks. Marathon is more general than SDK Schedulers and mainly focuses on tasks that don’t require managing local persistent state. SDK services rely on Marathon to run the Scheduler and to provide it with a configuration via environment variables. The Scheduler, however, maintains its own service tasks without any direct involvement by Marathon.</p>
  </li>
  <li>
    <p>Scheduler</p>

    <p>The Scheduler is the “management layer” of the service. It launches the service nodes and keeps them running. It also exposes endpoints to allow end users to control the service and diagnose problems. The Scheduler is kept online by the cluster’s “init system”, Marathon. The Scheduler itself is effectively a Java application that is configured via environment variables provided by Marathon.</p>
  </li>
  <li>
    <p>Packaging</p>

    <p>SDK services are packaged for deployment on DC/OS. DC/OS packages follow the <a href="https://github.com/mesosphere/universe">Universe schema</a>, which defines how packages expose customization options at initial installation. When a package is installed on the cluster, the packaging service (named ‘Cosmos’) creates a Marathon app that contains a rendered version of the <code class="highlighter-rouge">marathon.json.mustache</code> template provided by the package. For an SDK service, this Marathon app is the Scheduler for the service.</p>
  </li>
</ul>

<p>For further discussion of DC/OS components, see the <a href="https://docs.mesosphere.com/1.9/overview/architecture/components/">architecture documentation</a>.</p>

<h2 id="deployment">
<a id="deployment" class="anchor" href="#deployment" aria-hidden="true"><span class="octicon octicon-link"></span></a>Deployment</h2>

<p>Internally, the SDK treats “Deployment” as moving from one state to another state. By this definition, “Deployment” applies to many scenarios:</p>

<ul>
  <li>When a service is first installed, deployment is moving from a null configuration to a deployed configuration.</li>
  <li>When the deployed configuration is changed by editing an environment variable in the Scheduler, deployment is moving from an initial running configuration to a new proposed configuration.</li>
</ul>

<p>In this section, we’ll describe how these scenarios are handled by the Scheduler.</p>

<h3 id="initial-install">
<a id="initial-install" class="anchor" href="#initial-install" aria-hidden="true"><span class="octicon octicon-link"></span></a>Initial Install</h3>

<p>This is the flow for deploying a new service:</p>

<h4 id="steps-handled-by-the-dcos-cluster">
<a id="steps-handled-by-the-dcos-cluster" class="anchor" href="#steps-handled-by-the-dcos-cluster" aria-hidden="true"><span class="octicon octicon-link"></span></a>Steps handled by the DC/OS cluster</h4>

<ol>
  <li>
    <p>The user runs <code class="highlighter-rouge">dcos package install &lt;package-name&gt;</code> in the DC/OS CLI or clicks <code class="highlighter-rouge">Install</code> for a given package on the DC/OS Dashboard.</p>
  </li>
  <li>
    <p>A request is sent to the Cosmos packaging service to deploy the requested package along with a set of configuration options.</p>
  </li>
  <li>
    <p>Cosmos creates a Marathon app definition by rendering the package’s <code class="highlighter-rouge">marathon.json.mustache</code> with the configuration options provided in the request. In the case of an SDK service, this app represents the service’s Scheduler. Cosmos queries Marathon to create the app.</p>
  </li>
  <li>
    <p>Marathon launches the service’s Scheduler somewhere in the cluster using the rendered app definition provided by Cosmos.</p>
  </li>
  <li>
    <p>The service Scheduler is launched. From this point onwards, the SDK handles deployment.</p>
  </li>
</ol>

<h4 id="steps-handled-by-the-scheduler">
<a id="steps-handled-by-the-scheduler" class="anchor" href="#steps-handled-by-the-scheduler" aria-hidden="true"><span class="octicon octicon-link"></span></a>Steps handled by the Scheduler</h4>

<p>The service Scheduler’s <code class="highlighter-rouge">main()</code> function is run like any other Java application. The Scheduler starts with the following state:</p>

<ul>
  <li>A <code class="highlighter-rouge">svc.yml</code> template that represents the service configuration.</li>
  <li>Environment variables provided by Marathon, to be applied onto the <code class="highlighter-rouge">svc.yml</code> template.</li>
  <li>Any custom logic implemented by the service developer in their Main function (we’ll be assuming this is left with defaults for the purposes of this explanation).</li>
</ul>

<ol>
  <li>
    <p>The <code class="highlighter-rouge">svc.yml</code> template is rendered using the environment variables provided by Marathon.</p>
  </li>
  <li>
    <p>The rendered <code class="highlighter-rouge">svc.yml</code> “Service Spec” contains the host/port for the ZooKeeper instance, which the Scheduler uses for persistent configuration/state storage. The default is <code class="highlighter-rouge">master.mesos:2181</code>, but may be manually configured to use a different ZooKeeper instance. The Scheduler always stores its information under a znode named <code class="highlighter-rouge">dcos-service-&lt;svcname&gt;</code>.</p>
  </li>
  <li>
    <p>The Scheduler connects to that ZooKeeper instance and checks to see if it has previously stored a Mesos Framework ID for itself.</p>
  </li>
</ol>

<ul>
  <li>
    <p>If the Framework ID is present, the Scheduler will attempt to reconnect to Mesos using that ID. This may result in a “<a href="#framework-has-been-removed">Framework has been removed</a>” error if Mesos doesn’t recognize that Framework ID, indicating an incomplete uninstall.</p>
  </li>
  <li>
    <p>If the Framework ID is not present, the Scheduler will attempt to register with Mesos as a Framework. Assuming this is successful, the resulting Framework ID is then immediately stored.</p>
  </li>
</ul>

<ol>
  <li>
    <p>Now that the Scheduler has registered as a Mesos Framework, it is able to start interacting with Mesos and receiving offers. When this begins, Schedulers using the SDK will begin running the <a href="#offer-cycle">Offer Cycle</a> and deploying the service. See that section for more information.</p>
  </li>
  <li>
    <p>The Scheduler retrieves its deployed task state from ZooKeeper and finds that there are tasks that should be launched. This is the first launch, so all tasks need to be launched.</p>
  </li>
  <li>
    <p>The Scheduler deploys those missing tasks through the Mesos offer cycle using a <a href="#plans">Deployment Plan</a> to determine the ordering of that deployment.</p>
  </li>
  <li>
    <p>Once the Scheduler has launched the missing tasks, its current configuration should match the desired configuration defined by the “Service Spec” extracted from <code class="highlighter-rouge">svc.yml</code>.</p>

    <ol>
      <li>When the current configuration matches the desired configuration, the Scheduler will tell Mesos to suspend sending new offers, as there’s nothing to be done.</li>
      <li>The Scheduler idles until it receives an RPC from Mesos notifying it of a task status change, it receives an RPC from an end user against one of its HTTP APIs, or until it is killed by Marathon as the result of a configuration change.</li>
    </ol>
  </li>
</ol>

<h3 id="reconfiguration">
<a id="reconfiguration" class="anchor" href="#reconfiguration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reconfiguration</h3>

<p>This is the flow for reconfiguring a DC/OS service either in order to update specific configuration values, or to upgrade it to a new package version.</p>

<h4 id="steps-handled-by-the-dcos-cluster-1">
<a id="steps-handled-by-the-dcos-cluster-1" class="anchor" href="#steps-handled-by-the-dcos-cluster-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Steps handled by the DC/OS cluster</h4>

<ol>
  <li>The user edits the Scheduler’s environment variables either using the Scheduler CLI’s <code class="highlighter-rouge">update</code> command or via the DC/OS GUI.</li>
  <li>The DC/OS package manager instructs Marathon to kill the current Scheduler and launch a new Scheduler with the updated environment variables.</li>
</ol>

<h4 id="steps-handled-by-the-scheduler-1">
<a id="steps-handled-by-the-scheduler-1" class="anchor" href="#steps-handled-by-the-scheduler-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Steps handled by the Scheduler</h4>

<p>As with initial install above, at this point the Scheduler is re-launched with the same three sources of information it had before:</p>
<ul>
  <li>
<code class="highlighter-rouge">svc.yml</code> template.</li>
  <li>New environment variables.</li>
  <li>Custom logic implemented by the service developer (if any).</li>
</ul>

<p>In addition, the Scheduler now has a fourth piece:</p>
<ul>
  <li>Preexisting state in ZooKeeper</li>
</ul>

<p>Scheduler reconfiguration is slightly different from initial deployment because the Scheduler is now comparing its current state to a non-empty prior state and determining what needs to be changed.</p>

<ol>
  <li>After the Scheduler has rendered its <code class="highlighter-rouge">svc.yml</code> against the new environment variables, it has two Service Specs, reflecting two different configurations.
    <ol>
      <li>The Service Spec that was just rendered, reflecting the configuration change.</li>
      <li>The prior Service Spec (or “Target Configuration”) that was previously stored in ZooKeeper.</li>
    </ol>
  </li>
  <li>The Scheduler automatically compares the changes between the old and new Service Specs.
    <ol>
      <li>
<strong>Change validation</strong>: Certain changes, such as editing volumes and scale-down, are not currently supported because they are complicated and dangerous to get wrong.
        <ul>
          <li>If an invalid change is detected, the Scheduler will send an error message and refuse to proceed until the user has reverted the change by relaunching the Scheduler app in Marathon with the prior config.</li>
          <li>If the changes are valid, the new configuration is stored in ZooKeeper as the new Target Configuration and the change deployment proceeds as described below.</li>
        </ul>
      </li>
      <li>
<strong>Change deployment</strong>: The Scheduler produces a <code class="highlighter-rouge">diff</code> between the current state and some future state, including all of the Mesos calls (reserve, unreserve, launch, destroy, etc.) needed to get there. For example, if the number of tasks has been increased, then the Scheduler will launch the correct number of new tasks. If a task configuration setting has been changed, the Scheduler will deploy that change to the relevant affected tasks by relaunching them. Tasks that aren’t affected by the configuration change will be left as-is.</li>
      <li>
<strong>Custom update logic</strong>: Some services may have defined a <a href="#custom-update-plan">custom <code class="highlighter-rouge">update</code> Plan</a> in its <code class="highlighter-rouge">svc.yml</code>, in cases where different logic is needed for an update/upgrade than is needed for the initial deployment. When a custom <code class="highlighter-rouge">update</code> plan is defined, the Scheduler will automatically use this Plan, instead of the default <code class="highlighter-rouge">deploy</code> Plan, when rolling out an update to the service.</li>
    </ol>
  </li>
</ol>

<h3 id="uninstall">
<a id="uninstall" class="anchor" href="#uninstall" aria-hidden="true"><span class="octicon octicon-link"></span></a>Uninstall</h3>

<p>This is the flow for uninstalling a DC/OS service.</p>

<h4 id="steps-handled-by-the-cluster">
<a id="steps-handled-by-the-cluster" class="anchor" href="#steps-handled-by-the-cluster" aria-hidden="true"><span class="octicon octicon-link"></span></a>Steps handled by the cluster</h4>

<ol>
  <li>The user uses the DC/OS CLI’s <code class="highlighter-rouge">dcos package uninstall</code> command to uninstall the service.</li>
  <li>The DC/OS package manager instructs Marathon to kill the current Scheduler and to launch a new Scheduler with the environment variable <code class="highlighter-rouge">SDK_UNINSTALL</code> set to “true”.</li>
</ol>

<h4 id="steps-handled-by-the-scheduler-2">
<a id="steps-handled-by-the-scheduler-2" class="anchor" href="#steps-handled-by-the-scheduler-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Steps handled by the Scheduler</h4>

<p>When started in uninstall mode, the Scheduler performs the following actions:</p>
<ul>
  <li>Any Mesos resource reservations are unreserved.
    <ul>
      <li>
<strong>Warning</strong>: Any data stored in reserved disk resources will be irretrievably lost.</li>
    </ul>
  </li>
  <li>Preexisting state in ZooKeeper is deleted.</li>
</ul>

<h2 id="offer-cycle">
<a id="offer-cycle" class="anchor" href="#offer-cycle" aria-hidden="true"><span class="octicon octicon-link"></span></a>Offer Cycle</h2>

<p>The Offer Cycle is a core Mesos concept and often a source of confusion when running services on Mesos.</p>

<p>Mesos will periodically notify subscribed Schedulers of resources in the cluster. Schedulers are expected to either accept the offered resources or decline them. In this structure, Schedulers never have a complete picture of the cluster, they only know about what’s being explicitly offered to them at any given time. This allows Mesos the option of only advertising certain resources to specific Schedulers, without requiring any changes on the Scheduler’s end, but it also means that the Scheduler cannot deterministically know whether it’s seen everything that’s available in the cluster.</p>

<p>Schedulers written using the SDK perform the following operations as Offers are received from Mesos:</p>

<ol>
  <li>
<strong>Task Reconciliation</strong>: Mesos is the source of truth for what is running on the cluster. Task Reconciliation allows Mesos to convey the status of all tasks being managed by the service. The Scheduler will request a Task Reconciliation during initial startup, and Mesos will then send the current status of that Scheduler’s tasks. This allows the Scheduler to catch up with any potential status changes to its tasks that occurred after the Scheduler was last running. A common pattern in Mesos is to jealously guard most of what it knows about tasks, so this only contains status information, not general task information. The Scheduler keeps its own copy of what it knows about tasks in ZooKeeper. During an initial deployment this process is very fast as no tasks have been launched yet.</li>
  <li>
<strong>Offer Acceptance</strong>: Once the Scheduler has finished Task Reconciliation, it will start evaluating the resource offers it receives to determine if any match the requirements of the next task(s) to be launched. At this point, users on small clusters may find that the Scheduler isn’t launching tasks. This is generally because the Scheduler isn’t able to find offered machines with enough room to fit the tasks. To fix this, add more/bigger machines to the cluster, or reduce the requirements of the service.</li>
  <li>
<strong>Resource Cleanup</strong>: The Offers provided by Mesos include reservation information if those resources were previously reserved by the Scheduler. The Scheduler will automatically request that any unrecognized but reserved resources be automatically unreserved. This can come up in a few situations, for example, if an agent machine went away for several days and then came back, its resources may still be considered reserved by Mesos as reserved by the service, while the Scheduler has already moved on and doesn’t know about it anymore. At this point, the Scheduler will automatically clean up those resources.</li>
</ol>

<p>SDK Schedulers will automatically notify Mesos to stop sending offers, or “suspend” offers, when the Scheduler doesn’t have any work to do. For example, once a service deployment has completed, the Scheduler will request that offers be suspended. If the Scheduler is later notified that a task has exited via a status update, the Scheduler will resume offers in order to redeploy that task back where it was. This is done by waiting for the offer that matches that task’s reservation, and then launching the task against those resources once more.</p>

<h2 id="pods">
<a id="pods" class="anchor" href="#pods" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pods</h2>

<p>A Task generally maps to a single process within the service. A Pod is a collection of colocated Tasks that share an environment. All Tasks in a Pod will come up and go down together. Therefore, most maintenance operations against the service are at <a href="#pod-operations">Pod granularity</a> rather than Task granularity.</p>

<h2 id="plans">
<a id="plans" class="anchor" href="#plans" aria-hidden="true"><span class="octicon octicon-link"></span></a>Plans</h2>

<p>The Scheduler organizes its work into a list of Plans. Every SDK Scheduler has at least a Deployment Plan and a <a href="#recovery-plan">Recovery Plan</a>, but other Plans may also be added for things like custom Backup and Restore operations. The Deployment Plan is in charge of performing an initial deployment of the service. It is also used for rolling out configuration changes to the service (or in more abstract terms, handling the transition needed to get the service from some state to another state), unless the service developer provided a <a href="#custom-update-plan">custom <code class="highlighter-rouge">update</code> Plan</a>. The Recovery Plan is in charge of relaunching any exited tasks that should always be running.</p>

<p>Plans have a fixed three-level hierarchy. Plans contain Phases, and Phases contain Steps.</p>

<p>For example, let’s imagine a service with two <code class="highlighter-rouge">index</code> nodes and three <code class="highlighter-rouge">data</code> nodes. The Plan structure for a Scheduler in this configuration could look like this:</p>

<ul>
  <li>Deployment Plan (<code class="highlighter-rouge">deploy</code>)
    <ul>
      <li>Index Node Phase
        <ul>
          <li>Index Node 0 Step</li>
          <li>Index Node 1 Step</li>
        </ul>
      </li>
      <li>Data Node Phase
        <ul>
          <li>Data Node 0 Step</li>
          <li>Data Node 1 Step</li>
          <li>Data Node 2 Step</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Custom Update Plan (<code class="highlighter-rouge">update</code>)
    <ul>
      <li><em>(custom logic, if any, for rolling out a config update or software upgrade)</em></li>
    </ul>
  </li>
  <li>Recovery Plan (<code class="highlighter-rouge">recovery</code>)
    <ul>
      <li><em>(phases and steps are autogenerated as failures occur)</em></li>
    </ul>
  </li>
  <li>Index Backup Plan
    <ul>
      <li>Run Reindex Phase
        <ul>
          <li>Index Node 0 Step</li>
          <li>Index Node 1 Step</li>
        </ul>
      </li>
      <li>Upload Data Phase
        <ul>
          <li>Index Node 0 Step</li>
          <li>Index Node 1 Step</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Data Backup Plan
    <ul>
      <li>Data Backup Phase
        <ul>
          <li>Data Node 0 Step</li>
          <li>Data Node 1 Step</li>
          <li>Data Node 2 Step</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>As you can see, in addition to the default Deployment and Recovery Plans, this Scheduler also has a custom Update Plan which provides custom logic for rolling out a change to the service. If a custom plan is not defined then the Deployment Plan is used for this scenario. In addition, the service defines auxiliary Plans that support other custom behavior, specifically one Plan that handles backing up Index nodes, and another for that backs up Data nodes. In practice, there would likely also be Plans for restoring these backups. These auxiliary Plans could all be invoked manually by an operator, and may include additional parameters such as credentials or a backup location. Those are omitted here for brevity.</p>

<p>In short, Plans are the SDK’s abstraction for a sequence of tasks to be performed by the Scheduler. By default, these include deploying and maintaining the cluster, but additional maintenance operations may also be fit into this structure.</p>

<h3 id="custom-update-plan">
<a id="custom-update-plan" class="anchor" href="#custom-update-plan" aria-hidden="true"><span class="octicon octicon-link"></span></a>Custom Update Plan</h3>

<p>By default, the service will use the Deployment Plan when rolling out a configuration change or software upgrade, but some services may need custom logic in this scenario, in which case the service developer may have defined a custom plan named <code class="highlighter-rouge">update</code>.</p>

<h3 id="recovery-plan">
<a id="recovery-plan" class="anchor" href="#recovery-plan" aria-hidden="true"><span class="octicon octicon-link"></span></a>Recovery Plan</h3>

<p>The other default Plan is the Recovery Plan, which handles bringing back failed tasks. The Recovery Plan listens for offers that can be used to bring back those tasks and then relaunches tasks against those offers.</p>

<p>The Scheduler learns whether a task has failed by receiving Task Status updates from Mesos. Task Status updates can be sent during startup to let the scheduler know when a task has started running, to know when the task has exited successfully, or to know when the cluster has lost contact with the machine hosting that task.</p>

<p>When it receives a Task Status update, the Scheduler decides whether a given update indicates a task that needs to be relaunched. When a task must be relaunched, the Scheduler will wait on the Offer cycle.</p>

<h4 id="permanent-and-temporary-recovery">
<a id="permanent-and-temporary-recovery" class="anchor" href="#permanent-and-temporary-recovery" aria-hidden="true"><span class="octicon octicon-link"></span></a>Permanent and temporary recovery</h4>

<p>There are two types of recovery, permanent and temporary. The difference is mainly whether the task being recovered should stay on the same machine, and the side effects that result from that.</p>

<ul>
  <li>
<strong>Temporary</strong> recovery:
    <ul>
      <li>Temporary recovery is triggered when there is a hiccup in the task or the host machine.</li>
      <li>Recovery involves relaunching the task on the same machine as before.</li>
      <li>Recovery occurs automatically.</li>
      <li>Any data in the task’s persistent volumes survives the outage.</li>
      <li>May be manually triggered by a <code class="highlighter-rouge">pod restart</code> command.</li>
    </ul>
  </li>
  <li>
<strong>Permanent</strong> recovery:
    <ul>
      <li>Permanent recovery can be requested when the host machine fails permanently or when the host machine is scheduled for downtime.</li>
      <li>Recovery involves discarding any persistent volumes that the pod once had on the host machine.</li>
      <li>Recovery only occurs in response to a manual <code class="highlighter-rouge">pod replace</code> command (or operators may build their own tooling to invoke the replace command).</li>
    </ul>
  </li>
</ul>

<p>Triggering a permanent recovery is a destructive operation, as it discards any prior persistent volumes for the pod being recovered. This is desirable when the operator knows that the previous machine isn’t coming back. For safety’s sake, permanent recovery is currently not automatically triggered by the SDK itself.</p>

<h2 id="persistent-volumes">
<a id="persistent-volumes" class="anchor" href="#persistent-volumes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Persistent Volumes</h2>

<p>The SDK was created to help simplify the complexity of dealing with persistent volumes. SDK services currently treat volumes as tied to specific agent machines, as one might have in a datacenter with local drives in each system. While EBS or SAN volumes, for instance, can be re-mounted and reused across machines, this isn’t yet supported in the SDK.</p>

<p>Volumes are advertised as resources by Mesos, and Mesos offers multiple types of persistent volumes. The SDK supports two of these types: MOUNT volumes and ROOT volumes.</p>

<ul>
  <li>
<strong>ROOT</strong> volumes:
    <ul>
      <li>Use a shared filesystem tree.</li>
      <li>Share I/O with anything else on that filesystem.</li>
      <li>Are supported by default in new deployments and do not require additional cluster-level configuration.</li>
      <li>Are allocated exactly the amount of disk space that was requested.</li>
    </ul>
  </li>
  <li>
<strong>MOUNT</strong> volumes:
    <ul>
      <li>Use a dedicated partition.</li>
      <li>Have dedicated I/O for the partition.</li>
      <li>Require <a href="https://docs.mesosphere.com/1.9/storage/mount-disk-resources/">additional configuration</a> when setting up the DC/OS cluster.</li>
      <li>Are allocated the entire partition, so allocated space can far exceed what was originally requested. MOUNT volumes cannot be further subdivided between services.</li>
    </ul>
  </li>
</ul>

<p>The fact that MOUNT volumes cannot be subdivided between services means that if multiple services are deployed with MOUNT volumes, they can quickly be unable to densely colocate within the cluster unless many MOUNT volumes are created on each agent. Let’s look at the following deployment scenario across three DC/OS agent machines, each with two enabled MOUNT volumes labeled A and B:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Agent 1: A B
Agent 2: A B
Agent 3: A B
</code></pre></div></div>

<p>Now we install a service X with two nodes that each use one mount volume. The service consumes volume A on agents 1 and 3:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Agent 1: X B
Agent 2: A B
Agent 3: X B
</code></pre></div></div>

<p>Now a service Y is installed with two nodes that each use two mount volumes. The service consumes volume A and B on agent 2, but then is stuck without being able to deploy anything else:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Agent 1: X B
Agent 2: Y Y
Agent 3: X B
</code></pre></div></div>

<p>Configuring <code class="highlighter-rouge">ROOT</code> vs <code class="highlighter-rouge">MOUNT</code> volumes may depend on the service. Some services will support customizing this setting when it is relevant, while others may assume one or the other.</p>

<h2 id="virtual-networks">
<a id="virtual-networks" class="anchor" href="#virtual-networks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Virtual networks</h2>

<p>The SDK allows pods to join virtual networks, with the <code class="highlighter-rouge">dcos</code> virtual network available by defualt. You can specify that a pod should join the virtual network by using the <code class="highlighter-rouge">networks</code> keyword in your YAML definition. Refer to <a href="developer-guide.md">Developers Guide</a> for more information about how to define virtual networks in your service.</p>

<p>When a pod is on a virtual network such as the <code class="highlighter-rouge">dcos</code>:</p>
<ul>
  <li>Every pod gets its own IP address and its own array of ports.</li>
  <li>Pods do not use the ports on the host machine.</li>
  <li>Pod IP addresses can be resolved with the DNS: <code class="highlighter-rouge">&lt;task_name&gt;.&lt;service_name&gt;.autoip.dcos.thisdcos.directory</code>.</li>
  <li>You can also pass labels while invoking CNI plugins. Refer to <a href="developer.md">Developers Guide</a> for more information about adding CNI labels.</li>
</ul>

<h2 id="secrets">
<a id="secrets" class="anchor" href="#secrets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Secrets</h2>

<p>Enterprise DC/OS provides a secrets store to enable access to sensitive data such as database passwords, private keys, and API tokens. DC/OS manages secure transportation of secret data, access control and authorization, and secure storage of secret content.</p>

<p>The content of a secret is copied and made available within the pod. The SDK allows secrets to be exposed to pods as a file and/or as an environment variable. Refer to <a href="developer-guide.md">Developer Guide</a> for more information about how DC/OS secrets are integration in SDK-based services. If the content of the secret is changed, the relevant pod needs to be restarted so that it can get updated content from the secret store.</p>

<p><strong>Note:</strong> Secrets are available only in Enterprise DC/OS 1.10 onwards. <a href="https://docs.mesosphere.com/1.10/security/secrets/">Learn more about the secrets store</a>.</p>

<h3 id="authorization-for-secrets">
<a id="authorization-for-secrets" class="anchor" href="#authorization-for-secrets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Authorization for Secrets</h3>

<p>The path of a secret defines which service IDs can have access to it. You can think of secret paths as namespaces. <em>Only</em> services that are under the same namespace can read the content of the secret.</p>

<table>
  <thead>
    <tr>
      <th>Secret</th>
      <th>Service ID</th>
      <th>Can service access secret?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="highlighter-rouge">Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/user</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/dev1/user</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/user</code></td>
      <td>No</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/user/dev1</code></td>
      <td>No</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/secret-svc</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/secret-svc/dev1</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/secret-svc/instance2/dev2</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/secret-svc/a/b/c/dev3</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/instance1/Secret_Path2</code></td>
      <td><code class="highlighter-rouge">/secret-svc/dev1</code></td>
      <td>No</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/instance1/Secret_Path2</code></td>
      <td><code class="highlighter-rouge">/secret-svc/instance2/dev3</code></td>
      <td>No</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/instance1/Secret_Path2</code></td>
      <td><code class="highlighter-rouge">/secret-svc/instance1</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/instance1/Secret_Path2</code></td>
      <td><code class="highlighter-rouge">/secret-svc/instance1/dev3</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/instance1/Secret_Path2</code></td>
      <td><code class="highlighter-rouge">/secret-svc/instance1/someDir/dev3</code></td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>

<p><strong>Note:</strong> Absolute paths (paths with a leading slash) to secrets are not supported. The file path for a secret must be relative to the sandbox.</p>

<h3 id="binary-secrets">
<a id="binary-secrets" class="anchor" href="#binary-secrets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Binary Secrets</h3>

<p>You can store binary files, like a Kerberos keytab, in the DC/OS secrets store. Your file must be Base64-encoded as specified in RFC 4648.</p>

<p>You can use standard <code class="highlighter-rouge">base64</code> command line utility. The following example uses the BSD <code class="highlighter-rouge">base64</code> command.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$  base64 -i krb5.keytab -o kerb5.keytab.base64-encoded
</code></pre></div></div>

<p>The <code class="highlighter-rouge">base64</code> command line utility in Linux inserts line-feeds in the encoded data by default. Disable line-wrapping with the <code class="highlighter-rouge">-w 0</code> argument. Here is a sample base64 command in Linux.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$  base64 -w 0 -i krb5.keytab &gt; kerb5.keytab.base64-encoded
</code></pre></div></div>

<p>Prefix the secret name with <code class="highlighter-rouge">__dcos_base64__</code>. For example  <code class="highlighter-rouge">some/path/__dcos_base64__mysecret</code> and <code class="highlighter-rouge">__dcos_base64__mysecret</code> will be base64-decoded automatically.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$  dcos security secrets  create -f kerb5.keytab.base64-encoded  some/path/__dcos_base64__mysecret
</code></pre></div></div>

<p>When you reference the <code class="highlighter-rouge">__dcos_base64__mysecret</code> secret in your service, the content of the secret will be first base64-decoded, and then copied and made available to your service. Refer to the <a href="developer-guide.md">Developer Guide</a> for more information on how to reference DC/OS secrets as a file in SDK-based services. Refer to a binary secret
only as a file such that it will be autoatically decoded and made available as a temporary in-memory file mounted within your container (file-based secrets).</p>

<h2 id="placement-constraints">
<a id="placement-constraints" class="anchor" href="#placement-constraints" aria-hidden="true"><span class="octicon octicon-link"></span></a>Placement Constraints</h2>

<p>Placement constraints allow you to customize where a service is deployed in the DC/OS cluster. Depending on the service, some or all components may be configurable using <a href="http://mesosphere.github.io/marathon/docs/constraints.html">Marathon operators (reference)</a> with this syntax: <code class="highlighter-rouge">field:OPERATOR[:parameter]</code>. For example, if the reference lists <code class="highlighter-rouge">[["hostname", "UNIQUE"]]</code>, you should  use <code class="highlighter-rouge">hostname:UNIQUE</code>.</p>

<p>A common task is to specify a list of whitelisted systems to deploy to. To achieve this, use the following syntax for the placement constraint:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hostname:LIKE:10.0.0.159|10.0.1.202|10.0.3.3
</code></pre></div></div>

<p>You must include spare capacity in this list, so that if one of the whitelisted systems goes down, there is still enough room to repair your service (via <a href="#replace-a-pod"><code class="highlighter-rouge">pod replace</code></a>) without requiring that system.</p>

<h3 id="regions-and-zones">
<a id="regions-and-zones" class="anchor" href="#regions-and-zones" aria-hidden="true"><span class="octicon octicon-link"></span></a>Regions and Zones</h3>

<p>Placement constraints can be applied to zones by referring to the <code class="highlighter-rouge">@zone</code> key. For example, one could spread pods across a minimum of 3 different zones by specifying the constraint:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[["@zone", "GROUP_BY", "3"]]
</code></pre></div></div>

<p>When the region awareness feature is enabled (currently in beta), the <code class="highlighter-rouge">@region</code> key can also be referenced for defining placement constraints. Any placement constraints that do not reference the <code class="highlighter-rouge">@region</code> key are constrained to the local region.</p>

<h4 id="rack-aware-services">
<a id="rack-aware-services" class="anchor" href="#rack-aware-services" aria-hidden="true"><span class="octicon octicon-link"></span></a>Rack aware services</h4>

<p>Many rack aware services do not support reliable migration between rack-aware and non-rack-aware operation.  These services can choose to restrict the set of placement constraint transitions which are valid through use of the <code class="highlighter-rouge">ZoneValidator</code>.  The allowed placement constraint transitions when using the <code class="highlighter-rouge">ZoneValidator</code> are as follows:</p>

<h5 id="placement-constraint-references-zones">
<a id="placement-constraint-references-zones" class="anchor" href="#placement-constraint-references-zones" aria-hidden="true"><span class="octicon octicon-link"></span></a>Placement Constraint References Zones</h5>

<table>
  <thead>
    <tr>
      <th>Original Constraint</th>
      <th>New Constraint</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>None</td>
      <td>False</td>
    </tr>
    <tr>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h3 id="updating-placement-constraints">
<a id="updating-placement-constraints" class="anchor" href="#updating-placement-constraints" aria-hidden="true"><span class="octicon octicon-link"></span></a>Updating placement constraints</h3>

<p>Clusters change, and as such so should your placement constraints. We recommend using the following procedure to do this:</p>
<ul>
  <li>Update the placement constraint definition at the Scheduler.</li>
  <li>For each pod, <em>one at a time</em>, perform a <code class="highlighter-rouge">pod replace</code> for any pods that need to be moved to reflect the change.</li>
</ul>

<p>For example, let’s say we have the following deployment of our imaginary <code class="highlighter-rouge">data</code> nodes, with manual IPs defined for placing the nodes in the cluster:</p>

<ul>
  <li>Placement constraint of: <code class="highlighter-rouge">hostname:LIKE:10.0.10.3|10.0.10.8|10.0.10.26|10.0.10.28|10.0.10.84</code>
</li>
  <li>Tasks:
    <div class="highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>10.0.10.3: data-0
10.0.10.8: data-1
10.0.10.26: data-2
10.0.10.28: [empty]
10.0.10.84: [empty]
</code></pre></div>    </div>
  </li>
</ul>

<p>Given the above configuration, let’s assume <code class="highlighter-rouge">10.0.10.8</code> is being decommissioned and our service should be moved off of it. Steps:</p>

<ol>
  <li>Remove the decommissioned IP and add a new IP to the placement rule whitelist, by configuring the Scheduler environment with a new <code class="highlighter-rouge">DATA_NODE_PLACEMENT</code> setting:
    <div class="highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>hostname:LIKE:10.0.10.3|10.0.10.26|10.0.10.28|10.0.10.84|10.0.10.123
</code></pre></div>    </div>
  </li>
  <li>Wait for the Scheduler to restart with the new placement constraint setting.</li>
  <li>Trigger a redeployment of <code class="highlighter-rouge">data-1</code> from the decommissioned node to a new machine within the new whitelist: <code class="highlighter-rouge">dcos myservice node replace data-1</code>
</li>
  <li>Wait for <code class="highlighter-rouge">data-1</code> to be up and healthy before continuing with any other replacement operations.</li>
</ol>

<p>The ability to configure placement constraints is defined on a per-service basis. Some services may offer very granular settings, while others may not offer them at all. You’ll need to consult the documentation for the service in question, but in theory they should all understand the same set of <a href="http://mesosphere.github.io/marathon/docs/constraints.html">Marathon operators</a>.</p>

<h2 id="integration-with-dcos-access-controls">
<a id="integration-with-dcos-access-controls" class="anchor" href="#integration-with-dcos-access-controls" aria-hidden="true"><span class="octicon octicon-link"></span></a>Integration with DC/OS access controls</h2>

<p>In DC/OS 1.10 and above, you can integrate your SDK-based service with DC/OS ACLs to grant users and groups access to only certain services. You do this by installing your service into a folder, and then restricting access to some number of folders. Folders also allow you to namespace services. For instance, <code class="highlighter-rouge">staging/kafka</code> and <code class="highlighter-rouge">production/kafka</code>.</p>

<p>Steps:</p>

<ol>
  <li>In the DC/OS GUI, create a group, then add a user to the group. Or, just create a user. Click <strong>Organization</strong> &gt; <strong>Groups</strong> &gt; <strong>+</strong> or <strong>Organization</strong> &gt; <strong>Users</strong> &gt; <strong>+</strong>. If you create a group, you must also create a user and add them to the group.</li>
  <li>
    <p>Give the user permissions for the folder where you will install your service. In this example, we are creating a user called <code class="highlighter-rouge">developer</code>, who will have access to the <code class="highlighter-rouge">/testing</code> folder.
Select the group or user you created. Select <strong>ADD PERMISSION</strong> and then toggle to <strong>INSERT PERMISSION STRING</strong>. Add each of the following permissions to your user or group, and then click <strong>ADD PERMISSIONS</strong>.</p>

    <div class="highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>dcos:adminrouter:service:marathon full
dcos:service:marathon:marathon:services:/testing full
dcos:adminrouter:ops:mesos full
dcos:adminrouter:ops:slave full
</code></pre></div>    </div>
  </li>
  <li>Install a service (in this example, Kafka) into a folder called <code class="highlighter-rouge">test</code>. Go to <strong>Catalog</strong>, then search for <strong>beta-kafka</strong>.</li>
  <li>
    <p>Click <strong>CONFIGURE</strong> and change the service name to <code class="highlighter-rouge">/testing/kafka</code>, then deploy.</p>

    <p>The slashes in your service name are interpreted as folders. You are deploying Kafka in the <code class="highlighter-rouge">/testing</code> folder. Any user with access to the <code class="highlighter-rouge">/testing</code> folder will have access to the service.</p>
  </li>
</ol>

<p><strong>Important:</strong></p>
<ul>
  <li>Services cannot be renamed. Because the location of the service is specified in the name, you cannot move services between folders.</li>
  <li>DC/OS 1.9 and earlier does not accept slashes in service names. You may be able to create the service, but you will encounter unexpected problems.</li>
</ul>

<h3 id="interacting-with-your-foldered-service">
<a id="interacting-with-your-foldered-service" class="anchor" href="#interacting-with-your-foldered-service" aria-hidden="true"><span class="octicon octicon-link"></span></a>Interacting with your foldered service</h3>

<ul>
  <li>Interact with your foldered service via the DC/OS CLI with this flag: <code class="highlighter-rouge">--name=/path/to/myservice</code>.</li>
  <li>To interact with your foldered service over the web directly, use <code class="highlighter-rouge">http://&lt;dcos-url&gt;/service/path/to/myservice</code>. E.g., <code class="highlighter-rouge">http://&lt;dcos-url&gt;/service/testing/kafka/v1/endpoints</code>.</li>
</ul>

<h1 id="common-operations">
<a id="common-operations" class="anchor" href="#common-operations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Common Operations</h1>
<!--  disable mustache templating in this file: retain templated examples as-is -->

<p>This guide has so far focused on describing the components, how they work, and how to interact with them. At this point we’ll start looking at how that knowledge can be applied to a running service.</p>

<h2 id="initial-service-configuration">
<a id="initial-service-configuration" class="anchor" href="#initial-service-configuration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Initial service configuration</h2>

<p>The DC/OS package format allows packages to define user-visible installation options. To ensure consistent installations, we recommend exporting the options you use into an <code class="highlighter-rouge">options.json</code> file, which can then be placed in source control and kept up to date with the current state of the cluster. Keeping these configurations around will make it easy to duplicate or reinstall services using identical configurations.</p>

<p>Use this CLI command to see what options are available for a given package:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos package describe elastic <span class="nt">--config</span>
<span class="o">{</span>
  <span class="s2">"properties"</span>: <span class="o">{</span>
    <span class="s2">"coordinator_nodes"</span>: <span class="o">{</span>
      <span class="s2">"description"</span>: <span class="s2">"Elasticsearch coordinator node configuration properties"</span>,
      <span class="s2">"properties"</span>: <span class="o">{</span>
        <span class="s2">"count"</span>: <span class="o">{</span>
          <span class="s2">"default"</span>: 1,
          <span class="s2">"description"</span>: <span class="s2">"Number of coordinator nodes to run"</span>,
          <span class="s2">"minimum"</span>: 0,
          <span class="s2">"type"</span>: <span class="s2">"integer"</span>
        <span class="o">}</span>,
        <span class="s2">"cpus"</span>: <span class="o">{</span>
          <span class="s2">"default"</span>: 1.0,
          <span class="s2">"description"</span>: <span class="s2">"Node cpu requirements"</span>,
          <span class="s2">"type"</span>: <span class="s2">"number"</span>
        <span class="o">}</span>,
        ...
      <span class="o">}</span>
    <span class="o">}</span>
    <span class="s2">"service"</span>: <span class="o">{</span>
      <span class="s2">"description"</span>: <span class="s2">"DC/OS service configuration properties"</span>,
      <span class="s2">"properties"</span>: <span class="o">{</span>
        ...
        <span class="s2">"name"</span>: <span class="o">{</span>
          <span class="s2">"default"</span>: <span class="s2">"elastic"</span>,
          <span class="s2">"description"</span>: <span class="s2">"The name of the Elasticsearch service instance"</span>,
          <span class="s2">"type"</span>: <span class="s2">"string"</span>
        <span class="o">}</span>,
        ...
        <span class="s2">"user"</span>: <span class="o">{</span>
          <span class="s2">"default"</span>: <span class="s2">"core"</span>,
          <span class="s2">"description"</span>: <span class="s2">"The user that runs the Elasticsearch services and owns the Mesos sandbox."</span>,
          <span class="s2">"type"</span>: <span class="s2">"string"</span>
        <span class="o">}</span>
      <span class="o">}</span>
    <span class="o">}</span>
  <span class="o">}</span>
<span class="o">}</span>
...
</code></pre></div></div>

<p>Given the above example, let’s build an <code class="highlighter-rouge">elastic-prod-options.json</code> that customizes the above values:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"coordinator_nodes"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"count"</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w">
    </span><span class="s2">"cpus"</span><span class="p">:</span><span class="w"> </span><span class="mf">2.0</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="s2">"service"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"elastic-prod"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"user"</span><span class="p">:</span><span class="w"> </span><span class="s2">"elastic"</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Now that we have <code class="highlighter-rouge">elastic-prod-options.json</code>, we can install a service instance that uses it as follows:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos package <span class="nb">install</span> <span class="nt">--options</span><span class="o">=</span>elastic-prod-options.json elastic
</code></pre></div></div>

<p>Once we know the configuration is good, it should be added to our source control for tracking.</p>

<h2 id="updating-service-configuration">
<a id="updating-service-configuration" class="anchor" href="#updating-service-configuration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Updating service configuration</h2>

<p>Above, we described how a configuration update (including updating the version of the service) is handled. Now we will quickly show the steps to perform such an update.</p>

<p>Configuration updates are performed by updating the process environment of the Scheduler. Once restarted, the Scheduler will observe this change and re-deploy nodes as described in <a href="#Reconfiguration">Reconfiguration</a>.</p>

<h3 id="enterprise-dcos-110">
<a id="enterprise-dcos-110" class="anchor" href="#enterprise-dcos-110" aria-hidden="true"><span class="octicon octicon-link"></span></a>Enterprise DC/OS 1.10</h3>

<p>Enterprise DC/OS 1.10 introduces a convenient command line option that allows for easier updates to a service’s configuration, as well as allowing users to inspect the status of an update, to pause and resume updates, and to restart or complete steps if necessary.</p>

<h4 id="prerequisites">
<a id="prerequisites" class="anchor" href="#prerequisites" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prerequisites</h4>

<ul>
  <li>Enterprise DC/OS 1.10 or newer.</li>
  <li>A DC/OS SDK-based service with a version greater than 2.0.0-x.</li>
  <li>
<a href="https://docs.mesosphere.com/latest/cli/install/">The DC/OS CLI</a> installed and available.</li>
  <li>The service’s subcommand available and installed on your local machine.
    <ul>
      <li>You can install just the subcommand CLI by running <code class="highlighter-rouge">dcos package install --cli &lt;service-name&gt;</code>.</li>
      <li>If you are running an older version of the subcommand CLI that doesn’t have the <code class="highlighter-rouge">update</code> command, uninstall and reinstall your CLI.
        <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>dcos package uninstall <span class="nt">--cli</span> &lt;service-name&gt;
dcos package <span class="nb">install</span> <span class="nt">--cli</span> &lt;service-name&gt;
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<h5 id="updating-package-version">
<a id="updating-package-version" class="anchor" href="#updating-package-version" aria-hidden="true"><span class="octicon octicon-link"></span></a>Updating package version</h5>

<p>The instructions below show how to safely update one version of a service to the next.</p>

<h6 id="viewing-available-versions">
<a id="viewing-available-versions" class="anchor" href="#viewing-available-versions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Viewing available versions</h6>

<p>The <code class="highlighter-rouge">update package-versions</code> command allows you to view the versions of a service that you can upgrade or downgrade to. These are specified by the service maintainer and depend on the semantics of the service (i.e. whether or not upgrades are reversal).</p>

<p>For example, for <code class="highlighter-rouge">dse</code>, run:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update package-versions
</code></pre></div></div>

<h6 id="upgrading-or-downgrading-a-service">
<a id="upgrading-or-downgrading-a-service" class="anchor" href="#upgrading-or-downgrading-a-service" aria-hidden="true"><span class="octicon octicon-link"></span></a>Upgrading or downgrading a service</h6>

<ol>
  <li>Before updating the service itself, update its CLI subcommand to the new version:
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos package uninstall <span class="nt">--cli</span> dse
<span class="nv">$ </span>dcos package <span class="nb">install</span> <span class="nt">--cli</span> dse <span class="nt">--package-version</span><span class="o">=</span><span class="s2">"1.1.6-5.0.7"</span>
</code></pre></div>    </div>
  </li>
  <li>Once the CLI subcommand has been updated, call the update start command, passing in the version. For example, to update <code class="highlighter-rouge">dse</code> to version <code class="highlighter-rouge">1.1.6-5.0.7</code>:
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update start <span class="nt">--package-version</span><span class="o">=</span><span class="s2">"1.1.6-5.0.7"</span>
</code></pre></div>    </div>
  </li>
</ol>

<p>If you are missing mandatory configuration parameters, the <code class="highlighter-rouge">update</code> command will return an error.</p>

<p>To supply missing configuration values or to override configuration values, you can also provide an <code class="highlighter-rouge">options.json</code> file (see <a href="#updating-configuration">Updating configuration</a> below):</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update start <span class="nt">--options</span><span class="o">=</span>options.json <span class="nt">--package-version</span><span class="o">=</span><span class="s2">"1.1.6-5.0.7"</span>
</code></pre></div></div>

<p>The default behavior on update is to merge ‘Default’, ‘Stored’ and ‘Provided’ configurations, in that order, and then
validate against the schema. In some situations, such as when a schema option has been removed, the default behavior
might result in an invalid configuration. You can work around this with <code class="highlighter-rouge">--replace=true</code> which, when specified,
will override the ‘Stored’ options with the ‘Provided’ options.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update start <span class="nt">--options</span><span class="o">=</span>options.json <span class="nt">--replace</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--package-verion</span><span class="o">=</span><span class="s2">"1.1.6-5.0.7"</span>
</code></pre></div></div>

<p>See <a href="#advanced-update-actions">Advanced update actions</a> for commands you can use to inspect and manipulate an update after it has started.</p>

<h5 id="updating-configuration">
<a id="updating-configuration" class="anchor" href="#updating-configuration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Updating configuration</h5>

<p>The instructions below describe how to update the configuration for a running DC/OS service.</p>

<h6 id="preparing-configuration">
<a id="preparing-configuration" class="anchor" href="#preparing-configuration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparing configuration</h6>

<p>If you installed this service with Enterprise DC/OS 1.10, you can fetch the full configuration of a service (including any default values that were applied during installation). For example, for <code class="highlighter-rouge">dse</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse describe <span class="o">&gt;</span> options.json
</code></pre></div></div>

<p>Make any configuration changes to this <code class="highlighter-rouge">options.json</code> file.</p>

<p>If you installed this service with a prior version of DC/OS, this configuration will not have been persisted by the DC/OS package manager. You can instead use the <code class="highlighter-rouge">options.json</code> file that was used when <a href="#initial-service-configuration">installing the service</a>.</p>

<p><strong>Note:</strong> You need to specify all configuration values in the <code class="highlighter-rouge">options.json</code> file when performing a configuration update. Any unspecified values will be reverted to the default values specified by the DC/OS service. See the “Recreating <code class="highlighter-rouge">options.json</code>” section below for information on recovering these values.</p>

<p>####### Recreating <code class="highlighter-rouge">options.json</code> (optional)</p>

<p>If the <code class="highlighter-rouge">options.json</code> from when the service was last installed or updated is not available, you will need to manually recreate it using the following steps.</p>

<p>First, we’ll fetch the default application’s environment, current application’s environment, and the actual template that maps config values to the environment:</p>

<ol>
  <li>Ensure you have <a href="https://stedolan.github.io/jq/">jq</a> installed.</li>
  <li>Set the service name that you’re using, in this example we’ll use <code class="highlighter-rouge">dse</code>:
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nv">$ SERVICE_NAME</span><span class="o">=</span>dse
</code></pre></div>    </div>
  </li>
  <li>Get the version of the package that is currently installed:
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nv">$ PACKAGE_VERSION</span><span class="o">=</span><span class="k">$(</span>dcos package list | <span class="nb">grep</span> <span class="nv">$SERVICE_NAME</span> | <span class="nb">awk</span> <span class="s1">'{print $2}'</span><span class="k">)</span>
</code></pre></div>    </div>
  </li>
  <li>Then fetch and save the environment variables that have been set for the service:
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos marathon app show <span class="nv">$SERVICE_NAME</span> | jq .env <span class="o">&gt;</span> current_env.json
</code></pre></div>    </div>
  </li>
  <li>To identify those values that are custom, we’ll get the default environment variables for this version of the service:
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos package describe <span class="nt">--package-version</span><span class="o">=</span><span class="nv">$PACKAGE_VERSION</span> <span class="nt">--render</span> <span class="nt">--app</span> <span class="nv">$SERVICE_NAME</span> | jq .env <span class="o">&gt;</span> default_env.json
</code></pre></div>    </div>
  </li>
  <li>We’ll also get the entire application template:
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos package describe <span class="nv">$SERVICE_NAME</span> <span class="nt">--app</span> <span class="o">&gt;</span> marathon.json.mustache
</code></pre></div>    </div>
  </li>
</ol>

<p>Now that you have these files, we’ll attempt to recreate the <code class="highlighter-rouge">options.json</code>.</p>

<ol>
  <li>Use JQ and <code class="highlighter-rouge">diff</code> to compare the two:
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>diff &lt;<span class="o">(</span>jq <span class="nt">-S</span> <span class="nb">.</span> default_env.json<span class="o">)</span> &lt;<span class="o">(</span>jq <span class="nt">-S</span> <span class="nb">.</span> current_env.json<span class="o">)</span>
</code></pre></div>    </div>
  </li>
  <li>Now compare these values to the values contained in the <code class="highlighter-rouge">env</code> section in application template:
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>less marathon.json.mustache
</code></pre></div>    </div>
  </li>
  <li>Use the variable names (e.g. <code class="highlighter-rouge">{{service.name}}</code>) to create a new <code class="highlighter-rouge">options.json</code> file as described in <a href="#initial-service-configuration">Initial service configuration</a>.</li>
</ol>

<h6 id="starting-the-update">
<a id="starting-the-update" class="anchor" href="#starting-the-update" aria-hidden="true"><span class="octicon octicon-link"></span></a>Starting the update</h6>

<p>Once you are ready to begin, initiate an update using the DC/OS CLI, passing in the updated <code class="highlighter-rouge">options.json</code> file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update start <span class="nt">--options</span><span class="o">=</span>options.json
</code></pre></div></div>

<p>You will receive an acknowledgement message and the DC/OS package manager will restart the Scheduler in Marathon.</p>

<p>See <a href="#advanced-update-actions">Advanced update actions</a> for commands you can use to inspect and manipulate an update after it has started.</p>

<h5 id="advanced-update-actions">
<a id="advanced-update-actions" class="anchor" href="#advanced-update-actions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Advanced update actions</h5>

<p>The following sections describe advanced commands that be used to interact with an update in progress.</p>

<h6 id="monitoring-the-update">
<a id="monitoring-the-update" class="anchor" href="#monitoring-the-update" aria-hidden="true"><span class="octicon octicon-link"></span></a>Monitoring the update</h6>

<p>Once the Scheduler has been restarted, it will begin a new deployment plan as individual pods are restarted with the new configuration. Depending on the high availability characteristics of the service being updated, you may experience a service disruption.</p>

<p>You can query the status of the update as follows:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update status
</code></pre></div></div>

<p>If the Scheduler is still restarting, DC/OS will not be able to route to it and this command will return an error message. Wait a short while and try again. You can also go to the Services tab of the DC/OS GUI to check the status of the restart.</p>

<h6 id="pause">
<a id="pause" class="anchor" href="#pause" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pause</h6>

<p>To pause an ongoing update, issue a pause command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update pause
</code></pre></div></div>

<p>You will receive an error message if the plan has already completed or has been paused. Once completed, the plan will enter the <code class="highlighter-rouge">WAITING</code> state.</p>

<h6 id="resume">
<a id="resume" class="anchor" href="#resume" aria-hidden="true"><span class="octicon octicon-link"></span></a>Resume</h6>

<p>If a plan is in a <code class="highlighter-rouge">WAITING</code> state, as a result of being paused or reaching a breakpoint that requires manual operator verification, you can use the <code class="highlighter-rouge">resume</code> command to continue the plan:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update resume
</code></pre></div></div>

<p>You will receive an error message if you attempt to <code class="highlighter-rouge">resume</code> a plan that is already in progress or has already completed.</p>

<h6 id="force-complete">
<a id="force-complete" class="anchor" href="#force-complete" aria-hidden="true"><span class="octicon octicon-link"></span></a>Force Complete</h6>

<p>In order to manually “complete” a step (such that the Scheduler stops attempting to launch a task), you can issue a <code class="highlighter-rouge">force-complete</code> command. This will instruct to Scheduler to mark a specific step within a phase as complete. You need to specify both the phase and the step, for example:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update force-complete dse-phase dse-0:[node]
</code></pre></div></div>

<h6 id="force-restart">
<a id="force-restart" class="anchor" href="#force-restart" aria-hidden="true"><span class="octicon octicon-link"></span></a>Force Restart</h6>

<p>Similar to force complete, you can also force a restart. This can either be done for an entire plan, a phase, or just for a specific step.</p>

<p>To restart the entire plan:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update force-restart
</code></pre></div></div>

<p>Or for all steps in a single phase:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update force-restart dse-phase
</code></pre></div></div>

<p>Or for a specific step within a specific phase:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos dse update force-restart dse-phase dse-0:[node]
</code></pre></div></div>

<h4 id="open-source-dcos-dcos-19-and-earlier">
<a id="open-source-dcos-dcos-19-and-earlier" class="anchor" href="#open-source-dcos-dcos-19-and-earlier" aria-hidden="true"><span class="octicon octicon-link"></span></a>Open Source DC/OS, DC/OS 1.9, and Earlier</h4>

<p>If you do not have Enterprise DC/OS 1.10 or later, the CLI commands above are not available. For Open Source DC/OS of any version, or Enterprise DC/OS 1.9 and earlier, you can perform changes from the DC/OS GUI.</p>

<ol>
  <li>
    <p>Go to the <strong>Services</strong> tab of the DC/OS GUI and click the name of the Scheduler you wish to edit.</p>
  </li>
  <li>
    <p>Click the three dots on the right hand side of the page for your Scheduler, then choose <strong>Edit</strong>.</p>
  </li>
</ol>

<p><a href="img/ops-guide-edit-scheduler.png"><img src="img/ops-guide-edit-scheduler.png" alt="Choose edit from the three dot menu" width="400"></a></p>

<ol>
  <li>
    <p>In the window that appears, click the <strong>Environment</strong> tab to show a list of the Scheduler’s environment variables. For the sake of this demo, we will increase the <code class="highlighter-rouge">OPSCENTER_MEM</code> value from <code class="highlighter-rouge">4000</code> to <code class="highlighter-rouge">5000</code>, thereby increasing the RAM quota for the OpsCenter task in this service. See <a href="#finding-the-correct-environment-variable">finding the correct environment variable</a> for more information on determining the correct value to be updated.</p>
  </li>
  <li>After you click <code class="highlighter-rouge">Change and deploy</code>, the following will happen:
    <ul>
      <li>Marathon will restart the Scheduler so that it picks up our change.</li>
      <li>The Scheduler will detect that the OpsCenter task’s configuration has changed. The OpsCenter task will be restarted with the change applied. In this case, with allocated RAM increased from 4000 to 5000 MB.</li>
    </ul>
  </li>
  <li>We can see the result by looking at the Mesos task list. At the top we see the new <code class="highlighter-rouge">dse</code> Scheduler and new OpsCenter instance. At the bottom we see the previous <code class="highlighter-rouge">dse</code> Scheduler and OpsCenter instance which were replaced due to our change:</li>
</ol>

<p><a href="img/ops-guide-mesos-tasks-reconfigured.png"><img src="img/ops-guide-mesos-tasks-reconfigured.png" alt="dse app deployment in Mesos with exited tasks and newly launched tasks" width="400"></a></p>

<p>If we look at the Scheduler logs, we can even see where it detected the change. The <code class="highlighter-rouge">api-port</code> value is random on each Scheduler restart, so it tends to always display as ‘different’ in this log. Because of this, the Scheduler automatically ignores changes to <code class="highlighter-rouge">api-port</code>, and so the change can be ignored here:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO  2017-04-25 20:26:08,343 [main] com.mesosphere.sdk.config.DefaultConfigurationUpdater:printConfigDiff(215): Difference between configs:
<span class="gd">--- ServiceSpec.old
</span><span class="gi">+++ ServiceSpec.new
</span><span class="gu">@@ -3,5 +3,5 @@
</span>   "role" : "dse-role",
   "principal" : "dse-principal",
<span class="gd">-  "api-port" : 18446,
</span><span class="gi">+  "api-port" : 15063,
</span>   "web-url" : null,
   "ZooKeeper" : "master.mesos:2181",
<span class="gu">@@ -40,5 +40,5 @@
</span>             "type" : "SCALAR",
             "scalar" : {
<span class="gd">-              "value" : 4000.0
</span><span class="gi">+              "value" : 5000.0
</span>             },
             "ranges" : null,
</code></pre></div></div>

<p>The steps above apply to any configuration change: the Scheduler is restarted, detects the config change, and then launches and/or restarts any affected tasks to reflect the change. When multiple tasks are affected, the Scheduler will follow the deployment Plan used for those tasks to redeploy them. In practice this typically means that each task will be deployed in a sequential rollout, where task <code class="highlighter-rouge">N+1</code> is only redeployed after task <code class="highlighter-rouge">N</code> appears to be healthy and ready after being relaunched with the new configuration. Some services may have defined a custom <code class="highlighter-rouge">update</code> plan which invokes custom logic for rolling out changes which varies from the initial deployment rollout. The default behavior, when no custom <code class="highlighter-rouge">update</code> plan was defined, is to use the <code class="highlighter-rouge">deploy</code> plan.</p>

<h5 id="finding-the-correct-environment-variable">
<a id="finding-the-correct-environment-variable" class="anchor" href="#finding-the-correct-environment-variable" aria-hidden="true"><span class="octicon octicon-link"></span></a>Finding the correct environment variable</h5>

<p>While DC/OS Enterprise 1.10+ supports changing the configuration using the option schema directly, DC/OS Open and versions 1.9 and earlier require mapping those options to the environment variables that are passed to the Scheduler.</p>

<p>The correct environment variable for a given setting can vary depending on the service. For instance, some services have multiple types of nodes, each with separate count settings. If you want to increase the number of nodes, it would take some detective work to find the correct environment variable.</p>

<p>For example, let’s look at the most recent release of <code class="highlighter-rouge">confluent-kafka</code> as of this writing. The number of brokers is configured using a <a href="https://github.com/mesosphere/universe/blob/98a21f4f3710357a235f0549c3caabcab66893fd/repo/packages/C/confluent-kafka/16/config.json#L133"><code class="highlighter-rouge">count</code> setting in the <code class="highlighter-rouge">brokers</code> section</a>:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"..."</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="p">,</span><span class="w">
  </span><span class="s2">"count"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"description"</span><span class="p">:</span><span class="s2">"Number of brokers to run"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"type"</span><span class="p">:</span><span class="s2">"number"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"default"</span><span class="p">:</span><span class="mi">3</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="s2">"..."</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>To see where this setting is passed when the Scheduler is first launched, we can look at the adjacent <a href="https://github.com/mesosphere/universe/blob/98a21f4f3710357a235f0549c3caabcab66893fd/repo/packages/C/confluent-kafka/16/marathon.json.mustache#L34"><code class="highlighter-rouge">marathon.json.mustache</code> template file</a>. Searching for <code class="highlighter-rouge">brokers.count</code> in <code class="highlighter-rouge">marathon.json.mustache</code> reveals the environment variable that we should change:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"..."</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="p">,</span><span class="w">
  </span><span class="s2">"env"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"..."</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="p">,</span><span class="w">
    </span><span class="s2">"BROKER_COUNT"</span><span class="p">:</span><span class="w"> </span><span class="s2">"{{brokers.count}}"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"..."</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="s2">"..."</span><span class="p">:</span><span class="w"> </span><span class="s2">"..."</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>This method can be used mapping any configuration setting (applicable during initial install) to its associated Marathon environment variable (applicable during reconfiguration).</p>

<h3 id="uninstall">
<a id="uninstall-1" class="anchor" href="#uninstall-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Uninstall</h3>

<p>The uninstall flow was simplified for users as of DC/OS 1.10. The steps to uninstall a service therefore depends on the version of DC/OS:</p>

<h4 id="dcos-110-and-newer">
<a id="dcos-110-and-newer" class="anchor" href="#dcos-110-and-newer" aria-hidden="true"><span class="octicon octicon-link"></span></a>DC/OS 1.10 and newer</h4>

<p>If you are using DC/OS 1.10 and the installed service has a version greater than 2.0.0-x:</p>

<ol>
  <li>Uninstall the service. From the DC/OS CLI, enter <code class="highlighter-rouge">dcos package uninstall --app-id=&lt;instancename&gt; &lt;packagename&gt;</code>.</li>
</ol>

<p>For example, to uninstall a Confluent Kafka instance named <code class="highlighter-rouge">kafka-dev</code>, run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dcos package uninstall <span class="nt">--app-id</span><span class="o">=</span>kafka-dev confluent-kafka
</code></pre></div></div>

<h4 id="older-versions">
<a id="older-versions" class="anchor" href="#older-versions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Older versions</h4>

<p>If you are running DC/OS 1.9 or older, or a version of the service that is older than 2.0.0-x, follow these steps:</p>

<ol>
  <li>Stop the service. From the DC/OS CLI, enter <code class="highlighter-rouge">dcos package uninstall --app-id=&lt;instancename&gt; &lt;packagename&gt;</code>.
For example, <code class="highlighter-rouge">dcos package uninstall --app-id=kafka-dev confluent-kafka</code>.</li>
  <li>Clean up remaining reserved resources with the <code class="highlighter-rouge">janitor.py</code> script. See <a href="https://docs.mesosphere.com/1.10/deploying-services/uninstall/#framework-cleaner">DC/OS documentation</a> for more information about the cleaner script.</li>
</ol>

<p>For example, to uninstall a Confluent Kafka instance named <code class="highlighter-rouge">kafka-dev</code>, run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ MY_SERVICE_NAME</span><span class="o">=</span>kafka-dev
<span class="nv">$ </span>dcos package uninstall <span class="nt">--app-id</span><span class="o">=</span><span class="nv">$MY_SERVICE_NAME</span> confluent-kafka<span class="sb">`</span><span class="nb">.</span>
<span class="nv">$ </span>dcos node ssh <span class="nt">--master-proxy</span> <span class="nt">--leader</span> <span class="s2">"docker run mesosphere/janitor /janitor.py </span><span class="se">\</span><span class="s2">
    -r </span><span class="nv">$MY_SERVICE_NAME</span><span class="s2">-role </span><span class="se">\</span><span class="s2">
    -p </span><span class="nv">$MY_SERVICE_NAME</span><span class="s2">-principal </span><span class="se">\</span><span class="s2">
    -z dcos-service-</span><span class="nv">$MY_SERVICE_NAME</span><span class="s2">"</span>
</code></pre></div></div>

<h3 id="pod-operations">
<a id="pod-operations" class="anchor" href="#pod-operations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pod operations</h3>

<p>Most operations for maintaining a service will involve interacting with and manipulating its <a href="#pods">Pods</a>.</p>

<h4 id="add-or-remove-a-pod">
<a id="add-or-remove-a-pod" class="anchor" href="#add-or-remove-a-pod" aria-hidden="true"><span class="octicon octicon-link"></span></a>Add or Remove a pod</h4>

<p>Adding or removing pod instances within the service is treated as a configuration change, not a command.</p>

<p>In this case, we’re increasing a pod count value, as provided by the service’s configuration schema. In the case of the above <code class="highlighter-rouge">dse</code> service, we need to increase the configured <code class="highlighter-rouge">dsenode.count</code> from <code class="highlighter-rouge">3</code> (the default) to <code class="highlighter-rouge">4</code>. After the change, the Scheduler will deploy a new DSE node instance without changing the preexisting nodes.</p>

<p>For safety reasons, pod instances cannot be removed after they have been deployed by default. However, some services may allow some pods to be removed in cases where doing so is not a problem. To remove pod instances, you would simply decrease the count value, and then instances exceeding that count will be removed automatically in reverse order. For example, if you decreased <code class="highlighter-rouge">dsenode.count</code> from <code class="highlighter-rouge">4</code> to <code class="highlighter-rouge">2</code> and this was allowed by the DSE service, you would see <code class="highlighter-rouge">dsenode-3</code> be removed followed by <code class="highlighter-rouge">dsenode-2</code>, leaving only <code class="highlighter-rouge">dsenode-0</code> and <code class="highlighter-rouge">dsenode-1</code> still running. If the DSE service doesn’t allow the number of instances to be decreased, the Scheduler would instead reject the decrease and show a validation error in its <a href="#status">deploy Plan</a>.</p>

<h4 id="restart-a-pod">
<a id="restart-a-pod" class="anchor" href="#restart-a-pod" aria-hidden="true"><span class="octicon octicon-link"></span></a>Restart a pod</h4>

<p>Restarting a pod keeps it in the current location and leaves data in any persistent volumes as-is. Data outside of those volumes is reset via the restart. Restarting a pod may be useful if an underlying process is broken in some way and just needs a kick to get working again. For more information see <a href="#recovery-plan">Recovery</a>.</p>

<p>Restarting a pod can be done either via the CLI or via the underlying Scheduler API. Both forms use the same <a href="http://mesosphere.github.io/dcos-commons/reference/swagger-api/">API</a>. In these examples we list the known pods, and then restart the one named <code class="highlighter-rouge">dse-1</code>, which contains tasks named <code class="highlighter-rouge">dse-1-agent</code> and <code class="highlighter-rouge">dse-1-node</code>:</p>

<p>Via the CLI:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos datastax-dse <span class="nt">--name</span><span class="o">=</span>mydse pod list
<span class="o">[</span>
  <span class="s2">"dse-0"</span>,
  <span class="s2">"dse-1"</span>,
  <span class="s2">"dse-2"</span>,
  <span class="s2">"opscenter-0"</span>,
  <span class="s2">"studio-0"</span>
<span class="o">]</span>
<span class="nv">$ </span>dcos datastax-dse <span class="nt">--name</span><span class="o">=</span>mydse pod restart dse-1
<span class="o">{</span>
  <span class="s2">"pod"</span>: <span class="s2">"dse-1"</span>,
  <span class="s2">"tasks"</span>: <span class="o">[</span>
    <span class="s2">"dse-1-agent"</span>,
    <span class="s2">"dse-1-node"</span>
  <span class="o">]</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Via the HTTP API directly:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>curl <span class="nt">-k</span> <span class="nt">-H</span> <span class="s2">"Authorization: token=</span><span class="k">$(</span>dcos config show core.dcos_acs_token<span class="k">)</span><span class="s2">"</span> &lt;dcos-url&gt;/service/dse/v1/pod
<span class="o">[</span>
  <span class="s2">"dse-0"</span>,
  <span class="s2">"dse-1"</span>,
  <span class="s2">"dse-2"</span>,
  <span class="s2">"opscenter-0"</span>,
  <span class="s2">"studio-0"</span>
<span class="o">]</span>
<span class="nv">$ </span>curl <span class="nt">-k</span> <span class="nt">-X</span> POST <span class="nt">-H</span> <span class="s2">"Authorization: token=</span><span class="k">$(</span>dcos config show core.dcos_acs_token<span class="k">)</span><span class="s2">"</span> &lt;dcos-url&gt;/service/dse/v1/pod/dse-1/restart
<span class="o">{</span>
  <span class="s2">"pod"</span>: <span class="s2">"dse-1"</span>,
  <span class="s2">"tasks"</span>: <span class="o">[</span>
    <span class="s2">"dse-1-agent"</span>,
    <span class="s2">"dse-1-node"</span>
  <span class="o">]</span>
<span class="o">}</span>
</code></pre></div></div>

<p>All tasks within the pod are restarted as a unit. The response lists the names of the two tasks that were members of the pod.</p>

<h4 id="replace-a-pod">
<a id="replace-a-pod" class="anchor" href="#replace-a-pod" aria-hidden="true"><span class="octicon octicon-link"></span></a>Replace a pod</h4>

<p>Replacing a pod discards all of its current data and moves it to a new random location in the cluster. As of this writing, you can technically end up replacing a pod and have it go back where it started. Replacing a pod may be useful if an agent machine has gone down and is never coming back, or if an agent is about to undergo downtime.</p>

<p>Pod replacement is not currently done automatically by the SDK, as making the correct decision requires operator knowledge of cluster status. Is a node really dead, or will it be back in a couple minutes? However, operators are free to build their own tooling to make this decision and invoke the replace call automatically. For more information see <a href="#recovery-plan">Recovery</a>.</p>

<p>As with restarting a pod, replacing a pod can be done either via the CLI or by directly invoking the HTTP API. The response lists all the tasks running in the pod which were replaced as a result:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos datastax-dse <span class="nt">--name</span><span class="o">=</span>mydse pod replace dse-1
<span class="o">{</span>
  <span class="s2">"pod"</span>: <span class="s2">"dse-1"</span>,
  <span class="s2">"tasks"</span>: <span class="o">[</span>
    <span class="s2">"dse-1-agent"</span>,
    <span class="s2">"dse-1-node"</span>
  <span class="o">]</span>
<span class="o">}</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>curl <span class="nt">-k</span> <span class="nt">-X</span> POST <span class="nt">-H</span> <span class="s2">"Authorization: token=</span><span class="k">$(</span>dcos config show core.dcos_acs_token<span class="k">)</span><span class="s2">"</span> http://yourcluster.com/service/dse/v1/pod/dse-1/replace
<span class="o">{</span>
  <span class="s2">"pod"</span>: <span class="s2">"dse-1"</span>,
  <span class="s2">"tasks"</span>: <span class="o">[</span>
    <span class="s2">"dse-1-agent"</span>,
    <span class="s2">"dse-1-node"</span>
  <span class="o">]</span>
<span class="o">}</span>
</code></pre></div></div>

<h4 id="pause-a-pod">
<a id="pause-a-pod" class="anchor" href="#pause-a-pod" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pause a pod</h4>

<p>Pausing a pod relaunches it in an idle command state. This allows the operator to debug the contents of the pod, possibly making changes to fix problems. While these problems are often fixed by just replacing the pod, there may be cases where an in-place repair or other operation is needed.</p>

<p>For example:</p>
<ul>
  <li>A pod which crashes immediately upon starting may need additional work to be performed.</li>
  <li>Some services may <em>require</em> that certain repair operations be performed manually when the task itself isn’t running.
Being able to put the pod in an offline but accessible state makes it easier to resolve these situations.</li>
</ul>

<p>After the pod has been paused, it may be started again, at which point it will be restarted and will resume running task(s) where it left off.</p>

<p>Here is an example session where an <code class="highlighter-rouge">index-1</code> pod is crash looping due to some corrupted data in a persistent volume. The operator pauses the <code class="highlighter-rouge">index-1</code> pod, then uses <code class="highlighter-rouge">task exec</code> to repair the index. Following this, the operator starts the pod and it resumes normal operation:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos myservice debug pod pause index-1
<span class="o">{</span>
  <span class="s2">"pod"</span>: <span class="s2">"index-1"</span>,
  <span class="s2">"tasks"</span>: <span class="o">[</span>
    <span class="s2">"index-1-agent"</span>,
    <span class="s2">"index-1-node"</span>
  <span class="o">]</span>
<span class="o">}</span>

<span class="nv">$ </span>dcos myservice pod status
myservice
├─ index
│  ├─ index-0
│  │  ├─ index-0-agent <span class="o">(</span>COMPLETE<span class="o">)</span>
│  │  └─ index-0-node <span class="o">(</span>COMPLETE<span class="o">)</span>
│  └─ index-1
│     ├─ index-1-agent <span class="o">(</span>PAUSING<span class="o">)</span>
│     └─ index-1-node <span class="o">(</span>PAUSING<span class="o">)</span>
└─ data
   ├─ data-0
   │  └─ data-0-node <span class="o">(</span>COMPLETE<span class="o">)</span>
   └─ data-1
      └─ data-1-node <span class="o">(</span>COMPLETE<span class="o">)</span>

... repeat <span class="s2">"pod status"</span> <span class="k">until </span>index-1 tasks are PAUSED ...

<span class="nv">$ </span>dcos task <span class="nb">exec</span> <span class="nt">--interactive</span> <span class="nt">--tty</span> index-1-node /bin/bash
index-1-node<span class="nv">$ </span>./repair-index <span class="o">&amp;&amp;</span> <span class="nb">exit</span>

<span class="nv">$ </span>dcos myservice debug pod resume index-1
<span class="o">{</span>
  <span class="s2">"pod"</span>: <span class="s2">"index-1"</span>,
  <span class="s2">"tasks"</span>: <span class="o">[</span>
    <span class="s2">"index-1-agent"</span>,
    <span class="s2">"index-1-node"</span>
  <span class="o">]</span>
<span class="o">}</span>

<span class="nv">$ </span>dcos myservice pod status
myservice
├─ index
│  ├─ index-0
│  │  ├─ index-0-agent <span class="o">(</span>RUNNING<span class="o">)</span>
│  │  └─ index-0-node <span class="o">(</span>RUNNING<span class="o">)</span>
│  └─ index-1
│     ├─ index-1-agent <span class="o">(</span>STARTING<span class="o">)</span>
│     └─ index-1-node <span class="o">(</span>STARTING<span class="o">)</span>
└─ data
   ├─ data-0
   │  └─ data-0-node <span class="o">(</span>RUNNING<span class="o">)</span>
   └─ data-1
      └─ data-1-node <span class="o">(</span>RUNNING<span class="o">)</span>

... repeat <span class="s2">"pod status"</span> <span class="k">until </span>index-1 tasks are RUNNING ...
</code></pre></div></div>

<p>In the above example, all tasks in the pod were being paused and started, but it’s worth noting that the commands also support pausing and starting individual tasks within a pod. For example, <code class="highlighter-rouge">dcos myservice debug pod pause index-1 -t agent</code> will pause only the <code class="highlighter-rouge">agent</code> task within the <code class="highlighter-rouge">index-1</code> pod.</p>

<h3 id="plan-operations">
<a id="plan-operations" class="anchor" href="#plan-operations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Plan Operations</h3>

<p>This lists available commands for viewing and manipulating the <a href="#plans">Plans</a> used by the Scheduler to perform work against the underlying service.</p>

<h4 id="list">
<a id="list" class="anchor" href="#list" aria-hidden="true"><span class="octicon octicon-link"></span></a>List</h4>
<p>Show all plans for this service.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dcos kakfa plan list
</code></pre></div></div>

<h4 id="status">
<a id="status" class="anchor" href="#status" aria-hidden="true"><span class="octicon octicon-link"></span></a>Status</h4>
<p>Display the status of the plan with the provided plan name.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dcos kafka plan status deploy
</code></pre></div></div>

<p><strong>Note:</strong> The <code class="highlighter-rouge">--json</code> flag, though not default, is helpful in extracting phase UUIDs. Using the UUID instead of name for a
phase is a more ensures that the request, ie to pause or force-complete, is exactly the phase intended.</p>

<h4 id="start">
<a id="start" class="anchor" href="#start" aria-hidden="true"><span class="octicon octicon-link"></span></a>Start</h4>
<p>Start the plan with the provided name and any optional plan arguments.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dcos kafka plan start deploy
</code></pre></div></div>

<h4 id="stop">
<a id="stop" class="anchor" href="#stop" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stop</h4>
<p>Stop the running plan with the provided name.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dcos kafka plan stop deploy
</code></pre></div></div>

<p>Plan Pause differs from Plan Stop in the following ways:</p>
<ul>
  <li>Pause can be issued for a specific phase or for all phases within a plan. Stop can only be issued for a plan.</li>
  <li>Pause updates the underlying Phase/Step state. Stop not only updates the underlying state, but also restarts the plan.</li>
</ul>

<h4 id="pause-1">
<a id="pause-1" class="anchor" href="#pause-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pause</h4>
<p>Pause the plan, or a specific phase in that plan with the provided phase name (or UUID).</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dcos kafka plan pause deploy 97e70976-505f-4689-abd2-6286c4499091
</code></pre></div></div>

<p><strong>NOTE:</strong> The UUID above is an example. Use the Plan Status command with the <code class="highlighter-rouge">--json</code> flag to extract a valid UUID.</p>

<p>Plan Pause differs from Plan Stop in the following ways:</p>
<ul>
  <li>Pause can be issued for a specific phase or for all phases within a plan. Stop can only be issued for a plan.</li>
  <li>Pause updates the underlying Phase/Step state. Stop not only updated the underlying state, but also restarts the plan.</li>
</ul>

<h4 id="resume-1">
<a id="resume-1" class="anchor" href="#resume-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Resume</h4>
<p>Resume the plan, or a specific phase in that plan, with the provided phase name (or UUID).</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dcos kafka plan resume deploy 97e70976-505f-4689-abd2-6286c4499091
</code></pre></div></div>

<h4 id="force-restart-1">
<a id="force-restart-1" class="anchor" href="#force-restart-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Force-Restart</h4>
<p>Restart the plan with the provided name, or a specific phase in the plan, with the provided nam, or a specific step in a
phase of the plan with the provided step name.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dcos kafka plan force-restart deploy
</code></pre></div></div>

<h4 id="force-complete-1">
<a id="force-complete-1" class="anchor" href="#force-complete-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Force-Complete</h4>
<p>Force complete a specific step in the provided phase. Example uses include the following: Abort a sidecar operation due
to observed failure or due to known required manual preparation that was not performed.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dcos kafka plan force-complete deploy
</code></pre></div></div>

<!--  disable mustache templating in this file: retain templated examples as-is -->

<h1 id="diagnostic-tools">
<a id="diagnostic-tools" class="anchor" href="#diagnostic-tools" aria-hidden="true"><span class="octicon octicon-link"></span></a>Diagnostic Tools</h1>
<p>DC/OS clusters provide several tools for diagnosing problems with services running in the cluster. In addition, the SDK has its own endpoints that describe what the Scheduler is doing at any given time.</p>

<h2 id="logging">
<a id="logging" class="anchor" href="#logging" aria-hidden="true"><span class="octicon octicon-link"></span></a>Logging</h2>

<p>The first step to diagnosing a problem is typically to take a look at the logs. Tasks do different things, so it takes some knowledge of the problem being diagnosed to determine which task logs are relevant.</p>

<p>As of this writing, the best and fastest way to view and download logs is via the Mesos UI at <code class="highlighter-rouge">&lt;dcos-url&gt;/mesos</code>. On the Mesos front page you will see two lists: A list of currently running tasks, followed by a list of completed tasks (whether successful or failed).</p>

<p><a href="img/ops-guide-all-tasks.png"><img src="img/ops-guide-all-tasks.png" alt="mesos frontpage showing all tasks in the cluster" width="400"></a></p>

<p>The <code class="highlighter-rouge">Sandbox</code> link for one of these tasks shows a list of files from within the task itself. For example, here’s a sandbox view of a <code class="highlighter-rouge">broker-2</code> task from the above list:</p>

<p><a href="img/ops-guide-task-sandbox.png"><img src="img/ops-guide-task-sandbox.png" alt="contents of a task sandbox" width="400"></a></p>

<p>If the task is based on a Docker image, this list will only show the contents of <code class="highlighter-rouge">/mnt/sandbox</code>, and not the rest of the filesystem. If you need to view filesystem contents outside of this directory, you will need to use <code class="highlighter-rouge">dcos task exec</code> or <code class="highlighter-rouge">nsenter</code> as described below under <a href="#running-commands-within-containers">Running commands within containers</a>.</p>

<p>In the above task list there are multiple services installed, resulting in a pretty large list. The list can be filtered using the text box at the upper right, but there may be duplicate names across services. For example there are two instances of <code class="highlighter-rouge">confluent-kafka</code> and they’re each running a <code class="highlighter-rouge">broker-0</code>. As the cluster grows, this confusion gets proportionally worse. We want to limit the task list to only the tasks that are relevant to the service being diagnosed. To do this, click “Frameworks” on the upper left to see a list of all the installed frameworks (mapping to our services):</p>

<p><a href="img/ops-guide-frameworks-list.png"><img src="img/ops-guide-frameworks-list.png" alt="listing of frameworks installed to the cluster" width="400"></a></p>

<p>We then need to decide which framework to select from this list. This depends on what task we want to view:</p>

<h3 id="scheduler-logs">
<a id="scheduler-logs" class="anchor" href="#scheduler-logs" aria-hidden="true"><span class="octicon octicon-link"></span></a>Scheduler logs</h3>

<p>If the issue is one of deployment or management, e.g. a service is ‘stuck’ in initial deployment, or a task that previously went down isn’t being brought back at all, then the Scheduler logs will likely be the place to find out why.</p>

<p>From Mesos’s perspective, the Scheduler is being run as a Marathon app. Therefore we should pick <code class="highlighter-rouge">marathon</code> from this list and then find our Scheduler in the list of tasks.</p>

<p><a href="img/ops-guide-framework-tasks-marathon.png"><img src="img/ops-guide-framework-tasks-marathon.png" alt="listing of tasks running in the marathon framework (Marathon apps)" width="400"></a></p>

<p>Scheduler logs can be found either via the main Mesos frontpage in small clusters (possibly using the filter box at the top right), or by navigating into the list of tasks registered against the <code class="highlighter-rouge">marathon</code> framework in large clusters. In SDK services, the Scheduler is typically given the same name as the service. For example a <code class="highlighter-rouge">kafka-dev</code> service’s Scheduler would be named <code class="highlighter-rouge">kafka-dev</code>. We click the <code class="highlighter-rouge">Sandbox</code> link to view the Sandbox portion of the Scheduler filesystem, which contains files named <code class="highlighter-rouge">stdout</code> and <code class="highlighter-rouge">stderr</code>. These files respectively receive the stdout/stderr output of the Scheduler process, and can be examined to see what the Scheduler is doing.</p>

<p><a href="img/ops-guide-scheduler-sandbox.png"><img src="img/ops-guide-scheduler-sandbox.png" alt="contents of a scheduler sandbox" width="400"></a></p>

<p>For a good example of the kind of diagnosis you can perform using SDK Scheduler logs, see the below use case of <a href="#tasks-not-deploying--resource-starvation">Tasks not deploying / Resource starvation</a>.</p>

<h3 id="task-logs">
<a id="task-logs" class="anchor" href="#task-logs" aria-hidden="true"><span class="octicon octicon-link"></span></a>Task logs</h3>

<p>When the issue being diagnosed has to do with the service tasks, e.g. a given task is crash looping, the task logs will likely provide more information. The tasks being run as a part of a service are registered against a framework matching the service name. Therefore, we should pick <code class="highlighter-rouge">&lt;service-name&gt;</code> from this list to view a list of tasks specific to that service.</p>

<p><a href="img/ops-guide-framework-tasks-service.png"><img src="img/ops-guide-framework-tasks-service.png" alt="listing of tasks running in a framework (Service tasks)" width="400"></a></p>

<p>In the above list, we see separate lists of Active and Completed tasks:</p>
<ul>
  <li>Active tasks are still running. These give a picture of the current activity of the service.</li>
  <li>Completed tasks have exited for some reason, whether successfully or due to a failure. These give a picture of recent activity of the service. <strong>Note:</strong> Older completed tasks will be automatically garbage collected and their data may no longer be available here.</li>
</ul>

<p>Either or both of these lists may be useful depending on the context. Click on the <code class="highlighter-rouge">Sandbox</code> link for one of these tasks and then start looking at sandbox content. Files named <code class="highlighter-rouge">stderr</code> and <code class="highlighter-rouge">stdout</code> hold logs produced both by the SDK Executor process (a small wrapper around the service task) as well as any logs produced by the task itself. These files are automatically paginated at 2MB increments, so older logs may also be examined until they are automatically pruned. For an example of this behavior, see the <a href="img/ops-guide-scheduler-sandbox.png">scheduler sandbox</a> linked earlier.</p>

<p><a href="img/ops-guide-task-sandbox.png"><img src="img/ops-guide-task-sandbox.png" alt="contents of a task sandbox" width="400"></a></p>

<h3 id="mesos-agent-logs">
<a id="mesos-agent-logs" class="anchor" href="#mesos-agent-logs" aria-hidden="true"><span class="octicon octicon-link"></span></a>Mesos Agent logs</h3>

<p>Occasionally, it can also be useful to examine what a given Mesos agent is doing. The Mesos Agent handles deployment of Mesos tasks to a given physical system in the cluster. One Mesos Agent runs on each system. These logs can be useful for determining if there’s a problem at the system level that is causing alerts across multiple services on that system.</p>

<p>Navigate to the agent you want to view either directly from a task by clicking the “Agent” item in the breadcrumb when viewing a task (this will go directly to the agent hosting the task), or by navigating through the “Agents” menu item at the top of the screen (you will need to select the desired agent from the list).</p>

<p>In the Agent view, you’ll see a list of frameworks with a presence on that Agent. In the left pane you’ll see a plain link named “LOG”. Click that link to view the agent logs.</p>

<p><a href="img/ops-guide-agent.png"><img src="img/ops-guide-agent.png" alt="view of tasks running on a given agent" width="400"></a></p>

<h3 id="logs-via-the-cli">
<a id="logs-via-the-cli" class="anchor" href="#logs-via-the-cli" aria-hidden="true"><span class="octicon octicon-link"></span></a>Logs via the CLI</h3>

<p>You can also access logs via the <a href="https://dcos.io/docs/latest/usage/cli/install/">DC/OS CLI</a> using the <code class="highlighter-rouge">dcos task log</code> command. For example, lets assume the following list of tasks in a cluster:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos task
NAME                  HOST        USER  STATE  ID
broker-0              10.0.0.242  root    R    broker-0__81f56cc1-7b3d-4003-8c21-a9cd45ea6a21
broker-0              10.0.3.27   root    R    broker-0__75bcf7fd-7831-4f70-9cb8-9cb6693f4237
broker-1              10.0.0.242  root    R    broker-1__6bf127ab-5edc-4888-9dd3-f00be92b291c
broker-1              10.0.1.188  root    R    broker-1__d799afdb-78bf-44e9-bb63-d16cfc797d00
broker-2              10.0.1.151  root    R    broker-2__4a293161-b89f-429e-a22e-57a1846eb271
broker-2              10.0.3.60   root    R    broker-2__76f45cb0-4db9-41ad-835c-2cedf3d7f725
<span class="o">[</span>...]
</code></pre></div></div>

<p>In this case we have two overlapping sets of brokers from two different Kafka installs. Given these tasks, we can do several different things by combining task filters, file selection, and the <code class="highlighter-rouge">--follow</code> argument:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos task log broker                <span class="c"># get recent stdout logs from all six 'broker-#' instances</span>
<span class="nv">$ </span>dcos task log broker-0              <span class="c"># get recent stdout logs from two 'broker-0' instances</span>
<span class="nv">$ </span>dcos task log broker-0__75          <span class="c"># get recent stdout logs from the 'broker-0' instance on 10.0.3.27</span>
<span class="nv">$ </span>dcos task log <span class="nt">--follow</span> broker-0__75 <span class="c"># 'tail -f' the stdout logs from that broker instance</span>
<span class="nv">$ </span>dcos task log broker-0__75 stderr   <span class="c"># get recent stderr logs from that broker instance</span>
</code></pre></div></div>

<h2 id="metrics">
<a id="metrics" class="anchor" href="#metrics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Metrics</h2>

<h3 id="dcos--111">
<a id="dcos--111" class="anchor" href="#dcos--111" aria-hidden="true"><span class="octicon octicon-link"></span></a>DC/OS &gt;= 1.11</h3>
<p>The scheduler’s metrics are reported via three different mechanisms: <code class="highlighter-rouge">JSON</code>, <a href="https://prometheus.io/">prometheus</a> and <a href="https://github.com/etsy/statsd">StatsD</a>. The StatsD metrics are pushed to the address defined by the environment variables <code class="highlighter-rouge">STATSD_UDP_HOST</code> and <code class="highlighter-rouge">STATSD_UDP_PORT</code>. See <a href="https://dcos.io/docs/1.10/metrics/">DC/OS Metrics documentation</a> for more details.</p>

<p>The JSON representation of the metrics is available at the <code class="highlighter-rouge">/v1/metrics</code> endpoint`.</p>

<p>####### JSON</p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
	</span><span class="s2">"version"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3.1.3"</span><span class="p">,</span><span class="w">
	</span><span class="s2">"gauges"</span><span class="p">:</span><span class="w"> </span><span class="p">{},</span><span class="w">
	</span><span class="s2">"counters"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
		</span><span class="s2">"declines.long"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
			</span><span class="s2">"count"</span><span class="p">:</span><span class="w"> </span><span class="mi">15</span><span class="w">
		</span><span class="p">},</span><span class="w">
		</span><span class="s2">"offers.processed"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
			</span><span class="s2">"count"</span><span class="p">:</span><span class="w"> </span><span class="mi">18</span><span class="w">
		</span><span class="p">},</span><span class="w">
		</span><span class="s2">"offers.received"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
			</span><span class="s2">"count"</span><span class="p">:</span><span class="w"> </span><span class="mi">18</span><span class="w">
		</span><span class="p">},</span><span class="w">
		</span><span class="s2">"operation.create"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
			</span><span class="s2">"count"</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="w">
		</span><span class="p">},</span><span class="w">
		</span><span class="s2">"operation.launch_group"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
			</span><span class="s2">"count"</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="w">
		</span><span class="p">},</span><span class="w">
		</span><span class="s2">"operation.reserve"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
			</span><span class="s2">"count"</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="w">
		</span><span class="p">},</span><span class="w">
		</span><span class="s2">"revives"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
			</span><span class="s2">"count"</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="w">
		</span><span class="p">},</span><span class="w">
		</span><span class="s2">"task_status.task_running"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
			</span><span class="s2">"count"</span><span class="p">:</span><span class="w"> </span><span class="mi">6</span><span class="w">
		</span><span class="p">}</span><span class="w">
	</span><span class="p">},</span><span class="w">
	</span><span class="s2">"histograms"</span><span class="p">:</span><span class="w"> </span><span class="p">{},</span><span class="w">
	</span><span class="s2">"meters"</span><span class="p">:</span><span class="w"> </span><span class="p">{},</span><span class="w">
	</span><span class="s2">"timers"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
		</span><span class="s2">"offers.process"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
			</span><span class="s2">"count"</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w">
			</span><span class="s2">"max"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.684745927</span><span class="p">,</span><span class="w">
			</span><span class="s2">"mean"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.15145255818999337</span><span class="p">,</span><span class="w">
			</span><span class="s2">"min"</span><span class="p">:</span><span class="w"> </span><span class="mf">5.367950000000001E-4</span><span class="p">,</span><span class="w">
			</span><span class="s2">"p50"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0035879090000000002</span><span class="p">,</span><span class="w">
			</span><span class="s2">"p75"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.40317217800000005</span><span class="p">,</span><span class="w">
			</span><span class="s2">"p95"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.684745927</span><span class="p">,</span><span class="w">
			</span><span class="s2">"p98"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.684745927</span><span class="p">,</span><span class="w">
			</span><span class="s2">"p99"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.684745927</span><span class="p">,</span><span class="w">
			</span><span class="s2">"p999"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.684745927</span><span class="p">,</span><span class="w">
			</span><span class="s2">"stddev"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.24017017290826104</span><span class="p">,</span><span class="w">
			</span><span class="s2">"m15_rate"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5944843686231079</span><span class="p">,</span><span class="w">
			</span><span class="s2">"m1_rate"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5250565015924039</span><span class="p">,</span><span class="w">
			</span><span class="s2">"m5_rate"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.583689104996544</span><span class="p">,</span><span class="w">
			</span><span class="s2">"mean_rate"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.3809369986002824</span><span class="p">,</span><span class="w">
			</span><span class="s2">"duration_units"</span><span class="p">:</span><span class="w"> </span><span class="s2">"seconds"</span><span class="p">,</span><span class="w">
			</span><span class="s2">"rate_units"</span><span class="p">:</span><span class="w"> </span><span class="s2">"calls/second"</span><span class="w">
		</span><span class="p">}</span><span class="w">
	</span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>The Prometheus representation of the metrics is available at the <code class="highlighter-rouge">/v1/metrics/prometheus</code> endpoint.
####### Prometheus</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># HELP declines_long Generated from Dropwizard metric import (metric=declines.long, type=com.codahale.metrics.Counter)
# TYPE declines_long gauge
declines_long 20.0
# HELP offers_processed Generated from Dropwizard metric import (metric=offers.processed, type=com.codahale.metrics.Counter)
# TYPE offers_processed gauge
offers_processed 24.0
# HELP offers_received Generated from Dropwizard metric import (metric=offers.received, type=com.codahale.metrics.Counter)
# TYPE offers_received gauge
offers_received 24.0
# HELP operation_create Generated from Dropwizard metric import (metric=operation.create, type=com.codahale.metrics.Counter)
# TYPE operation_create gauge
operation_create 5.0
# HELP operation_launch_group Generated from Dropwizard metric import (metric=operation.launch_group, type=com.codahale.metrics.Counter)
# TYPE operation_launch_group gauge
operation_launch_group 4.0
# HELP operation_reserve Generated from Dropwizard metric import (metric=operation.reserve, type=com.codahale.metrics.Counter)
# TYPE operation_reserve gauge
operation_reserve 20.0
# HELP revives Generated from Dropwizard metric import (metric=revives, type=com.codahale.metrics.Counter)
# TYPE revives gauge
revives 4.0
# HELP task_status_task_finished Generated from Dropwizard metric import (metric=task_status.task_finished, type=com.codahale.metrics.Counter)
# TYPE task_status_task_finished gauge
task_status_task_finished 1.0
# HELP task_status_task_running Generated from Dropwizard metric import (metric=task_status.task_running, type=com.codahale.metrics.Counter)
# TYPE task_status_task_running gauge
task_status_task_running 8.0
# HELP offers_process Generated from Dropwizard metric import (metric=offers.process, type=com.codahale.metrics.Timer)
# TYPE offers_process summary
offers_process{quantile="0.5",} 2.0609500000000002E-4
offers_process{quantile="0.75",} 2.2853200000000001E-4
offers_process{quantile="0.95",} 0.005792643
offers_process{quantile="0.98",} 0.005792643
offers_process{quantile="0.99",} 0.111950848
offers_process{quantile="0.999",} 0.396119612
offers_process_count 244.0
</code></pre></div></div>

<h2 id="running-commands-within-containers">
<a id="running-commands-within-containers" class="anchor" href="#running-commands-within-containers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Running commands within containers</h2>

<p>An extremely useful tool for diagnosing task state is the ability to run arbitrary commands <em>within</em> the task. The available tools for doing this depend on the version of DC/OS you’re using:</p>

<h3 id="dcos--19">
<a id="dcos--19" class="anchor" href="#dcos--19" aria-hidden="true"><span class="octicon octicon-link"></span></a>DC/OS &gt;= 1.9</h3>

<p>DC/OS 1.9 introduced the <code class="highlighter-rouge">task exec</code> command as a convenient frontend to <code class="highlighter-rouge">nsenter</code>, which is described below.</p>

<h4 id="prerequisites">
<a id="prerequisites-1" class="anchor" href="#prerequisites-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Prerequisites</h4>

<ul>
  <li>
    <p>SSH keys for accessing your cluster configured (i.e. via <code class="highlighter-rouge">ssh-add</code>). SSH is used behind the scenes to get into the cluster.</p>
  </li>
  <li>
    <p>A <a href="https://dcos.io/docs/latest/usage/cli/install/">recent version of the DC/OS CLI</a> with support for the <code class="highlighter-rouge">task exec</code> command.</p>
  </li>
</ul>

<h4 id="using-dcos-task-exec">
<a id="using-dcos-task-exec" class="anchor" href="#using-dcos-task-exec" aria-hidden="true"><span class="octicon octicon-link"></span></a>Using <code class="highlighter-rouge">dcos task exec</code>
</h4>

<p>Once you’re set up, running commands is very straightforward. For example, let’s assume the list of tasks from the CLI logs section above, where there’s two <code class="highlighter-rouge">broker-0</code> tasks, one named <code class="highlighter-rouge">broker-0__81f56cc1-7b3d-4003-8c21-a9cd45ea6a21</code> and another named <code class="highlighter-rouge">broker-0__75bcf7fd-7831-4f70-9cb8-9cb6693f4237</code>. Unlike with <code class="highlighter-rouge">task logs</code>, we can only run <code class="highlighter-rouge">task exec</code> on one command at a time, so if two tasks match the task filter then we see the following error:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos task <span class="nb">exec </span>broker-0 <span class="nb">echo </span>hello world
There are multiple tasks with ID matching <span class="o">[</span>broker-0]. Please choose one:
	broker-0__81f56cc1-7b3d-4003-8c21-a9cd45ea6a21
	broker-0__75bcf7fd-7831-4f70-9cb8-9cb6693f4237
</code></pre></div></div>

<p>Therefore we need to be more specific:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos task <span class="nb">exec </span>broker-0__75 <span class="nb">echo </span>hello world
hello world
<span class="nv">$ </span>dcos task <span class="nb">exec </span>broker-0__75 <span class="nb">pwd</span>
/
</code></pre></div></div>

<p>We can also run interactive commands using the <code class="highlighter-rouge">-it</code> flags (short for <code class="highlighter-rouge">--interactive --tty</code>):</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos task <span class="nb">exec</span> <span class="nt">--interactive</span> <span class="nt">--tty</span> broker-0__75 /bin/bash
broker-container# <span class="nb">echo </span>hello world
hello world
broker-container# <span class="nb">pwd</span>
/
broker-container# <span class="nb">exit</span>
</code></pre></div></div>

<p>While you could technically change the container filesystem using <code class="highlighter-rouge">dcos task exec</code>, any changes will be destroyed if the container restarts.</p>

<h3 id="dcos--18">
<a id="dcos--18" class="anchor" href="#dcos--18" aria-hidden="true"><span class="octicon octicon-link"></span></a>DC/OS &lt;= 1.8</h3>

<p>DC/OS 1.8 and earlier do not support <code class="highlighter-rouge">dcos task exec</code>, but <code class="highlighter-rouge">dcos node ssh</code> and <code class="highlighter-rouge">nsenter</code> may be used instead to get the same thing, with a little more effort.</p>

<p>First, run <code class="highlighter-rouge">dcos task</code> to get the list of tasks (and their respective IPs), and cross-reference that with <code class="highlighter-rouge">dcos node</code> to get the list of agents (and their respective IPs). For example:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos task
NAME                  HOST        USER  STATE  ID
broker-0              10.0.1.151  root    R    broker-0__81f56cc1-7b3d-4003-8c21-a9cd45ea6a21
broker-0              10.0.3.27   root    R    broker-0__75bcf7fd-7831-4f70-9cb8-9cb6693f4237
<span class="nv">$ </span>dcos node
 HOSTNAME       IP                         ID
10.0.0.242  10.0.0.242  2fb7eb4d-d4fc-44b8-ab44-c858f2233675-S0
10.0.1.151  10.0.1.151  2fb7eb4d-d4fc-44b8-ab44-c858f2233675-S1
10.0.1.188  10.0.1.188  2fb7eb4d-d4fc-44b8-ab44-c858f2233675-S2
...
</code></pre></div></div>

<p>In this case we’re interested in the <code class="highlighter-rouge">broker-0</code> on <code class="highlighter-rouge">10.0.1.151</code>. We can see that <code class="highlighter-rouge">broker-0</code>’s Mesos Agent has an ID of <code class="highlighter-rouge">2fb7eb4d-d4fc-44b8-ab44-c858f2233675-S1</code>. Let’s SSH into that machine using <code class="highlighter-rouge">dcos node ssh</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos node ssh <span class="nt">--master-proxy</span> <span class="nt">--mesos-id</span><span class="o">=</span>2fb7eb4d-d4fc-44b8-ab44-c858f2233675-S1
agent-system<span class="err">$</span>
</code></pre></div></div>

<p>Now that we’re logged into the host Agent machine, we need to find a relevant PID for the <code class="highlighter-rouge">broker-0</code> container. This can take some guesswork:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>agent-system<span class="nv">$ </span>ps aux | <span class="nb">grep</span> <span class="nt">-i</span> confluent
...
root      5772  0.6  3.3 6204460 520280 ?      Sl   Apr25   2:34 /var/lib/mesos/slave/slaves/2fb7eb4d-d4fc-44b8-ab44-c858f2233675-S0/frameworks/2fb7eb4d-d4fc-44b8-ab44-c858f2233675-0004/executors/broker-0__1eb65420-535e-477b-9ac1-797e79c15277/runs/f5377eac-3a87-4080-8b80-128434e42a25/jre1.8.0_121//bin/java ... kafka_confluent-3.2.0/config/server.properties
root      6059  0.7 10.3 6203432 1601008 ?     Sl   Apr25   2:43 /var/lib/mesos/slave/slaves/2fb7eb4d-d4fc-44b8-ab44-c858f2233675-S0/frameworks/2fb7eb4d-d4fc-44b8-ab44-c858f2233675-0003/executors/broker-1__8de30046-1016-4634-b43e-45fe7ede0817/runs/19982072-08c3-4be6-9af9-efcd3cc420d3/jre1.8.0_121//bin/java ... kafka_confluent-3.2.0/config/server.properties
...
</code></pre></div></div>

<p>As we can see above, there appear to be two likely candidates, one on PID 5772 and the other on PID 6059. The one on PID 5772 has mention of <code class="highlighter-rouge">broker-0</code> so that’s probably the one we want. Lets run the <code class="highlighter-rouge">nsenter</code> command using PID 6059:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>agent-system<span class="nv">$ </span><span class="nb">sudo </span>nsenter <span class="nt">--mount</span> <span class="nt">--uts</span> <span class="nt">--ipc</span> <span class="nt">--net</span> <span class="nt">--pid</span> <span class="nt">--target</span> 6059
broker-container#
</code></pre></div></div>

<p>Looks like we were successful! Now we can run commands inside this container to verify that it’s the one we really want, and then proceed with the diagnosis.</p>

<h2 id="querying-the-scheduler">
<a id="querying-the-scheduler" class="anchor" href="#querying-the-scheduler" aria-hidden="true"><span class="octicon octicon-link"></span></a>Querying the Scheduler</h2>

<p>The Scheduler exposes several HTTP endpoints that provide information on any current deployment as well as the Scheduler’s view of its tasks. For a full listing of HTTP endpoints, see the <a href="http://mesosphere.github.io/dcos-commons/reference/swagger-api/">API reference</a>. The Scheduler endpoints most useful to field diagnosis come from three sections:</p>

<ul>
  <li>
<strong>Plan</strong>: Describes any work that the Scheduler is currently doing, and what work it’s about to do. These endpoints also allow manually triggering Plan operations, or restarting them if they’re stuck.</li>
  <li>
<strong>Pods</strong>: Describes the tasks that the Scheduler has currently deployed. The full task info describing the task environment can be retrieved, as well as the last task status received from Mesos.</li>
  <li>
<strong>State</strong>: Access to other miscellaneous state information such as service-specific properties data.</li>
</ul>

<p>For full documentation of each command, see the <a href="https://mesosphere.github.io/dcos-commons/reference/swagger-api/">API Reference</a>. Here is an example of invoking one of these commands against a service named <code class="highlighter-rouge">hello-world</code> via <code class="highlighter-rouge">curl</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">export </span><span class="nv">AUTH_TOKEN</span><span class="o">=</span><span class="k">$(</span>dcos config show core.dcos_acs_token<span class="k">)</span>
<span class="nv">$ </span>curl <span class="nt">-k</span> <span class="nt">-H</span> <span class="s2">"Authorization: token=</span><span class="nv">$AUTH_TOKEN</span><span class="s2">"</span> https://&lt;dcos_url&gt;/service/hello-world/v1/plans/deploy
</code></pre></div></div>

<p>These endpoints may also be conveniently accessed using the SDK CLI after installing a service. See <code class="highlighter-rouge">dcos &lt;svcname&gt; -h</code> for a list of all commands. These are wrappers around the above API.</p>

<p>For example, let’s get a list of pods using the CLI, and then via the HTTP API:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos datastax-dse <span class="nt">--name</span><span class="o">=</span>mydse pod list
<span class="o">[</span>
  <span class="s2">"dse-0"</span>,
  <span class="s2">"dse-1"</span>,
  <span class="s2">"dse-2"</span>,
  <span class="s2">"opscenter-0"</span>,
  <span class="s2">"studio-0"</span>
<span class="o">]</span>
<span class="nv">$ </span>curl <span class="nt">-k</span> <span class="nt">-H</span> <span class="s2">"Authorization: token=</span><span class="k">$(</span>dcos config show core.dcos_acs_token<span class="k">)</span><span class="s2">"</span> &lt;dcos-url&gt;/service/dse/v1/pod
<span class="o">[</span>
  <span class="s2">"dse-0"</span>,
  <span class="s2">"dse-1"</span>,
  <span class="s2">"dse-2"</span>,
  <span class="s2">"opscenter-0"</span>,
  <span class="s2">"studio-0"</span>
<span class="o">]</span>
</code></pre></div></div>

<p>The <code class="highlighter-rouge">-v</code> (or <code class="highlighter-rouge">--verbose</code>) argument allows you to view and diagnose the underlying requests made by the CLI:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos datastax-dse <span class="nt">--name</span><span class="o">=</span>mydse <span class="nt">-v</span> pod list
2017/04/25 15:03:43 Running DC/OS CLI <span class="nb">command</span>: dcos config show core.dcos_url
2017/04/25 15:03:44 HTTP Query: GET https://yourcluster.com/service/dse/v1/pod
2017/04/25 15:03:44 Running DC/OS CLI <span class="nb">command</span>: dcos config show core.dcos_acs_token
2017/04/25 15:03:44 Running DC/OS CLI <span class="nb">command</span>: dcos config show core.ssl_verify
<span class="o">[</span>
  <span class="s2">"dse-0"</span>,
  <span class="s2">"dse-1"</span>,
  <span class="s2">"dse-2"</span>,
  <span class="s2">"opscenter-0"</span>,
  <span class="s2">"studio-0"</span>
<span class="o">]</span>
2017/04/25 15:03:44 Response: 200 OK <span class="o">(</span><span class="nt">-1</span> bytes<span class="o">)</span>
</code></pre></div></div>

<h2 id="zookeeperexhibitor">
<a id="zookeeperexhibitor" class="anchor" href="#zookeeperexhibitor" aria-hidden="true"><span class="octicon octicon-link"></span></a>ZooKeeper/Exhibitor</h2>

<p><strong>Break glass in case of emergency: This should only be used as a last resort. Modifying anything in ZooKeeper directly may cause your service to behave in inconsistent, even incomprehensible ways.</strong></p>

<p>DC/OS comes with Exhibitor, a commonly used frontend for viewing ZooKeeper. Exhibitor may be accessed at <code class="highlighter-rouge">&lt;dcos-url&gt;/exhibitor</code>. A given SDK service will have a node named <code class="highlighter-rouge">dcos-service-&lt;svcname&gt;</code> visible here. This is where the Scheduler puts its state, so that it isn’t lost if the Scheduler is restarted. In practice it’s far easier to access this information via the Scheduler API (or via the service CLI) as described earlier, but direct access using Exhibitor can be useful in situations where the Scheduler itself is unavailable or otherwise unable to serve requests.</p>

<p><a href="img/ops-guide-exhibitor-view-taskstatus.png"><img src="img/ops-guide-exhibitor-view-taskstatus.png" alt="viewing a task's most recent TaskStatus protobuf in Exhibitor" width="400"></a></p>

<h1 id="troubleshooting">
<a id="troubleshooting" class="anchor" href="#troubleshooting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Troubleshooting</h1>
<p>This section goes over some common pitfalls and how to fix them.</p>

<h2 id="tasks-not-deploying--resource-starvation">
<a id="tasks-not-deploying--resource-starvation" class="anchor" href="#tasks-not-deploying--resource-starvation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tasks not deploying / Resource starvation</h2>

<p>When the Scheduler is performing offer evaluation, it will log its decisions about offers it has received. This can be useful in the common case of determining why a task is failing to deploy.</p>

<p>In this example we have a newly-deployed <code class="highlighter-rouge">dse</code> Scheduler that isn’t deploying the third <code class="highlighter-rouge">dsenode</code> task that we requested. This can often happen if our cluster doesn’t have any machines with enough room to run the task.</p>

<p>In recent versions of the Scheduler, a Scheduler endpoint at <code class="highlighter-rouge">http://yourcluster.com/service/&lt;servicename&gt;/v1/debug/offers</code> will display an HTML table containing a summary of recently-evaluated offers. This table’s contents are currently very similar to what can be found in logs, but in a slightly more accessible format. Alternately, we can look at the Scheduler’s logs in <code class="highlighter-rouge">stdout</code> (or <code class="highlighter-rouge">stderr</code> in older SDK versions).</p>

<p>When looking at either the Offers debug endpoint, or at the Scheduler logs directly, we find several examples of offers that were insufficient to deploy the remaining node. It’s important to remember that <em>offers will regularly be rejected</em> due to not meeting the needs of a deployed task and that this is <em>completely normal</em>. What we’re looking for is a common theme across those rejections that would indicate what we’re missing.</p>

<p>From scrolling through the scheduler logs, we see a couple of patterns. First, there are failures like this, where the only thing missing is CPUs. The remaining task requires 2 CPUs but this offer apparently didn’t have enough:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO  2017-04-25 19:17:13,846 [pool-8-thread-1] com.mesosphere.sdk.offer.evaluate.OfferEvaluator:evaluate(69): Offer 1: failed 1 of 14 evaluation stages:
  PASS(PlacementRuleEvaluationStage): No placement rule defined
  PASS(ExecutorEvaluationStage): Offer contains the matching Executor ID
  PASS(ResourceEvaluationStage): Offer contains sufficient 'cpus': requirement=type: SCALAR scalar { value: 0.5 }
  PASS(ResourceEvaluationStage): Offer contains sufficient 'mem': requirement=type: SCALAR scalar { value: 500.0 }
  PASS(LaunchEvaluationStage): Added launch information to offer requirement
  FAIL(ResourceEvaluationStage): Failed to satisfy required resource 'cpus': name: "cpus" type: SCALAR scalar { value: 2.0 } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
  PASS(ResourceEvaluationStage): Offer contains sufficient 'mem': requirement=type: SCALAR scalar { value: 8000.0 }
  PASS(MultiEvaluationStage): All child stages passed
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 9042 end: 9042 } }
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 9160 end: 9160 } }
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 7000 end: 7000 } }
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 7001 end: 7001 } }
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 8609 end: 8609 } }
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 8182 end: 8182 } }
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 7199 end: 7199 } }
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 21621 end: 21621 } }
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 8983 end: 8983 } }
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 7077 end: 7077 } }
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 7080 end: 7080 } }
    PASS(PortEvaluationStage): Offer contains sufficient 'ports': requirement=type: RANGES ranges { range { begin: 7081 end: 7081 } }
  PASS(VolumeEvaluationStage): Offer contains sufficient 'disk'
  PASS(VolumeEvaluationStage): Offer contains sufficient 'disk'
  PASS(VolumeEvaluationStage): Offer contains sufficient 'disk'
  PASS(VolumeEvaluationStage): Offer contains sufficient 'disk'
  PASS(LaunchEvaluationStage): Added launch information to offer requirement
  PASS(ReservationEvaluationStage): Added reservation information to offer requirement
</code></pre></div></div>

<p>If we scroll up from this rejection summary, we find a message describing what the agent had offered in terms of CPU:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO  2017-04-25 19:17:13,834 [pool-8-thread-1] com.mesosphere.sdk.offer.MesosResourcePool:consumeUnreservedMerged(239): Offered quantity of cpus is insufficient: desired type: SCALAR scalar { value: 2.0 }, offered type: SCALAR scalar { value: 0.5 }
</code></pre></div></div>

<p>Understandably, our Scheduler is refusing to launch a DSE node on a system with 0.5 remaining CPUs when the DSE node needs 2.0 CPUs.</p>

<p>Another pattern we see is a message like this, where the offer is being rejected for several reasons:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>INFO  2017-04-25 19:17:14,849 [pool-8-thread-1] com.mesosphere.sdk.offer.evaluate.OfferEvaluator:evaluate(69): Offer 1: failed 6 of 14 evaluation stages:
  PASS(PlacementRuleEvaluationStage): No placement rule defined
  PASS(ExecutorEvaluationStage): Offer contains the matching Executor ID
  FAIL(ResourceEvaluationStage): Failed to satisfy required resource 'cpus': name: "cpus" type: SCALAR scalar { value: 0.5 } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
  PASS(ResourceEvaluationStage): Offer contains sufficient 'mem': requirement=type: SCALAR scalar { value: 500.0 }
  PASS(LaunchEvaluationStage): Added launch information to offer requirement
  FAIL(ResourceEvaluationStage): Failed to satisfy required resource 'cpus': name: "cpus" type: SCALAR scalar { value: 2.0 } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
  FAIL(ResourceEvaluationStage): Failed to satisfy required resource 'mem': name: "mem" type: SCALAR scalar { value: 8000.0 } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
  FAIL(MultiEvaluationStage): Failed to pass all child stages
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 9042 end: 9042 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 9160 end: 9160 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 7000 end: 7000 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 7001 end: 7001 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 8609 end: 8609 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 8182 end: 8182 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 7199 end: 7199 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 21621 end: 21621 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 8983 end: 8983 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 7077 end: 7077 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 7080 end: 7080 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
    FAIL(PortEvaluationStage): Failed to satisfy required resource 'ports': name: "ports" type: RANGES ranges { range { begin: 7081 end: 7081 } } role: "dse-role" reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
  FAIL(VolumeEvaluationStage): Failed to satisfy required volume 'disk': name: "disk" type: SCALAR scalar { value: 10240.0 } role: "dse-role" disk { persistence { id: "" principal: "dse-principal" } volume { container_path: "dse-data" mode: RW } } reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
  PASS(VolumeEvaluationStage): Offer contains sufficient 'disk'
  PASS(VolumeEvaluationStage): Offer contains sufficient 'disk'
  FAIL(VolumeEvaluationStage): Failed to satisfy required volume 'disk': name: "disk" type: SCALAR scalar { value: 10240.0 } role: "dse-role" disk { persistence { id: "" principal: "dse-principal" } volume { container_path: "solr-data" mode: RW } } reservation { principal: "dse-principal" labels { labels { key: "resource_id" value: "" } } }
  PASS(LaunchEvaluationStage): Added launch information to offer requirement
  PASS(ReservationEvaluationStage): Added reservation information to offer requirement
</code></pre></div></div>

<p>In this case, we see that none of the ports our DSE task needs are available on this system (not to mention the lack of sufficient CPU and RAM). This will typically happen when we’re looking at an agent that we’ve already deployed to. The agent in question here is likely running either <code class="highlighter-rouge">dsenode-0</code> or <code class="highlighter-rouge">dsenode-1</code>, where we had already reserved those ports ourselves.</p>

<p>We’re seeing that none of the remaining agents in the cluster have room to fit our <code class="highlighter-rouge">dsenode-2</code>. To resolve this, we need to either add more agents to the DC/OS cluster or we need to reduce the requirements of our service to make it fit. In the latter case, be aware of any performance issues that may result if resource usage is reduced too far. Insufficient CPU quota will result in throttled tasks, and insufficient RAM quota will result in OOMed tasks.</p>

<p>This is a good example of the kind of diagnosis you can perform by skimming the SDK Scheduler logs.</p>

<h2 id="accidentially-deleted-marathon-task-but-not-service">
<a id="accidentially-deleted-marathon-task-but-not-service" class="anchor" href="#accidentially-deleted-marathon-task-but-not-service" aria-hidden="true"><span class="octicon octicon-link"></span></a>Accidentially deleted Marathon task but not service</h2>

<p>A common user mistake is to remove the Scheduler task from Marathon, which doesn’t do anything to uninstall the service tasks themselves. If you do this, you have two options:</p>

<h3 id="uninstall-the-rest-of-the-service">
<a id="uninstall-the-rest-of-the-service" class="anchor" href="#uninstall-the-rest-of-the-service" aria-hidden="true"><span class="octicon octicon-link"></span></a>Uninstall the rest of the service</h3>

<p>If you really wanted to uninstall the service, you just need to complete the normal <code class="highlighter-rouge"><span class="k">package</span> <span class="n">uninstall</span></code> steps described under <a href="#uninstall">Uninstall</a>.</p>

<h3 id="recover-the-scheduler">
<a id="recover-the-scheduler" class="anchor" href="#recover-the-scheduler" aria-hidden="true"><span class="octicon octicon-link"></span></a>Recover the Scheduler</h3>

<p>If you want to bring the Scheduler back, you can do a <code class="highlighter-rouge">dcos package install</code> using the options that you had configured before. This will re-install a new Scheduler that should match the previous one (assuming you got your options right), and it will resume where it left off. To ensure that you don’t forget the options your services are configured with, we recommend keeping a copy of your service’s <code class="highlighter-rouge">options.json</code> in source control so that you can easily recover it later. See also <a href="#initial-service-configuration">Initial configuration</a>.</p>

<h2 id="framework-has-been-removed">
<a id="framework-has-been-removed" class="anchor" href="#framework-has-been-removed" aria-hidden="true"><span class="octicon octicon-link"></span></a>‘Framework has been removed’</h2>

<p>Long story short, you forgot to run <code class="highlighter-rouge">janitor.py</code> the last time you ran the service. See <a href="#uninstall">Uninstall</a> for steps on doing that. In case you’re curious, here’s what happened:</p>

<ol>
  <li>You ran <code class="highlighter-rouge">dcos package uninstall</code>. This destroyed the scheduler and its associated tasks, <em>but didn’t clean up its reserved resources</em>.</li>
  <li>Later on, you tried to reinstall the service. The Scheduler came up and found an entry in ZooKeeper with the previous framework ID, which would have been cleaned up by <code class="highlighter-rouge">janitor.py</code>. The Scheduler tried to re-register using that framework ID.</li>
  <li>Mesos returned an error because it knows that framework ID is no longer valid. Hence the confusing ‘Framework has been removed’ error.</li>
</ol>

<h2 id="stuck-deployments">
<a id="stuck-deployments" class="anchor" href="#stuck-deployments" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stuck deployments</h2>

<p>You can sometimes get into valid situations where a deployment is being blocked by a repair operation or vice versa. For example, say you were rolling out an update to a 500 node Cassandra cluster. The deployment gets paused at node #394 because it’s failing to come back, and, for whatever reason, we don’t have the time or the inclination to <code class="highlighter-rouge">pod replace</code> it and wait for it to come back.</p>

<p>In this case, we can use <code class="highlighter-rouge">plan</code> commands to force the Scheduler to skip node #394 and proceed with the rest of the deployment:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos cassandra plan status deploy
<span class="o">{</span>
  <span class="s2">"phases"</span>: <span class="o">[</span>
    <span class="o">{</span>
      <span class="s2">"id"</span>: <span class="s2">"aefd33e3-af78-425e-ad2e-6cc4b0bc1907"</span>,
      <span class="s2">"name"</span>: <span class="s2">"cassandra-phase"</span>,
      <span class="s2">"steps"</span>: <span class="o">[</span>
        ...
        <span class="o">{</span> <span class="s2">"id"</span>: <span class="s2">"f108a6a8-d41f-4c49-a1c0-4a8540876f6f"</span>, <span class="s2">"name"</span>: <span class="s2">"node-393:[node]"</span>, <span class="s2">"status"</span>: <span class="s2">"COMPLETE"</span> <span class="o">}</span>,
        <span class="o">{</span> <span class="s2">"id"</span>: <span class="s2">"83a7f8bc-f593-452a-9ceb-627d101da545"</span>, <span class="s2">"name"</span>: <span class="s2">"node-394:[node]"</span>, <span class="s2">"status"</span>: <span class="s2">"PENDING"</span> <span class="o">}</span>, <span class="c"># stuck here</span>
        <span class="o">{</span> <span class="s2">"id"</span>: <span class="s2">"61ce9d7d-b023-4a8a-9191-bfa261ace064"</span>, <span class="s2">"name"</span>: <span class="s2">"node-395:[node]"</span>, <span class="s2">"status"</span>: <span class="s2">"PENDING"</span> <span class="o">}</span>,
        ...
      <span class="o">]</span>,
      <span class="s2">"status"</span>: <span class="s2">"IN_PROGRESS"</span>
    <span class="o">}</span>,
    ...
  <span class="o">]</span>,
  <span class="s2">"errors"</span>: <span class="o">[]</span>,
  <span class="s2">"status"</span>: <span class="s2">"IN_PROGRESS"</span>
<span class="o">}</span>
<span class="nv">$ </span>dcos plan force deploy cassandra-phase node-394:[node]
<span class="o">{</span>
  <span class="s2">"message"</span>: <span class="s2">"Received cmd: forceComplete"</span>
<span class="o">}</span>
</code></pre></div></div>

<p>After forcing the <code class="highlighter-rouge">node-394:[node]</code> step, we can then see that the Plan shows it in a <code class="highlighter-rouge">COMPLETE</code> state, and that the Plan is proceeding with <code class="highlighter-rouge">node-395</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ dcos cassandra plan status deploy
{
  "phases": [
    {
      "id": "aefd33e3-af78-425e-ad2e-6cc4b0bc1907",
      "name": "cassandra-phase",
      "steps": [
        ...
        { "id": "f108a6a8-d41f-4c49-a1c0-4a8540876f6f", "name": "node-393:[node]", "status": "COMPLETE" },
        { "id": "83a7f8bc-f593-452a-9ceb-627d101da545", "name": "node-394:[node]", "status": "COMPLETE" },
        { "id": "61ce9d7d-b023-4a8a-9191-bfa261ace064", "name": "node-395:[node]", "status": "PENDING" },
        ...
      ],
      "status": "IN_PROGRESS"
    },
    ...
  ],
  "errors": [],
  "status": "IN_PROGRESS"
}
</code></pre></div></div>

<p>If we want to go back and fix the deployment of that node, we can simply force the scheduler to treat it as a pending operation again:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ dcos plan restart deploy cassandra-phase node-394:[node]
{
  "message": "Received cmd: restart"
}
</code></pre></div></div>

<p>Now, we see that the step is again marked as <code class="highlighter-rouge">PENDING</code> as the Scheduler again attempts to redeploy that node:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ dcos cassandra plan status deploy
{
  "phases": [
    {
      "id": "aefd33e3-af78-425e-ad2e-6cc4b0bc1907",
      "name": "cassandra-phase",
      "steps": [
        ...
        { "id": "f108a6a8-d41f-4c49-a1c0-4a8540876f6f", "name": "node-393:[node]", "status": "COMPLETE" },
        { "id": "83a7f8bc-f593-452a-9ceb-627d101da545", "name": "node-394:[node]", "status": "PENDING" },
        { "id": "61ce9d7d-b023-4a8a-9191-bfa261ace064", "name": "node-395:[node]", "status": "COMPLETE" },
        ...
      ],
      "status": "IN_PROGRESS"
    },
    ...
  ],
  "errors": [],
  "status": "IN_PROGRESS"
}
</code></pre></div></div>

<p>This example shows how steps in the deployment Plan (or any other Plan) can be manually retriggered or forced to a completed state by querying the Scheduler. This doesn’t come up often, but it can be a useful tool in certain situations.</p>

<p><strong>Note:</strong> The <code class="highlighter-rouge">dcos plan</code> commands will also accept UUID <code class="highlighter-rouge">id</code> values instead of the <code class="highlighter-rouge">name</code> values for the <code class="highlighter-rouge">phase</code> and <code class="highlighter-rouge">step</code> arguments. Providing UUIDs avoids the possibility of a race condition where we view the plan, then it changes structure, then we change a plan step that isn’t the same one we were expecting (but which had the same name).</p>

<h3 id="deleting-a-task-in-zookeeper-to-forcibly-wipe-that-task">
<a id="deleting-a-task-in-zookeeper-to-forcibly-wipe-that-task" class="anchor" href="#deleting-a-task-in-zookeeper-to-forcibly-wipe-that-task" aria-hidden="true"><span class="octicon octicon-link"></span></a>Deleting a task in ZooKeeper to forcibly wipe that task</h3>

<p>If the scheduler is still failing after <code class="highlighter-rouge">pod replace &lt;name&gt;</code> to clear a task, a last resort is to use <a href="#ZooKeeperexhibitor">Exhibitor</a> to delete the offending task from the Scheduler’s ZooKeeper state, and then to restart the Scheduler task in Marathon so that it picks up the change. After the Scheduler restarts, it will do the following:</p>
<ul>
  <li>Automatically unreserve the task’s previous resources with Mesos because it doesn’t recognize them anymore (via the Resource Cleanup operation described earlier).</li>
  <li>Automatically redeploy the task on a new agent.</li>
</ul>

<p><strong>Note:</strong> This operation can easily lead to a completely broken service. <strong>Do this at your own risk.</strong> <a href="img/ops-guide-exhibitor-delete-task.png">Break glass in case of emergency</a></p>

<h3 id="oomed-task">
<a id="oomed-task" class="anchor" href="#oomed-task" aria-hidden="true"><span class="octicon octicon-link"></span></a>OOMed task</h3>

<p>Your tasks can be killed from an OOM if you didn’t give them sufficient resources. This will manifest as sudden <code class="highlighter-rouge">Killed</code> messages in <a href="#task-logs">Task logs</a>, sometimes consistently but often not. To verify that the cause is an OOM, the following places can be checked:</p>
<ul>
  <li>Check <a href="#scheduler-logs">Scheduler logs</a> (or <code class="highlighter-rouge">dcos &lt;svcname&gt; pod status &lt;podname&gt;)</code> to see TaskStatus updates from mesos for a given failed pod.</li>
  <li>Check <a href="#mesos-agent-logs">Agent logs</a> directly for mention of the Mesos Agent killing a task due to excess memory usage.</li>
</ul>

<p>After you’ve been able to confirm that the problem is indeed an OOM, you can solve it by either <a href="#updating-service-configuration">updating the service configuration</a> to reserve more memory, or configuring the underlying service itself to use less memory (assuming the option is available).</p>


</div>
</div>
</body>

</html>
