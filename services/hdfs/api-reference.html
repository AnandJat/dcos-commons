<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">







<head>
<title>HDFS: API Reference</title>
<link rel="stylesheet" type="text/css" media="all" href="../../style/gh-basic.css" />
<link rel="shortcut icon" type="image/png" href="https://mesosphere.com/favicon.ico"/>
<!-- The Dropdown library is written by Stephen Morley, licensed CC0 1.0 Universal (Public Domain Dedication)-->
<link rel="stylesheet" type="text/css" media="all" href="../../style/Dropdown.css" />
<script src="../../style/Dropdown.js"></script>
<style type="text/css">
/* set the background color of menu items */
.dropdown, .dropdown ul { background: #555555; clear: both; }
/* set the background color of active items */
.dropdown li:hover > a, .dropdown li:hover > span, .dropdown li.dropdownOpen > a, .dropdown li.dropdownOpen > span { background: #af87e0; }
/* pad items, set their text color, and fade their background color */
.dropdown a, .dropdown span { padding: 0.25em 0.5em; color: white; transition: background 0.2s; }
/* show '+' on expandable items */
.dropdown span:after { content: " +"; }

/* toc style: remove extra margin between elements */
#markdown-toc ul { margin: 0; }
</style>
</head>

<body>
<div id="wrapper">

<a href="../..">
<img style="float: left; margin-bottom: 2em" src="https://mesosphere.com/wp-content/themes/mesosphere/library/images/assets/dcos-sdk-logo.png" width="250" alt="DC/OS Software Development Kit" />
</a>
<img style="float: right" src="https://img.shields.io/badge/Status-Alpha-BF97F0.svg?style=flat-square" alt="Status: Alpha" />

<ul class="dropdown" style="clear: both">
  <li>
    <a href="../..">Home</a>
  </li>
  <li>
    <span>Documentation</span>
    <ul>
      
      
      
      <li><a href="../../operations-guide.html">SDK Operations Guide</a></li>
      
      <li><a href="../../developer-guide.html">SDK Developer Guide</a></li>
      
      <li><a href="../../yaml-reference.html">YAML Reference</a></li>
      
      <li><a href="../../glossary.html">Glossary</a></li>
      
      <li><a href="../../faq.html">Frequently Asked Questions</a></li>
      
      <li><a href="../../ops-guide"></a></li>
      
      <li><a href="../../swagger-api">REST APIs</a></li>
      <li><a href="../../api">Javadoc Reference</a></li>
    </ul>
  </li>
  <li>
    <span>Tutorials</span>
    <ul>
      
      
      
      <li><a href="../../tutorials/data-store-tutorial.html">Data Store Tutorial</a></li>
      
      <li><a href="../../tutorials/kafka-tutorial.html">Kafka Tutorial</a></li>
      
      <li><a href="../../tutorials/automatic-repair.html">Automatic Repair</a></li>
      
      <li><a href="../../tutorials/quick-start-java.html">Quick Start (Java)</a></li>
      
    </ul>
  </li>
  <li>
    <span>Services</span>
    <ul>
      
      
      
      
      <li>
        
        <span>Elastic</span>
        
        <ul>
          
          
          <li><a href="../../services/elastic/install.html">Install and Customize</a></li>
          
          <li><a href="../../services/elastic/quick-start.html">Usage Example</a></li>
          
          <li><a href="../../services/elastic/upgrade.html">Upgrade</a></li>
          
          <li><a href="../../services/elastic/uninstall.html">Uninstall</a></li>
          
          <li><a href="../../services/elastic/configure.html">Configuring</a></li>
          
          <li><a href="../../services/elastic/x-pack.html">X-Pack</a></li>
          
          <li><a href="../../services/elastic/connecting.html">Connecting Clients</a></li>
          
          <li><a href="../../services/elastic/backup_restore.html">Backup and Restore</a></li>
          
          <li><a href="../../services/elastic/managing.html">Managing</a></li>
          
          <li><a href="../../services/elastic/api-reference.html">API Reference</a></li>
          
          <li><a href="../../services/elastic/troubleshooting.html">Troubleshooting</a></li>
          
          <li><a href="../../services/elastic/version_policy.html">Version Policy</a></li>
          
          <li><a href="../../services/elastic/limitations.html">Limitations</a></li>
          
          <li><a href="../../services/elastic/changelog.html">Changelog</a></li>
          
        </ul>
      </li>
      
      <li>
        
        <span>HDFS</span>
        
        <ul>
          
          
          <li><a href="../../services/hdfs/quick-start.html">Quickstart</a></li>
          
          <li><a href="../../services/hdfs/install.html">Install and Customize</a></li>
          
          <li><a href="../../services/hdfs/uninstall.html">Uninstall</a></li>
          
          <li><a href="../../services/hdfs/configure.html">Configuring</a></li>
          
          <li><a href="../../services/hdfs/connecting-clients.html">Connecting Clients</a></li>
          
          <li><a href="../../services/hdfs/limitations.html">Limitations</a></li>
          
          <li><a href="../../services/hdfs/managing.html">Managing</a></li>
          
          <li><a href="../../services/hdfs/api-reference.html">API Reference</a></li>
          
          <li><a href="../../services/hdfs/troubleshooting.html">Troubleshooting</a></li>
          
        </ul>
      </li>
      
      <li>
        
        <span>Kafka</span>
        
        <ul>
          
          
          <li><a href="../../services/kafka/install-and-customize.html">Install and Customize</a></li>
          
          <li><a href="../../services/kafka/quick-start.html">Quick Start</a></li>
          
          <li><a href="../../services/kafka/uninstall.html">Uninstall</a></li>
          
          <li><a href="../../services/kafka/configure.html">Configure</a></li>
          
          <li><a href="../../services/kafka/connecting-clients.html">Connecting Clients</a></li>
          
          <li><a href="../../services/kafka/managing.html">Managing</a></li>
          
          <li><a href="../../services/kafka/api-reference.html">API Reference</a></li>
          
          <li><a href="../../services/kafka/troubleshooting.html">Troubleshooting</a></li>
          
          <li><a href="../../services/kafka/version-policy.html">Version Policy</a></li>
          
          <li><a href="../../services/kafka/limitations.html">Limitations</a></li>
          
        </ul>
      </li>
      
    </ul>
  </li>
  <li><a href="https://github.com/mesosphere/dcos-commons/blob/master/CONTRIBUTING.md">Contributing</a></li>
  <li><a href="http://chat.dcos.io" target="_blank">Slack</a></li>
</ul>
<h1>HDFS: API Reference</h1>
<div id="content">
<!--  disable mustache templating in this file: retain templated examples as-is -->

<p>The DC/OS HDFS Service implements a REST API that may be accessed from outside the cluster. The <dcos_url> parameter referenced below indicates the base URL of the DC/OS cluster on which the HDFS Service is deployed.</dcos_url></p>

<p><a name="#rest-auth"></a></p>
<h1 id="rest-api-authentication">REST API Authentication</h1>
<p>REST API requests must be authenticated. This authentication is only applicable for interacting with the HDFS REST API directly. You do not need the token to access the HDFS nodes themselves.</p>

<p>If you are using Enterprise DC/OS, follow these instructions to <a href="https://docs.mesosphere.com/1.9/security/service-auth/custom-service-auth/">create a service account and an authentication token</a>. You can then configure your service to automatically refresh the authentication token when it expires. To get started more quickly, you can also <a href="https://docs.mesosphere.com/1.9/security/iam-api/">get the authentication token without a service account</a>, but you will need to manually refresh the token.</p>

<p>If you are using open source DC/OS, follow these instructions to <a href="https://dcos.io/docs/1.9/security/iam-api/">pass your HTTP API token to the DC/OS endpoint</a>.</p>

<p>Once you have the authentication token, you can store it in an environment variable and reference it in your REST API calls:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>export auth_token=uSeR_t0k3n
</code></pre>
</div>

<p>The <code class="highlighter-rouge">curl</code> examples in this document assume that an auth token has been stored in an environment variable named <code class="highlighter-rouge">auth_token</code>.</p>

<p>If you are using Enterprise DC/OS, the security mode of your installation may also require the <code class="highlighter-rouge">--ca-cert</code> flag when making REST calls. Refer to <a href="https://docs.mesosphere.com/1.9/networking/tls-ssl/#get-dcos-cert">Obtaining and passing the DC/OS certificate in cURL requests</a> for information on how to use the <code class="highlighter-rouge">--cacert</code> flag. <a href="https://docs.mesosphere.com/1.9/networking/tls-ssl/">If your security mode is <code class="highlighter-rouge">disabled</code></a>, do not use the <code class="highlighter-rouge">--ca-cert</code> flag.</p>

<h1 id="plan-api">Plan API</h1>
<p>The Plan API provides endpoints for monitoring and controlling service installation and configuration updates.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>curl -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/plans/deploy
</code></pre>
</div>
<h2 id="pause-installation">Pause Installation</h2>

<p>The installation will pause after completing installation of the current node and wait for user input.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>curl -X POST -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/plans/deploy/interrupt
</code></pre>
</div>

<h2 id="resume-installation">Resume Installation</h2>

<p>The REST API request below will resume installation at the next pending node.</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>curl -X PUT &lt;dcos_surl&gt;/service/hdfs/v1/plans/deploy/continue
</code></pre>
</div>

<h1 id="connection-api">Connection API</h1>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>curl -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> dcos_url/service/hdfs/v1/endpoints/hdfs-site.xml
</code></pre>
</div>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>curl -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/endpoints/core-site.xml
</code></pre>
</div>

<p>You will see a response similar to the following:</p>

<div class="language-xml highlighter-rouge"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.nameservice.id<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>hdfs<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.nameservices<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>hdfs<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.ha.namenodes.hdfs<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>name-0-node,name-1-node<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

    <span class="c">&lt;!-- namenode --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.shared.edits.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>qjournal://journal-0-node.hdfs.autoip.dcos.thisdcos.directory:8485;journal-1-node.hdfs.autoip.dcos.thisdcos.directory:8485;journal-2-node.hdfs.autoip.dcos.thisdcos.directory:8485/hdfs<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.name.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/name-data<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.safemode.threshold-pct<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.9<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.heartbeat.recheck-interval<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>60000<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.handler.count<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>20<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.invalidate.work.pct.per.iteration<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.95<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.replication.work.multiplier.per.iteration<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>4<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.datanode.registration.ip-hostname-check<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>false<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>


    <span class="c">&lt;!-- name-0-node --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-address.hdfs.name-0-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>name-0-node.hdfs.autoip.dcos.thisdcos.directory:9001<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-bind-host.hdfs.name-0-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.http-address.hdfs.name-0-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>name-0-node.hdfs.autoip.dcos.thisdcos.directory:9002<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.http-bind-host.hdfs.name-0-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>


    <span class="c">&lt;!-- name-1-node --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-address.hdfs.name-1-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>name-1-node.hdfs.autoip.dcos.thisdcos.directory:9001<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-bind-host.hdfs.name-1-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.http-address.hdfs.name-1-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>name-1-node.hdfs.autoip.dcos.thisdcos.directory:9002<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.http-bind-host.hdfs.name-1-node<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

    <span class="c">&lt;!-- journalnode --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.journalnode.rpc-address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0:8485<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.journalnode.http-address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0:8480<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.journalnode.edits.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/journal-data<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

    <span class="c">&lt;!-- datanode --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0:9003<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.http.address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0:9004<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.ipc.address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>0.0.0.0:9005<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.data.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/data-data<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.balance.bandwidthPerSec<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>41943040<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.handler.count<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>10<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

    <span class="c">&lt;!-- HA --&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>ha.zookeeper.quorum<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>master.mesos:2181<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.ha.fencing.methods<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>shell(/bin/true)<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.ha.automatic-failover.enabled<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>


    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.image.compress<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.image.compression.codec<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>org.apache.hadoop.io.compress.SnappyCodec<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.client.read.shortcircuit<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.client.read.shortcircuit.streams.cache.size<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>1000<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.client.read.shortcircuit.streams.cache.size.expiry.ms<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>1000<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.client.failover.proxy.provider.hdfs<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.domain.socket.path<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/var/lib/hadoop-hdfs/dn_socket<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.permissions.enabled<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>false<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;/configuration&gt;</span>
</code></pre>
</div>

<div class="language-xml highlighter-rouge"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</span>
<span class="cp">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.default.name<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>hdfs://hdfs<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.hue.hosts<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.hue.groups<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.root.hosts<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.root.groups<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.httpfs.groups<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.proxyuser.httpfs.hosts<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>*<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>ha.zookeeper.parent-znode<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/dcos-service-hdfs/hadoop-ha<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;/configuration&gt;</span>
</code></pre>
</div>
<p>The contents of the responses represent valid hdfs-site.xml and core-site.xml that can be used by clients to connect to the service.</p>

<h1 id="nodes-api">Nodes API</h1>

<p>The pods API provides endpoints for retrieving information about nodes, restarting them, and replacing them.</p>

<h2 id="list-nodes">List Nodes</h2>

<p>A list of available node ids can be retrieved by sending a GET request to <code class="highlighter-rouge">/v1/pods</code>:</p>

<p>CLI Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>dcos beta-hdfs pods list
</code></pre>
</div>

<p>HTTP Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>curl  -H "Authorization:token=$auth_token" &lt;dcos_url&gt;/service/hdfs/v1/pods
[
    "data-0",
    "data-1",
    "data-2",
    "journal-0",
    "journal-1",
    "journal-2",
    "name-0",
    "name-1",
    "zkfc-0",
    "zkfc-1"
]
</code></pre>
</div>

<h2 id="node-info">Node Info</h2>

<p>You can retrieve node information by sending a GET request to <code class="highlighter-rouge">/v1/pods/&lt;node-id&gt;/info</code>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>curl  -H "Authorization:token=$auth_token" &lt;dcos_url&gt;/service/hdfs/v1/pods/&lt;node-id&gt;/info
</code></pre>
</div>

<p>CLI Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>dcos beta-hdfs pods info journal-0
</code></pre>
</div>

<p>HTTP Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>curl  -H "Authorization:token=$auth_token" &lt;dcos_url&gt;/service/hdfs/v1/pods/journal-0/info
[{
	info: {
		name: "journal-0-node",
		taskId: {
			value: "journal-0-node__b31a70f4-73c5-4065-990c-76c0c704b8e4"
		},
		slaveId: {
			value: "0060634a-aa2b-4fcc-afa6-5569716b533a-S5"
		},
		resources: [{
			name: "cpus",
			type: "SCALAR",
			scalar: {
				value: 0.3
			},
			ranges: null,
			set: null,
			role: "hdfs-role",
			reservation: {
				principal: "hdfs-principal",
				labels: {
					labels: [{
						key: "resource_id",
						value: "4208f1ea-586f-4157-81fd-dfa0877e7472"
					}]
				}
			},
			disk: null,
			revocable: null,
			shared: null
		}, {
			name: "mem",
			type: "SCALAR",
			scalar: {
				value: 512
			},
			ranges: null,
			set: null,
			role: "hdfs-role",
			reservation: {
				principal: "hdfs-principal",
				labels: {
					labels: [{
						key: "resource_id",
						value: "a0be3c2c-3c7c-47ad-baa9-be81fb5d5f2e"
					}]
				}
			},
			disk: null,
			revocable: null,
			shared: null
		}, {
			name: "ports",
			type: "RANGES",
			scalar: null,
			ranges: {
				range: [{
					begin: 8480,
					end: 8480
				}, {
					begin: 8485,
					end: 8485
				}]
			},
			set: null,
			role: "hdfs-role",
			reservation: {
				principal: "hdfs-principal",
				labels: {
					labels: [{
						key: "resource_id",
						value: "d50b3deb-97c7-4960-89e5-ac4e508e4564"
					}]
				}
			},
			disk: null,
			revocable: null,
			shared: null
		}, {
			name: "disk",
			type: "SCALAR",
			scalar: {
				value: 5000
			},
			ranges: null,
			set: null,
			role: "hdfs-role",
			reservation: {
				principal: "hdfs-principal",
				labels: {
					labels: [{
						key: "resource_id",
						value: "3e624468-11fb-4fcf-9e67-ddb883b1718e"
					}]
				}
			},
			disk: {
				persistence: {
					id: "6bf7fcf1-ccdf-41a3-87ba-459162da1f03",
					principal: "hdfs-principal"
				},
				volume: {
					mode: "RW",
					containerPath: "journal-data",
					hostPath: null,
					image: null,
					source: null
				},
				source: null
			},
			revocable: null,
			shared: null
		}],
		executor: {
			type: null,
			executorId: {
				value: "journal__e42893b5-9d96-4dfb-8e85-8360d483a122"
			},
			frameworkId: null,
			command: {
				uris: [{
					value: "https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/executor.zip",
					executable: null,
					extract: null,
					cache: null,
					outputFile: null
				}, {
					value: "https://downloads.mesosphere.com/libmesos-bundle/libmesos-bundle-1.9-argus-1.1.x-2.tar.gz",
					executable: null,
					extract: null,
					cache: null,
					outputFile: null
				}, {
					value: "https://downloads.mesosphere.com/java/jre-8u112-linux-x64-jce-unlimited.tar.gz",
					executable: null,
					extract: null,
					cache: null,
					outputFile: null
				}, {
					value: "https://downloads.mesosphere.com/hdfs/assets/hadoop-2.6.0-cdh5.9.1-dcos.tar.gz",
					executable: null,
					extract: null,
					cache: null,
					outputFile: null
				}, {
					value: "https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/bootstrap.zip",
					executable: null,
					extract: null,
					cache: null,
					outputFile: null
				}, {
					value: "http://api.hdfs.marathon.l4lb.thisdcos.directory/v1/artifacts/template/25f791d8-4d42-458f-84fb-9d82842ffb3e/journal/node/core-site",
					executable: null,
					extract: false,
					cache: null,
					outputFile: "config-templates/core-site"
				}, {
					value: "http://api.hdfs.marathon.l4lb.thisdcos.directory/v1/artifacts/template/25f791d8-4d42-458f-84fb-9d82842ffb3e/journal/node/hdfs-site",
					executable: null,
					extract: false,
					cache: null,
					outputFile: "config-templates/hdfs-site"
				}, {
					value: "http://api.hdfs.marathon.l4lb.thisdcos.directory/v1/artifacts/template/25f791d8-4d42-458f-84fb-9d82842ffb3e/journal/node/hadoop-metrics2",
					executable: null,
					extract: false,
					cache: null,
					outputFile: "config-templates/hadoop-metrics2"
				}],
				environment: null,
				shell: null,
				value: "export LD_LIBRARY_PATH=$MESOS_SANDBOX/libmesos-bundle/lib:$LD_LIBRARY_PATH &amp;&amp; export MESOS_NATIVE_JAVA_LIBRARY=$(ls $MESOS_SANDBOX/libmesos-bundle/lib/libmesos-*.so) &amp;&amp; export JAVA_HOME=$(ls -d $MESOS_SANDBOX/jre*/) &amp;&amp; ./executor/bin/executor",
				arguments: [],
				user: null
			},
			container: null,
			resources: [],
			name: "journal",
			source: null,
			data: null,
			discovery: null,
			shutdownGracePeriod: null,
			labels: null
		},
		command: {
			uris: [],
			environment: {
				variables: [{
					name: "PERMISSIONS_ENABLED",
					value: "false"
				}, {
					name: "DATA_NODE_BALANCE_BANDWIDTH_PER_SEC",
					value: "41943040"
				}, {
					name: "NAME_NODE_HANDLER_COUNT",
					value: "20"
				}, {
					name: "CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE",
					value: "1000"
				}, {
					name: "HADOOP_ROOT_LOGGER",
					value: "INFO,console"
				}, {
					name: "HA_FENCING_METHODS",
					value: "shell(/bin/true)"
				}, {
					name: "SERVICE_ZK_ROOT",
					value: "dcos-service-hdfs"
				}, {
					name: "HADOOP_PROXYUSER_HUE_GROUPS",
					value: "*"
				}, {
					name: "NAME_NODE_HEARTBEAT_RECHECK_INTERVAL",
					value: "60000"
				}, {
					name: "HADOOP_PROXYUSER_HUE_HOSTS",
					value: "*"
				}, {
					name: "CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS",
					value: "1000"
				}, {
					name: "JOURNAL_NODE_RPC_PORT",
					value: "8485"
				}, {
					name: "CLIENT_FAILOVER_PROXY_PROVIDER_HDFS",
					value: "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"
				}, {
					name: "DATA_NODE_HANDLER_COUNT",
					value: "10"
				}, {
					name: "HA_AUTOMATIC_FAILURE",
					value: "true"
				}, {
					name: "JOURNALNODE",
					value: "true"
				}, {
					name: "NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION",
					value: "4"
				}, {
					name: "HADOOP_PROXYUSER_HTTPFS_HOSTS",
					value: "*"
				}, {
					name: "POD_INSTANCE_INDEX",
					value: "0"
				}, {
					name: "DATA_NODE_IPC_PORT",
					value: "9005"
				}, {
					name: "JOURNAL_NODE_HTTP_PORT",
					value: "8480"
				}, {
					name: "NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK",
					value: "false"
				}, {
					name: "TASK_USER",
					value: "root"
				}, {
					name: "journal-0-node",
					value: "true"
				}, {
					name: "HADOOP_PROXYUSER_ROOT_GROUPS",
					value: "*"
				}, {
					name: "TASK_NAME",
					value: "journal-0-node"
				}, {
					name: "HADOOP_PROXYUSER_ROOT_HOSTS",
					value: "*"
				}, {
					name: "IMAGE_COMPRESS",
					value: "true"
				}, {
					name: "CLIENT_READ_SHORTCIRCUIT",
					value: "true"
				}, {
					name: "FRAMEWORK_NAME",
					value: "hdfs"
				}, {
					name: "IMAGE_COMPRESSION_CODEC",
					value: "org.apache.hadoop.io.compress.SnappyCodec"
				}, {
					name: "NAME_NODE_SAFEMODE_THRESHOLD_PCT",
					value: "0.9"
				}, {
					name: "NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION",
					value: "0.95"
				}, {
					name: "HADOOP_PROXYUSER_HTTPFS_GROUPS",
					value: "*"
				}, {
					name: "CLIENT_READ_SHORTCIRCUIT_PATH",
					value: "/var/lib/hadoop-hdfs/dn_socket"
				}, {
					name: "DATA_NODE_HTTP_PORT",
					value: "9004"
				}, {
					name: "DATA_NODE_RPC_PORT",
					value: "9003"
				}, {
					name: "NAME_NODE_HTTP_PORT",
					value: "9002"
				}, {
					name: "NAME_NODE_RPC_PORT",
					value: "9001"
				}, {
					name: "CONFIG_TEMPLATE_CORE_SITE",
					value: "config-templates/core-site,hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml"
				}, {
					name: "CONFIG_TEMPLATE_HDFS_SITE",
					value: "config-templates/hdfs-site,hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml"
				}, {
					name: "CONFIG_TEMPLATE_HADOOP_METRICS2",
					value: "config-templates/hadoop-metrics2,hadoop-2.6.0-cdh5.9.1/etc/hadoop/hadoop-metrics2.properties"
				}, {
					name: "PORT_JOURNAL_RPC",
					value: "8485"
				}, {
					name: "PORT_JOURNAL_HTTP",
					value: "8480"
				}]
			},
			shell: null,
			value: "./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs journalnode",
			arguments: [],
			user: null
		},
		container: null,
		healthCheck: null,
		killPolicy: null,
		data: null,
		labels: {
			labels: [{
				key: "goal_state",
				value: "RUNNING"
			}, {
				key: "offer_attributes",
				value: ""
			}, {
				key: "task_type",
				value: "journal"
			}, {
				key: "index",
				value: "0"
			}, {
				key: "offer_hostname",
				value: "10.0.1.23"
			}, {
				key: "target_configuration",
				value: "4bdb3f97-96b0-4e78-8d47-f39edc33f6e3"
			}]
		},
		discovery: null
	},
	status: {
		taskId: {
			value: "journal-0-node__b31a70f4-73c5-4065-990c-76c0c704b8e4"
		},
		state: "TASK_RUNNING",
		message: "Reconciliation: Latest task state",
		source: "SOURCE_MASTER",
		reason: "REASON_RECONCILIATION",
		data: null,
		slaveId: {
			value: "0060634a-aa2b-4fcc-afa6-5569716b533a-S5"
		},
		executorId: null,
		timestamp: 1486694618.923135,
		uuid: null,
		healthy: null,
		labels: null,
		containerStatus: {
			containerId: {
				value: "a4c8433f-2648-4ba7-a8b8-5fe5df20e8af",
				parent: null
			},
			networkInfos: [{
				ipAddresses: [{
					protocol: null,
					ipAddress: "10.0.1.23"
				}],
				name: null,
				groups: [],
				labels: null,
				portMappings: []
			}],
			cgroupInfo: null,
			executorPid: 5594
		},
		unreachableTime: null
	}
}]
</code></pre>
</div>

<h2 id="replace-a-node">Replace a Node</h2>

<p>The replace endpoint can be used to replace a node with an instance running on another agent node.</p>

<p>CLI Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>dcos beta-hdfs pods replace &lt;node-id&gt;
</code></pre>
</div>

<p>HTTP Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>curl -X POST -H "Authorization:token=$auth_token" &lt;dcos_url&gt;/service/hdfs/v1/pods/&lt;node-id&gt;/replace
</code></pre>
</div>

<p>If the operation succeeds, a <code class="highlighter-rouge">200 OK</code> is returned.</p>

<h2 id="restart-a-node">Restart a Node</h2>

<p>The restart endpoint can be used to restart a node in place on the same agent node.</p>

<p>CLI Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>dcos beta-hdfs pods restart &lt;node-id&gt;
</code></pre>
</div>

<p>HTTP Example</p>
<div class="language-bash highlighter-rouge"><pre class="highlight"><code>curl -X POST -H <span class="s2">"Authorization:token=</span><span class="nv">$auth_token</span><span class="s2">"</span> &lt;dcos_url&gt;/service/hdfs/v1/pods/&lt;node-id&gt;/restart
</code></pre>
</div>

<p>If the operation succeeds a <code class="highlighter-rouge">200 OK</code> is returned.</p>

<h1 id="configuration-api">Configuration API</h1>

<p>The configuration API provides an endpoint to view current and previous configurations of the cluster.</p>

<h2 id="view-target-config">View Target Config</h2>

<p>You can view the current target configuration by sending a GET request to <code class="highlighter-rouge">/v1/configurations/target</code>.</p>

<p>CLI Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>dcos beta-hdfs config target
</code></pre>
</div>

<p>HTTP Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>curl -H "Authorization:token=$auth_token" &lt;dcos_url&gt;/service/hdfs/v1/configurations/target
{
	name: "hdfs",
	role: "hdfs-role",
	principal: "hdfs-principal",
	api - port: 10002,
	web - url: null,
	zookeeper: "master.mesos:2181",
	pod - specs: [{
		type: "journal",
		user: null,
		count: 3,
		container: null,
		uris: [
			"https://downloads.mesosphere.com/hdfs/assets/hadoop-2.6.0-cdh5.9.1-dcos.tar.gz",
			"https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/bootstrap.zip"
		],
		task - specs: [{
			name: "node",
			goal: "RUNNING",
			resource - set: {
				id: "node-resource-set",
				resource - specifications: [{
					@type: "DefaultResourceSpec",
					name: "cpus",
					value: {
						type: "SCALAR",
						scalar: {
							value: 0.3
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "DefaultResourceSpec",
					name: "mem",
					value: {
						type: "SCALAR",
						scalar: {
							value: 512
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "PortsSpec",
					name: "ports",
					value: {
						type: "RANGES",
						scalar: null,
						ranges: {
							range: [{
								begin: 8485,
								end: 8485
							}, {
								begin: 8480,
								end: 8480
							}]
						},
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					port - specs: [{
						@type: "PortSpec",
						name: "ports",
						value: {
							type: "RANGES",
							scalar: null,
							ranges: {
								range: [{
									begin: 8485,
									end: 8485
								}]
							},
							set: null,
							text: null
						},
						role: "hdfs-role",
						principal: "hdfs-principal",
						port - name: "journal-rpc",
						envKey: null
					}, {
						@type: "PortSpec",
						name: "ports",
						value: {
							type: "RANGES",
							scalar: null,
							ranges: {
								range: [{
									begin: 8480,
									end: 8480
								}]
							},
							set: null,
							text: null
						},
						role: "hdfs-role",
						principal: "hdfs-principal",
						port - name: "journal-http",
						envKey: null
					}],
					envKey: null
				}],
				volume - specifications: [{
					@type: "DefaultVolumeSpec",
					type: "ROOT",
					container - path: "journal-data",
					name: "disk",
					value: {
						type: "SCALAR",
						scalar: {
							value: 5000
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: "DISK_SIZE"
				}],
				role: "hdfs-role",
				principal: "hdfs-principal"
			},
			command - spec: {
				value: "./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs journalnode",
				environment: {
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
					CLIENT_READ_SHORTCIRCUIT: "true",
					CLIENT_READ_SHORTCIRCUIT_PATH: "/var/lib/hadoop-hdfs/dn_socket",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: "1000",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: "1000",
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: "41943040",
					DATA_NODE_HANDLER_COUNT: "10",
					DATA_NODE_HTTP_PORT: "9004",
					DATA_NODE_IPC_PORT: "9005",
					DATA_NODE_RPC_PORT: "9003",
					HADOOP_PROXYUSER_HTTPFS_GROUPS: "*",
					HADOOP_PROXYUSER_HTTPFS_HOSTS: "*",
					HADOOP_PROXYUSER_HUE_GROUPS: "*",
					HADOOP_PROXYUSER_HUE_HOSTS: "*",
					HADOOP_PROXYUSER_ROOT_GROUPS: "*",
					HADOOP_PROXYUSER_ROOT_HOSTS: "*",
					HADOOP_ROOT_LOGGER: "INFO,console",
					HA_AUTOMATIC_FAILURE: "true",
					HA_FENCING_METHODS: "shell(/bin/true)",
					IMAGE_COMPRESS: "true",
					IMAGE_COMPRESSION_CODEC: "org.apache.hadoop.io.compress.SnappyCodec",
					JOURNALNODE: "true",
					JOURNAL_NODE_HTTP_PORT: "8480",
					JOURNAL_NODE_RPC_PORT: "8485",
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: "false",
					NAME_NODE_HANDLER_COUNT: "20",
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: "60000",
					NAME_NODE_HTTP_PORT: "9002",
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: "0.95",
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: "4",
					NAME_NODE_RPC_PORT: "9001",
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: "0.9",
					PERMISSIONS_ENABLED: "false",
					SERVICE_ZK_ROOT: "dcos-service-hdfs",
					TASK_USER: "root"
				}
			},
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: [{
				name: "core-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "
			}, {
				name: "hdfs-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:$1@$0](.*)s/.*/{{TASK_USER}}/ RULE:[1:$1@$0](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "
			}, {
				name: "hadoop-metrics2",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/hadoop-metrics2.properties",
				template - content: "# Autogenerated by the Mesos Framework, DO NOT EDIT *.sink.statsd.class=org.apache.hadoop.metrics2.sink.StatsDSink journalnode.sink.statsd.period=10 journalnode.sink.statsd.server.host={{STATSD_UDP_HOST}} journalnode.sink.statsd.server.port={{STATSD_UDP_PORT}} journalnode.sink.statsd.skip.hostname=false"
			}]
		}],
		placement - rule: {
			@type: "AndRule",
			rules: [{
				@type: "TaskTypeRule",
				type: "journal",
				converter: {
					@type: "TaskTypeLabelConverter"
				},
				behavior: "AVOID"
			}, {
				@type: "TaskTypeRule",
				type: "name",
				converter: {
					@type: "TaskTypeLabelConverter"
				},
				behavior: "AVOID"
			}]
		}
	}, {
		type: "name",
		user: null,
		count: 2,
		container: null,
		uris: [
			"https://downloads.mesosphere.com/hdfs/assets/hadoop-2.6.0-cdh5.9.1-dcos.tar.gz",
			"https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/bootstrap.zip"
		],
		task - specs: [{
			name: "node",
			goal: "RUNNING",
			resource - set: {
				id: "name-resources",
				resource - specifications: [{
					@type: "DefaultResourceSpec",
					name: "cpus",
					value: {
						type: "SCALAR",
						scalar: {
							value: 0.3
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "DefaultResourceSpec",
					name: "mem",
					value: {
						type: "SCALAR",
						scalar: {
							value: 512
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "PortsSpec",
					name: "ports",
					value: {
						type: "RANGES",
						scalar: null,
						ranges: {
							range: [{
								begin: 9001,
								end: 9001
							}, {
								begin: 9002,
								end: 9002
							}]
						},
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					port - specs: [{
						@type: "PortSpec",
						name: "ports",
						value: {
							type: "RANGES",
							scalar: null,
							ranges: {
								range: [{
									begin: 9001,
									end: 9001
								}]
							},
							set: null,
							text: null
						},
						role: "hdfs-role",
						principal: "hdfs-principal",
						port - name: "name-rpc",
						envKey: null
					}, {
						@type: "PortSpec",
						name: "ports",
						value: {
							type: "RANGES",
							scalar: null,
							ranges: {
								range: [{
									begin: 9002,
									end: 9002
								}]
							},
							set: null,
							text: null
						},
						role: "hdfs-role",
						principal: "hdfs-principal",
						port - name: "name-http",
						envKey: null
					}],
					envKey: null
				}],
				volume - specifications: [{
					@type: "DefaultVolumeSpec",
					type: "ROOT",
					container - path: "name-data",
					name: "disk",
					value: {
						type: "SCALAR",
						scalar: {
							value: 5000
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: "DISK_SIZE"
				}],
				role: "hdfs-role",
				principal: "hdfs-principal"
			},
			command - spec: {
				value: "./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs namenode",
				environment: {
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
					CLIENT_READ_SHORTCIRCUIT: "true",
					CLIENT_READ_SHORTCIRCUIT_PATH: "/var/lib/hadoop-hdfs/dn_socket",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: "1000",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: "1000",
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: "41943040",
					DATA_NODE_HANDLER_COUNT: "10",
					DATA_NODE_HTTP_PORT: "9004",
					DATA_NODE_IPC_PORT: "9005",
					DATA_NODE_RPC_PORT: "9003",
					FRAMEWORK_NAME: "",
					HADOOP_PROXYUSER_HTTPFS_GROUPS: "*",
					HADOOP_PROXYUSER_HTTPFS_HOSTS: "*",
					HADOOP_PROXYUSER_HUE_GROUPS: "*",
					HADOOP_PROXYUSER_HUE_HOSTS: "*",
					HADOOP_PROXYUSER_ROOT_GROUPS: "*",
					HADOOP_PROXYUSER_ROOT_HOSTS: "*",
					HADOOP_ROOT_LOGGER: "INFO,console",
					HA_AUTOMATIC_FAILURE: "true",
					HA_FENCING_METHODS: "shell(/bin/true)",
					IMAGE_COMPRESS: "true",
					IMAGE_COMPRESSION_CODEC: "org.apache.hadoop.io.compress.SnappyCodec",
					JOURNAL_NODE_HTTP_PORT: "8480",
					JOURNAL_NODE_RPC_PORT: "8485",
					NAMENODE: "true",
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: "false",
					NAME_NODE_HANDLER_COUNT: "20",
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: "60000",
					NAME_NODE_HTTP_PORT: "9002",
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: "0.95",
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: "4",
					NAME_NODE_RPC_PORT: "9001",
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: "0.9",
					PERMISSIONS_ENABLED: "false",
					SERVICE_ZK_ROOT: "dcos-service-hdfs",
					TASK_USER: "root"
				}
			},
			health - check - spec: null,
			readiness - check - spec: {
				command: "./hadoop-2.6.0-cdh5.9.1/bin/hdfs haadmin -getServiceState name-$POD_INSTANCE_INDEX-node",
				delay: 0,
				interval: 5,
				timeout: 60
			},
			config - files: [{
				name: "core-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "
			}, {
				name: "hdfs-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:$1@$0](.*)s/.*/{{TASK_USER}}/ RULE:[1:$1@$0](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "
			}, {
				name: "hadoop-metrics2",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/hadoop-metrics2.properties",
				template - content: "# Autogenerated by the Mesos Framework, DO NOT EDIT *.sink.statsd.class=org.apache.hadoop.metrics2.sink.StatsDSink namenode.sink.statsd.period=10 namenode.sink.statsd.server.host={{STATSD_UDP_HOST}} namenode.sink.statsd.server.port={{STATSD_UDP_PORT}} namenode.sink.statsd.skip.hostname=false"
			}]
		}, {
			name: "format",
			goal: "FINISHED",
			resource - set: {
				id: "name-resources",
				resource - specifications: [{
					@type: "DefaultResourceSpec",
					name: "cpus",
					value: {
						type: "SCALAR",
						scalar: {
							value: 0.3
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "DefaultResourceSpec",
					name: "mem",
					value: {
						type: "SCALAR",
						scalar: {
							value: 512
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "PortsSpec",
					name: "ports",
					value: {
						type: "RANGES",
						scalar: null,
						ranges: {
							range: [{
								begin: 9001,
								end: 9001
							}, {
								begin: 9002,
								end: 9002
							}]
						},
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					port - specs: [{
						@type: "PortSpec",
						name: "ports",
						value: {
							type: "RANGES",
							scalar: null,
							ranges: {
								range: [{
									begin: 9001,
									end: 9001
								}]
							},
							set: null,
							text: null
						},
						role: "hdfs-role",
						principal: "hdfs-principal",
						port - name: "name-rpc",
						envKey: null
					}, {
						@type: "PortSpec",
						name: "ports",
						value: {
							type: "RANGES",
							scalar: null,
							ranges: {
								range: [{
									begin: 9002,
									end: 9002
								}]
							},
							set: null,
							text: null
						},
						role: "hdfs-role",
						principal: "hdfs-principal",
						port - name: "name-http",
						envKey: null
					}],
					envKey: null
				}],
				volume - specifications: [{
					@type: "DefaultVolumeSpec",
					type: "ROOT",
					container - path: "name-data",
					name: "disk",
					value: {
						type: "SCALAR",
						scalar: {
							value: 5000
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: "DISK_SIZE"
				}],
				role: "hdfs-role",
				principal: "hdfs-principal"
			},
			command - spec: {
				value: "./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs namenode -format",
				environment: {
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
					CLIENT_READ_SHORTCIRCUIT: "true",
					CLIENT_READ_SHORTCIRCUIT_PATH: "/var/lib/hadoop-hdfs/dn_socket",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: "1000",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: "1000",
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: "41943040",
					DATA_NODE_HANDLER_COUNT: "10",
					DATA_NODE_HTTP_PORT: "9004",
					DATA_NODE_IPC_PORT: "9005",
					DATA_NODE_RPC_PORT: "9003",
					FRAMEWORK_NAME: "",
					HADOOP_PROXYUSER_HTTPFS_GROUPS: "*",
					HADOOP_PROXYUSER_HTTPFS_HOSTS: "*",
					HADOOP_PROXYUSER_HUE_GROUPS: "*",
					HADOOP_PROXYUSER_HUE_HOSTS: "*",
					HADOOP_PROXYUSER_ROOT_GROUPS: "*",
					HADOOP_PROXYUSER_ROOT_HOSTS: "*",
					HADOOP_ROOT_LOGGER: "INFO,console",
					HA_AUTOMATIC_FAILURE: "true",
					HA_FENCING_METHODS: "shell(/bin/true)",
					IMAGE_COMPRESS: "true",
					IMAGE_COMPRESSION_CODEC: "org.apache.hadoop.io.compress.SnappyCodec",
					JOURNAL_NODE_HTTP_PORT: "8480",
					JOURNAL_NODE_RPC_PORT: "8485",
					NAMENODE: "true",
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: "false",
					NAME_NODE_HANDLER_COUNT: "20",
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: "60000",
					NAME_NODE_HTTP_PORT: "9002",
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: "0.95",
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: "4",
					NAME_NODE_RPC_PORT: "9001",
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: "0.9",
					PERMISSIONS_ENABLED: "false",
					SERVICE_ZK_ROOT: "dcos-service-hdfs",
					TASK_USER: "root"
				}
			},
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: [{
				name: "core-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "
			}, {
				name: "hdfs-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:$1@$0](.*)s/.*/{{TASK_USER}}/ RULE:[1:$1@$0](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "
			}]
		}, {
			name: "bootstrap",
			goal: "FINISHED",
			resource - set: {
				id: "name-resources",
				resource - specifications: [{
					@type: "DefaultResourceSpec",
					name: "cpus",
					value: {
						type: "SCALAR",
						scalar: {
							value: 0.3
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "DefaultResourceSpec",
					name: "mem",
					value: {
						type: "SCALAR",
						scalar: {
							value: 512
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "PortsSpec",
					name: "ports",
					value: {
						type: "RANGES",
						scalar: null,
						ranges: {
							range: [{
								begin: 9001,
								end: 9001
							}, {
								begin: 9002,
								end: 9002
							}]
						},
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					port - specs: [{
						@type: "PortSpec",
						name: "ports",
						value: {
							type: "RANGES",
							scalar: null,
							ranges: {
								range: [{
									begin: 9001,
									end: 9001
								}]
							},
							set: null,
							text: null
						},
						role: "hdfs-role",
						principal: "hdfs-principal",
						port - name: "name-rpc",
						envKey: null
					}, {
						@type: "PortSpec",
						name: "ports",
						value: {
							type: "RANGES",
							scalar: null,
							ranges: {
								range: [{
									begin: 9002,
									end: 9002
								}]
							},
							set: null,
							text: null
						},
						role: "hdfs-role",
						principal: "hdfs-principal",
						port - name: "name-http",
						envKey: null
					}],
					envKey: null
				}],
				volume - specifications: [{
					@type: "DefaultVolumeSpec",
					type: "ROOT",
					container - path: "name-data",
					name: "disk",
					value: {
						type: "SCALAR",
						scalar: {
							value: 5000
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: "DISK_SIZE"
				}],
				role: "hdfs-role",
				principal: "hdfs-principal"
			},
			command - spec: {
				value: "./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs namenode -bootstrapStandby",
				environment: {
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
					CLIENT_READ_SHORTCIRCUIT: "true",
					CLIENT_READ_SHORTCIRCUIT_PATH: "/var/lib/hadoop-hdfs/dn_socket",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: "1000",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: "1000",
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: "41943040",
					DATA_NODE_HANDLER_COUNT: "10",
					DATA_NODE_HTTP_PORT: "9004",
					DATA_NODE_IPC_PORT: "9005",
					DATA_NODE_RPC_PORT: "9003",
					FRAMEWORK_NAME: "",
					HADOOP_PROXYUSER_HTTPFS_GROUPS: "*",
					HADOOP_PROXYUSER_HTTPFS_HOSTS: "*",
					HADOOP_PROXYUSER_HUE_GROUPS: "*",
					HADOOP_PROXYUSER_HUE_HOSTS: "*",
					HADOOP_PROXYUSER_ROOT_GROUPS: "*",
					HADOOP_PROXYUSER_ROOT_HOSTS: "*",
					HADOOP_ROOT_LOGGER: "INFO,console",
					HA_AUTOMATIC_FAILURE: "true",
					HA_FENCING_METHODS: "shell(/bin/true)",
					IMAGE_COMPRESS: "true",
					IMAGE_COMPRESSION_CODEC: "org.apache.hadoop.io.compress.SnappyCodec",
					JOURNAL_NODE_HTTP_PORT: "8480",
					JOURNAL_NODE_RPC_PORT: "8485",
					NAMENODE: "true",
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: "false",
					NAME_NODE_HANDLER_COUNT: "20",
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: "60000",
					NAME_NODE_HTTP_PORT: "9002",
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: "0.95",
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: "4",
					NAME_NODE_RPC_PORT: "9001",
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: "0.9",
					PERMISSIONS_ENABLED: "false",
					SERVICE_ZK_ROOT: "dcos-service-hdfs",
					TASK_USER: "root"
				}
			},
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: [{
				name: "core-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "
			}, {
				name: "hdfs-bootstrap-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:$1@$0](.*)s/.*/{{TASK_USER}}/ RULE:[1:$1@$0](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "
			}]
		}],
		placement - rule: {
			@type: "AndRule",
			rules: [{
				@type: "TaskTypeRule",
				type: "name",
				converter: {
					@type: "TaskTypeLabelConverter"
				},
				behavior: "AVOID"
			}, {
				@type: "TaskTypeRule",
				type: "journal",
				converter: {
					@type: "TaskTypeLabelConverter"
				},
				behavior: "AVOID"
			}]
		}
	}, {
		type: "zkfc",
		user: null,
		count: 2,
		container: null,
		uris: [
			"https://downloads.mesosphere.com/hdfs/assets/hadoop-2.6.0-cdh5.9.1-dcos.tar.gz",
			"https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/bootstrap.zip"
		],
		task - specs: [{
			name: "node",
			goal: "RUNNING",
			resource - set: {
				id: "zkfc-resources",
				resource - specifications: [{
					@type: "DefaultResourceSpec",
					name: "cpus",
					value: {
						type: "SCALAR",
						scalar: {
							value: 0.3
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "DefaultResourceSpec",
					name: "mem",
					value: {
						type: "SCALAR",
						scalar: {
							value: 512
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}],
				volume - specifications: [],
				role: "hdfs-role",
				principal: "hdfs-principal"
			},
			command - spec: {
				value: "./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs zkfc",
				environment: {
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
					CLIENT_READ_SHORTCIRCUIT: "true",
					CLIENT_READ_SHORTCIRCUIT_PATH: "/var/lib/hadoop-hdfs/dn_socket",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: "1000",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: "1000",
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: "41943040",
					DATA_NODE_HANDLER_COUNT: "10",
					DATA_NODE_HTTP_PORT: "9004",
					DATA_NODE_IPC_PORT: "9005",
					DATA_NODE_RPC_PORT: "9003",
					HADOOP_PROXYUSER_HTTPFS_GROUPS: "*",
					HADOOP_PROXYUSER_HTTPFS_HOSTS: "*",
					HADOOP_PROXYUSER_HUE_GROUPS: "*",
					HADOOP_PROXYUSER_HUE_HOSTS: "*",
					HADOOP_PROXYUSER_ROOT_GROUPS: "*",
					HADOOP_PROXYUSER_ROOT_HOSTS: "*",
					HADOOP_ROOT_LOGGER: "INFO,console",
					HA_AUTOMATIC_FAILURE: "true",
					HA_FENCING_METHODS: "shell(/bin/true)",
					IMAGE_COMPRESS: "true",
					IMAGE_COMPRESSION_CODEC: "org.apache.hadoop.io.compress.SnappyCodec",
					JOURNAL_NODE_HTTP_PORT: "8480",
					JOURNAL_NODE_RPC_PORT: "8485",
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: "false",
					NAME_NODE_HANDLER_COUNT: "20",
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: "60000",
					NAME_NODE_HTTP_PORT: "9002",
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: "0.95",
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: "4",
					NAME_NODE_RPC_PORT: "9001",
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: "0.9",
					PERMISSIONS_ENABLED: "false",
					SERVICE_ZK_ROOT: "dcos-service-hdfs",
					TASK_USER: "root",
					ZKFC: "true"
				}
			},
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: [{
				name: "core-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "
			}, {
				name: "hdfs-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:$1@$0](.*)s/.*/{{TASK_USER}}/ RULE:[1:$1@$0](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "
			}]
		}, {
			name: "format",
			goal: "FINISHED",
			resource - set: {
				id: "zkfc-resources",
				resource - specifications: [{
					@type: "DefaultResourceSpec",
					name: "cpus",
					value: {
						type: "SCALAR",
						scalar: {
							value: 0.3
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "DefaultResourceSpec",
					name: "mem",
					value: {
						type: "SCALAR",
						scalar: {
							value: 512
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}],
				volume - specifications: [],
				role: "hdfs-role",
				principal: "hdfs-principal"
			},
			command - spec: {
				value: "./bootstrap &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs zkfc -formatZK",
				environment: {
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
					CLIENT_READ_SHORTCIRCUIT: "true",
					CLIENT_READ_SHORTCIRCUIT_PATH: "/var/lib/hadoop-hdfs/dn_socket",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: "1000",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: "1000",
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: "41943040",
					DATA_NODE_HANDLER_COUNT: "10",
					DATA_NODE_HTTP_PORT: "9004",
					DATA_NODE_IPC_PORT: "9005",
					DATA_NODE_RPC_PORT: "9003",
					HADOOP_PROXYUSER_HTTPFS_GROUPS: "*",
					HADOOP_PROXYUSER_HTTPFS_HOSTS: "*",
					HADOOP_PROXYUSER_HUE_GROUPS: "*",
					HADOOP_PROXYUSER_HUE_HOSTS: "*",
					HADOOP_PROXYUSER_ROOT_GROUPS: "*",
					HADOOP_PROXYUSER_ROOT_HOSTS: "*",
					HADOOP_ROOT_LOGGER: "INFO,console",
					HA_AUTOMATIC_FAILURE: "true",
					HA_FENCING_METHODS: "shell(/bin/true)",
					IMAGE_COMPRESS: "true",
					IMAGE_COMPRESSION_CODEC: "org.apache.hadoop.io.compress.SnappyCodec",
					JOURNAL_NODE_HTTP_PORT: "8480",
					JOURNAL_NODE_RPC_PORT: "8485",
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: "false",
					NAME_NODE_HANDLER_COUNT: "20",
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: "60000",
					NAME_NODE_HTTP_PORT: "9002",
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: "0.95",
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: "4",
					NAME_NODE_RPC_PORT: "9001",
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: "0.9",
					PERMISSIONS_ENABLED: "false",
					SERVICE_ZK_ROOT: "dcos-service-hdfs",
					TASK_USER: "root",
					ZKFC: "true"
				}
			},
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: [{
				name: "core-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "
			}, {
				name: "hdfs-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:$1@$0](.*)s/.*/{{TASK_USER}}/ RULE:[1:$1@$0](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "
			}]
		}],
		placement - rule: {
			@type: "AndRule",
			rules: [{
				@type: "TaskTypeRule",
				type: "zkfc",
				converter: {
					@type: "TaskTypeLabelConverter"
				},
				behavior: "AVOID"
			}, {
				@type: "TaskTypeRule",
				type: "name",
				converter: {
					@type: "TaskTypeLabelConverter"
				},
				behavior: "COLOCATE"
			}]
		}
	}, {
		type: "data",
		user: null,
		count: 3,
		container: null,
		uris: [
			"https://downloads.mesosphere.com/hdfs/assets/hadoop-2.6.0-cdh5.9.1-dcos.tar.gz",
			"https://downloads.mesosphere.com/hdfs/assets/1.0.0-2.6.0/bootstrap.zip"
		],
		task - specs: [{
			name: "node",
			goal: "RUNNING",
			resource - set: {
				id: "node-resource-set",
				resource - specifications: [{
					@type: "DefaultResourceSpec",
					name: "cpus",
					value: {
						type: "SCALAR",
						scalar: {
							value: 0.3
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "DefaultResourceSpec",
					name: "mem",
					value: {
						type: "SCALAR",
						scalar: {
							value: 512
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: null
				}, {
					@type: "PortsSpec",
					name: "ports",
					value: {
						type: "RANGES",
						scalar: null,
						ranges: {
							range: [{
								begin: 9003,
								end: 9003
							}, {
								begin: 9004,
								end: 9004
							}, {
								begin: 9005,
								end: 9005
							}]
						},
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					port - specs: [{
						@type: "PortSpec",
						name: "ports",
						value: {
							type: "RANGES",
							scalar: null,
							ranges: {
								range: [{
									begin: 9003,
									end: 9003
								}]
							},
							set: null,
							text: null
						},
						role: "hdfs-role",
						principal: "hdfs-principal",
						port - name: "data-rpc",
						envKey: null
					}, {
						@type: "PortSpec",
						name: "ports",
						value: {
							type: "RANGES",
							scalar: null,
							ranges: {
								range: [{
									begin: 9004,
									end: 9004
								}]
							},
							set: null,
							text: null
						},
						role: "hdfs-role",
						principal: "hdfs-principal",
						port - name: "data-http",
						envKey: null
					}, {
						@type: "PortSpec",
						name: "ports",
						value: {
							type: "RANGES",
							scalar: null,
							ranges: {
								range: [{
									begin: 9005,
									end: 9005
								}]
							},
							set: null,
							text: null
						},
						role: "hdfs-role",
						principal: "hdfs-principal",
						port - name: "data-ipc",
						envKey: null
					}],
					envKey: null
				}],
				volume - specifications: [{
					@type: "DefaultVolumeSpec",
					type: "ROOT",
					container - path: "data-data",
					name: "disk",
					value: {
						type: "SCALAR",
						scalar: {
							value: 5000
						},
						ranges: null,
						set: null,
						text: null
					},
					role: "hdfs-role",
					principal: "hdfs-principal",
					envKey: "DISK_SIZE"
				}],
				role: "hdfs-role",
				principal: "hdfs-principal"
			},
			command - spec: {
				value: "./bootstrap &amp;&amp; mkdir -p /var/lib/hadoop-hdfs &amp;&amp; chown root /var/lib/hadoop-hdfs &amp;&amp; ./hadoop-2.6.0-cdh5.9.1/bin/hdfs datanode ",
				environment: {
					CLIENT_FAILOVER_PROXY_PROVIDER_HDFS: "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider",
					CLIENT_READ_SHORTCIRCUIT: "true",
					CLIENT_READ_SHORTCIRCUIT_PATH: "/var/lib/hadoop-hdfs/dn_socket",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE: "1000",
					CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS: "1000",
					DATANODE: "true",
					DATA_NODE_BALANCE_BANDWIDTH_PER_SEC: "41943040",
					DATA_NODE_HANDLER_COUNT: "10",
					DATA_NODE_HTTP_PORT: "9004",
					DATA_NODE_IPC_PORT: "9005",
					DATA_NODE_RPC_PORT: "9003",
					FRAMEWORK_NAME: "",
					HADOOP_PROXYUSER_HTTPFS_GROUPS: "*",
					HADOOP_PROXYUSER_HTTPFS_HOSTS: "*",
					HADOOP_PROXYUSER_HUE_GROUPS: "*",
					HADOOP_PROXYUSER_HUE_HOSTS: "*",
					HADOOP_PROXYUSER_ROOT_GROUPS: "*",
					HADOOP_PROXYUSER_ROOT_HOSTS: "*",
					HADOOP_ROOT_LOGGER: "INFO,console",
					HA_AUTOMATIC_FAILURE: "true",
					HA_FENCING_METHODS: "shell(/bin/true)",
					IMAGE_COMPRESS: "true",
					IMAGE_COMPRESSION_CODEC: "org.apache.hadoop.io.compress.SnappyCodec",
					JOURNAL_NODE_HTTP_PORT: "8480",
					JOURNAL_NODE_RPC_PORT: "8485",
					NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK: "false",
					NAME_NODE_HANDLER_COUNT: "20",
					NAME_NODE_HEARTBEAT_RECHECK_INTERVAL: "60000",
					NAME_NODE_HTTP_PORT: "9002",
					NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION: "0.95",
					NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION: "4",
					NAME_NODE_RPC_PORT: "9001",
					NAME_NODE_SAFEMODE_THRESHOLD_PCT: "0.9",
					PERMISSIONS_ENABLED: "false",
					SERVICE_ZK_ROOT: "dcos-service-hdfs",
					TASK_USER: "root"
				}
			},
			health - check - spec: null,
			readiness - check - spec: null,
			config - files: [{
				name: "core-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/core-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HUE_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_ROOT_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_GROUPS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;{{HADOOP_PROXYUSER_HTTPFS_HOSTS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.parent-znode&lt;/name&gt; &lt;value&gt;/{{SERVICE_ZK_ROOT}}/hadoop-ha&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;!-- The ZKFC nodes use this property to verify they are connecting to the namenode with the expected principal. --&gt; &lt;name&gt;hadoop.security.service.user.name.key.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authentication&lt;/name&gt; &lt;value&gt;kerberos&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.security.authorization&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; {{/SECURE_MODE}} &lt;/configuration&gt; "
			}, {
				name: "hdfs-site",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/hdfs-site.xml",
				template - content: "&lt;?xml version="
				1.0 " encoding="
				UTF - 8 " standalone="
				no "?&gt; &lt;?xml-stylesheet type="
				text / xsl " href="
				configuration.xsl "?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservice.id&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.hdfs&lt;/name&gt; &lt;value&gt;name-0-node,name-1-node&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://journal-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}};journal-2-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{JOURNAL_NODE_RPC_PORT}}/hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/name-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.safemode.threshold-pct&lt;/name&gt; &lt;value&gt;{{NAME_NODE_SAFEMODE_THRESHOLD_PCT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HEARTBEAT_RECHECK_INTERVAL}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;{{NAME_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.invalidate.work.pct.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_INVALIDATE_WORK_PCT_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt; &lt;value&gt;{{NAME_NODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt; &lt;value&gt;{{NAME_NODE_DATA_NODE_REGISTRATION_IP_HOSTNAME_CHECK}}&lt;/value&gt; &lt;/property&gt; &lt;!-- name-0-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;name-0-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-0-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- name-1-node --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;name-1-node.{{FRAMEWORK_NAME}}.autoip.dcos.thisdcos.directory:{{NAME_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-bind-host.hdfs.name-1-node&lt;/name&gt; &lt;value&gt;0.0.0.0&lt;/value&gt; &lt;/property&gt; &lt;!-- journalnode --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.rpc-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.http-address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{JOURNAL_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/journal-data&lt;/value&gt; &lt;/property&gt; &lt;!-- datanode --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_RPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_HTTP_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt; &lt;value&gt;0.0.0.0:{{DATA_NODE_IPC_PORT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;{{MESOS_SANDBOX}}/data-data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt; &lt;value&gt;41943040&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt; &lt;value&gt;{{DATA_NODE_HANDLER_COUNT}}&lt;/value&gt; &lt;/property&gt; &lt;!-- HA --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master.mesos:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;{{HA_FENCING_METHODS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;{{HA_AUTOMATIC_FAILURE}}&lt;/value&gt; &lt;/property&gt; {{#NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.ha.namenode.id&lt;/name&gt; &lt;value&gt;name-{{POD_INSTANCE_INDEX}}-node&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} &lt;property&gt; &lt;name&gt;dfs.image.compress&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.image.compression.codec&lt;/name&gt; &lt;value&gt;{{IMAGE_COMPRESSION_CODEC}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.read.shortcircuit.streams.cache.size.expiry.ms&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_STREAMS_CACHE_SIZE_EXPIRY_MS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.hdfs&lt;/name&gt; &lt;value&gt;{{CLIENT_FAILOVER_PROXY_PROVIDER_HDFS}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.domain.socket.path&lt;/name&gt; &lt;value&gt;{{CLIENT_READ_SHORTCIRCUIT_PATH}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;{{PERMISSIONS_ENABLED}}&lt;/value&gt; &lt;/property&gt; {{#SECURE_MODE}} &lt;property&gt; &lt;name&gt;ignore.secure.ports.for.testing&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- Security Configuration --&gt; &lt;property&gt; &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt; &lt;value&gt; RULE:[2:$1@$0](.*)s/.*/{{TASK_USER}}/ RULE:[1:$1@$0](.*)s/.*/{{TASK_USER}}/ &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal.pattern&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/*@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.cluster.administrators&lt;/name&gt; &lt;value&gt;core,root,hdfs,nobody&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.{{TASK_NAME}}.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; {{#DATANODE}} &lt;!-- DataNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/data-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt; &lt;value&gt;700&lt;/value&gt; &lt;/property&gt; {{/DATANODE}} {{#NAMENODE}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/name-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/NAMENODE}} {{#ZKFC}} &lt;!-- NameNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/{{KERBEROS_PRIMARY}}.zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/zkfc-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/ZKFC}} {{#JOURNALNODE}} &lt;!-- JournalNode Security Configuration --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt; &lt;value&gt;keytabs/hdfs.journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos.keytab&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt; &lt;value&gt;{{KERBEROS_PRIMARY_HTTP}}/journal-{{POD_INSTANCE_INDEX}}-node.{{FRAMEWORK_NAME}}.mesos@{{KERBEROS_REALM}}&lt;/value&gt; &lt;/property&gt; {{/JOURNALNODE}} {{/SECURE_MODE}} &lt;/configuration&gt; "
			}, {
				name: "hadoop-metrics2",
				relative - path: "hadoop-2.6.0-cdh5.9.1/etc/hadoop/hadoop-metrics2.properties",
				template - content: "# Autogenerated by the Mesos Framework, DO NOT EDIT *.sink.statsd.class=org.apache.hadoop.metrics2.sink.StatsDSink datanode.sink.statsd.period=10 datanode.sink.statsd.server.host={{STATSD_UDP_HOST}} datanode.sink.statsd.server.port={{STATSD_UDP_PORT}} datanode.sink.statsd.skip.hostname=false"
			}]
		}],
		placement - rule: {
			@type: "TaskTypeRule",
			type: "data",
			converter: {
				@type: "TaskTypeLabelConverter"
			},
			behavior: "AVOID"
		}
	}],
	replacement - failure - policy: {
		permanentFailureTimoutMins: null,
		minReplaceDelayMins: 0
	}
}
</code></pre>
</div>

<h2 id="list-configs">List Configs</h2>

<p>You can list all configuration IDs by sending a GET request to <code class="highlighter-rouge">/v1/configurations</code>.</p>

<p>CLI Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>dcos beta-hdfs config list
</code></pre>
</div>

<p>HTTP Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>curl -H "Authorization:token=$auth_token" &lt;dcos_url&gt;/service/hdfs/v1/configurations
[
    "9a8d4308-ab9d-4121-b460-696ec3368ad6"
]
</code></pre>
</div>

<h2 id="view-specified-config">View Specified Config</h2>

<p>You can view a specific configuration by sending a GET request to <code class="highlighter-rouge">/v1/configurations/&lt;config-id&gt;</code>.</p>

<p>CLI Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>dcos hdfs config show 9a8d4308-ab9d-4121-b460-696ec3368ad6
</code></pre>
</div>

<p>HTTP Example</p>
<div class="highlighter-rouge"><pre class="highlight"><code>curl -H "Authorization:token=$auth_token" &lt;dcos_url&gt;/service/hdfs/v1/configurations/9a8d4308-ab9d-4121-b460-696ec3368ad6
{
    ... same format as target config above ...
}
</code></pre>
</div>

<h1 id="service-status-info">Service Status Info</h1>
<p>Send a GET request to the <code class="highlighter-rouge">/v1/state/properties/suppressed</code> endpoint to learn if HDFS is in a <code class="highlighter-rouge">suppressed</code> state and not receiving offers. If a service does not need offers, Mesos can “suppress” it so that other services are not starved for resources.
You can use this request to troubleshoot: if you think HDFS should be receiving resource offers, but is not, you can use this API call to see if HDFS is suppressed.</p>
<div class="highlighter-rouge"><pre class="highlight"><code>curl -H "Authorization: token=$auth_token" "&lt;dcos_url&gt;/service/hdfs/v1/state/properties/suppressed"
</code></pre>
</div>

</div>
</div>
</body>

</html>
