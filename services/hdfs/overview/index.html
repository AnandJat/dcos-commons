<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">







<head>
<title>HDFS: Overview</title>
<link rel="stylesheet" type="text/css" media="all" href="/dcos-commons/style/layout.css" />
<link rel="shortcut icon" type="image/png" href="https://mesosphere.com/favicon.ico"/>
<!-- The Dropdown library is written by Stephen Morley, licensed CC0 1.0 Universal (Public Domain Dedication)-->
<link rel="stylesheet" type="text/css" media="all" href="/dcos-commons/style/Dropdown.css" />
<script src="/dcos-commons/style/Dropdown.js"></script>
<style type="text/css">
/* set the background color of menu items */
.dropdown, .dropdown ul { background: #555555; clear: both; }
/* set the background color of active items */
.dropdown li:hover > a, .dropdown li:hover > span, .dropdown li.dropdownOpen > a, .dropdown li.dropdownOpen > span { background: #af87e0; }
/* pad items, set their text color, and fade their background color */
.dropdown a, .dropdown span { padding: 0.25em 0.5em; color: white; transition: background 0.2s; }
/* show '+' on expandable items */
.dropdown span:after { content: " +"; }

/* toc style: remove extra margin between elements */
.section-nav ul { margin: 0; }
</style>
</head>

<body>
<div id="wrapper">

<a href="/dcos-commons">
<img style="float: left; margin-bottom: 2em" src="https://mesosphere.com/wp-content/themes/mesosphere/library/images/assets/dcos-sdk-logo.png" width="250" alt="DC/OS Software Development Kit" />
</a>
<img style="float: right" src="https://img.shields.io/badge/Status-Alpha-BF97F0.svg?style=flat-square" alt="Status: Alpha" />

<ul class="dropdown" style="clear: both">
  <li>
    <a href="/dcos-commons">Home</a>
  </li>
  <li>
    <span>Documentation</span>
    <ul>
      
      
      
      
      <li><a href="/dcos-commons/operations-guide/">SDK Operations Guide</a></li>
      
      
      
      <li><a href="/dcos-commons/developer-guide/">SDK Developer Guide</a></li>
      
      
      
      <li><a href="/dcos-commons/yaml-reference/">YAML Reference</a></li>
      
      
      
      <li><a href="/dcos-commons/faq/">Frequently Asked Questions</a></li>
      
      
      
      <li><a href="/dcos-commons/glossary/">Glossary</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      <li><a href="/dcos-commons/reference/api">Javadoc Reference</a></li>
      <li><a href="/dcos-commons/reference/swagger-api">REST APIs</a></li>
    </ul>
  </li>
  <li>
    <span>Tutorials</span>
    <ul>
      
      
      
      <li><a href="/dcos-commons/tutorials/secrets-tutorial/">Secrets Tutorial</a></li>
      
      <li><a href="/dcos-commons/tutorials/kafka-tutorial/">Kafka Tutorial</a></li>
      
    </ul>
  </li>
  <li>
    <span>Services</span>
    <ul>
      
      
      
      
      <li>
        
        <span>Cassandra</span>
        
        <ul>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/install/">Install and Customize</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/service-settings/">Service Settings</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/cassandra-settings/">Cassandra Settings</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/node-settings/">Node Settings</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/uninstall/">Uninstall</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/quick-start/">Quick Start</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/connecting-clients/">Connecting Clients</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/managing/">Managing</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/api-reference/">API Reference</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/diagnostic-tools/">Diagnostic Tools</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/common-operations/">Common Operations</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/overview/">Overview</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/disaster-recovery/">Disaster Recovery</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/troubleshooting/">Troubleshooting</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/limitations/">Limitations</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/supported-versions/">Supported Versions</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/release-notes/">Release Notes</a></li>
          
          
          
          <li><a href="/dcos-commons/services/cassandra/upgrade/">Upgrade</a></li>
          
          
        </ul>
      </li>
      
      <li>
        
        <span>Elastic</span>
        
        <ul>
          
          
          
          <li><a href="/dcos-commons/services/elastic/install/">Install and Customize</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/elastic-x-pack/">X-Pack</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/custom-elasticsearch-yaml/">Custom Elasticsearch YAML</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/uninstall/">Uninstall</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/quick-start/">Quick Start</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/connecting-clients/">Connecting Clients</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/managing/">Managing</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/common-operations/">Common Operations</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/diagnostic-tools/">Diagnostic Tools</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/overview/">Overview</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/api-reference/">API Reference</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/disaster-recovery/">Disaster Recovery</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/troubleshooting/">Troubleshooting</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/limitations/">Limitations</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/supported-versions/">Supported Versions</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/release-notes/">Release Notes</a></li>
          
          
          
          <li><a href="/dcos-commons/services/elastic/upgrade/">Upgrade</a></li>
          
          
        </ul>
      </li>
      
      <li>
        
        <span>HDFS</span>
        
        <ul>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/install/">Install and Customize</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/kerberos/">Kerberos</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/uninstall/">Uninstall</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/quick-start/">Quick Start</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/connecting-clients/">Connecting Clients</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/managing/">Managing</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/diagnostic-tools/">Diagnostic Tools</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/common-operations/">Common Operations</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/overview/">Overview</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/api-reference/">API Reference</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/troubleshooting/">Troubleshooting</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/limitations/">Limitations</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/supported-versions/">Supported Versions</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/release-notes/">Release Notes</a></li>
          
          
          
          <li><a href="/dcos-commons/services/hdfs/upgrade/">Upgrade</a></li>
          
          
        </ul>
      </li>
      
      <li>
        
        <span>Kafka</span>
        
        <ul>
          
          
          
          <li><a href="/dcos-commons/services/kafka/install/">Install and Customize</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/security/">Security</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/uninstall/">Uninstall</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/quick-start/">Quick Start</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/connecting-clients/">Connecting Clients</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/managing/">Managing</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/common-operations/">Common Operations</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/diagnostic-tools/">Diagnostic Tools</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/api-reference/">API Reference</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/overview/">Overview</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/troubleshooting/">Troubleshooting</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/limitations/">Limitations</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/supported-versions/">Supported Versions</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/release-notes/">Release Notes</a></li>
          
          
          
          <li><a href="/dcos-commons/services/kafka/upgrade/">Upgrade</a></li>
          
          
        </ul>
      </li>
      
    </ul>
  </li>
  <li><a href="https://github.com/mesosphere/dcos-commons/blob/master/CONTRIBUTING.md">Contributing</a></li>
  <li><a href="http://chat.dcos.io" target="_blank">Slack</a></li>
</ul>
<h1>HDFS: Overview</h1>
<div id="content">


<h2 id="components">Components</h2>

<p>The following components work together to deploy and maintain the service.</p>

<ul>
  <li>
    <p>Mesos</p>

    <p>Mesos is the foundation of the DC/OS cluster. Everything launched within the cluster is allocated resources and managed by Mesos. A typical Mesos cluster has one or three Masters that manage resources for the entire cluster. On DC/OS, the machines running the Mesos Masters will typically run other cluster services as well, such as Marathon and Cosmos, as local system processes. Separately from the Master machines are the Agent machines, which are where in-cluster processes are run. For more information on Mesos architecture, see the <a href="https://mesos.apache.org/documentation/latest/architecture/">Apache Mesos documentation</a>. For more information on DC/OS architecture, see the <a href="https://docs.mesosphere.com/1.9/overview/architecture/">DC/OS architecture documentation</a>.</p>
  </li>
  <li>
    <p>ZooKeeper</p>

    <p>ZooKeeper is a common foundation for DC/OS system components, like Marathon and Mesos. It provides distributed key-value storage for configuration, synchronization, name registration, and cluster state storage. DC/OS comes with ZooKeeper installed by default, typically with one instance per DC/OS master.</p>

    <p>SDK Schedulers use the default ZooKeeper instance to store persistent state across restarts (under znodes named <code class="highlighter-rouge">dcos-service-&lt;svcname&gt;</code>). This allows Schedulers to be killed at any time and continue where they left off.</p>

    <p><strong>Note:</strong> SDK Schedulers currently require ZooKeeper, but any persistent configuration storage (such as etcd) could fit this role. ZooKeeper is a convenient default because it is always present in DC/OS clusters.</p>
  </li>
  <li>
    <p>Marathon</p>

    <p>Marathon is the “init system” of a DC/OS cluster. Marathon launches tasks in the cluster and keeps them running. From the perspective of Mesos, Marathon is itself another Scheduler running its own tasks. Marathon is more general than SDK Schedulers and mainly focuses on tasks that don’t require managing local persistent state. SDK services rely on Marathon to run the Scheduler and to provide it with a configuration via environment variables. The Scheduler, however, maintains its own service tasks without any direct involvement by Marathon.</p>
  </li>
  <li>
    <p>Scheduler</p>

    <p>The Scheduler is the “management layer” of the service. It launches the service nodes and keeps them running. It also exposes endpoints to allow end users to control the service and diagnose problems. The Scheduler is kept online by the cluster’s “init system”, Marathon. The Scheduler itself is effectively a Java application that is configured via environment variables provided by Marathon.</p>
  </li>
  <li>
    <p>Packaging</p>

    <p>HDFS is packaged for deployment on DC/OS. DC/OS packages follow the <a href="https://github.com/mesosphere/universe">Universe schema</a>, which defines how packages expose customization options at initial installation. When a package is installed on the cluster, the packaging service (named ‘Cosmos’) creates a Marathon app that contains a rendered version of the <code class="highlighter-rouge">marathon.json.mustache</code> template provided by the package. For DC/OS HDFS, this Marathon app is the scheduler for the service.</p>
  </li>
</ul>

<p>For further discussion of DC/OS components, see the <a href="https://docs.mesosphere.com/1.9/overview/architecture/components/">architecture documentation</a>.</p>

<h2 id="deployment">Deployment</h2>

<p>Internally, beta-hdfs treats “Deployment” as moving from one state to another state. By this definition, “Deployment” applies to many scenarios:</p>

<ul>
  <li>When beta-hdfs is first installed, deployment is moving from a null configuration to a deployed configuration.</li>
  <li>When the deployed configuration is changed by editing an environment variable in the scheduler, deployment is moving from an initial running configuration to a new proposed configuration.</li>
</ul>

<p>In this section, we’ll describe how these scenarios are handled by the scheduler.</p>

<h3 id="initial-install">Initial Install</h3>

<p>This is the flow for deploying a new service:</p>

<h4 id="steps-handled-by-the-dcos-cluster">Steps handled by the DC/OS cluster</h4>

<ol>
  <li>
    <p>The user runs <code class="highlighter-rouge">dcos package install beta-hdfs</code> in the DC/OS CLI or clicks <code class="highlighter-rouge">Install</code> for a given package on the DC/OS Dashboard.</p>
  </li>
  <li>
    <p>A request is sent to the Cosmos packaging service to deploy the requested package along with a set of configuration options.</p>
  </li>
  <li>
    <p>Cosmos creates a Marathon app definition by rendering beta-hdfs’s <code class="highlighter-rouge">marathon.json.mustache</code> with the configuration options provided in the request, which represents beta-hdfs’s Scheduler. Cosmos queries Marathon to create the app.</p>
  </li>
  <li>
    <p>Marathon launches the beta-hdfs’s scheduler somewhere in the cluster using the rendered app definition provided by Cosmos.</p>
  </li>
  <li>
    <p>beta-hdfs’s scheduler is launched. From this point onwards, the SDK handles deployment.</p>
  </li>
</ol>

<h4 id="steps-handled-by-the-scheduler">Steps handled by the Scheduler</h4>

<p>beta-hdfs’s <code class="highlighter-rouge">main()</code> function is run like any other Java application. The scheduler starts with the following state:</p>

<ul>
  <li>A <code class="highlighter-rouge">svc.yml</code> template that represents the service configuration.</li>
  <li>Environment variables provided by Marathon, to be applied onto the <code class="highlighter-rouge">svc.yml</code> template.</li>
  <li>Any custom logic implemented by the service developer in their Main function (we’ll be assuming this is left with defaults for the purposes of this explanation).</li>
</ul>

<ol>
  <li>
    <p>The <code class="highlighter-rouge">svc.yml</code> template is rendered using the environment variables provided by Marathon.</p>
  </li>
  <li>
    <p>The rendered <code class="highlighter-rouge">svc.yml</code> “Service Spec” contains the host/port for the ZooKeeper instance, which the Scheduler uses for persistent configuration/state storage. The default is <code class="highlighter-rouge">master.mesos:2181</code>, but may be manually configured to use a different ZooKeeper instance. The Scheduler always stores its information under a znode named <code class="highlighter-rouge">dcos-service-&lt;svcname&gt;</code>.</p>
  </li>
  <li>
    <p>The Scheduler connects to that ZooKeeper instance and checks to see if it has previously stored a Mesos Framework ID for itself.</p>
  </li>
</ol>

<ul>
  <li>
    <p>If the Framework ID is present, the Scheduler will attempt to reconnect to Mesos using that ID. This may result in a “<a href="#framework-has-been-removed">Framework has been removed</a>” error if Mesos doesn’t recognize that Framework ID, indicating an incomplete uninstall.</p>
  </li>
  <li>
    <p>If the Framework ID is not present, the Scheduler will attempt to register with Mesos as a Framework. Assuming this is successful, the resulting Framework ID is then immediately stored.</p>
  </li>
</ul>

<ol>
  <li>
    <p>Now that the Scheduler has registered as a Mesos Framework, it is able to start interacting with Mesos and receiving offers. When this begins, the scheduler will begin running the <a href="#offer-cycle">Offer Cycle</a> and deploying beta-hdfs. See that section for more information.</p>
  </li>
  <li>
    <p>The Scheduler retrieves its deployed task state from ZooKeeper and finds that there are tasks that should be launched. This is the first launch, so all tasks need to be launched.</p>
  </li>
  <li>
    <p>The Scheduler deploys those missing tasks through the Mesos offer cycle using a <a href="#plans">Deployment Plan</a> to determine the ordering of that deployment.</p>
  </li>
  <li>
    <p>Once the Scheduler has launched the missing tasks, its current configuration should match the desired configuration defined by the “Service Spec” extracted from <code class="highlighter-rouge">svc.yml</code>.</p>

    <ol>
      <li>When the current configuration matches the desired configuration, the Scheduler will tell Mesos to suspend sending new offers, as there’s nothing to be done.</li>
      <li>The Scheduler idles until it receives an RPC from Mesos notifying it of a task status change, it receives an RPC from an end user against one of its HTTP APIs, or until it is killed by Marathon as the result of a configuration change.</li>
    </ol>
  </li>
</ol>

<h3 id="reconfiguration">Reconfiguration</h3>

<p>This is the flow for reconfiguring a DC/OS service either in order to update specific configuration values, or to upgrade it to a new package version.</p>

<h4 id="steps-handled-by-the-dcos-cluster-1">Steps handled by the DC/OS cluster</h4>

<ol>
  <li>The user edits the Scheduler’s environment variables either using the Scheduler CLI’s <code class="highlighter-rouge">update</code> command or via the DC/OS GUI.</li>
  <li>The DC/OS package manager instructs Marathon to kill the current Scheduler and launch a new Scheduler with the updated environment variables.</li>
</ol>

<h4 id="steps-handled-by-the-scheduler-1">Steps handled by the Scheduler</h4>

<p>As with initial install above, at this point the Scheduler is re-launched with the same three sources of information it had before:</p>
<ul>
  <li><code class="highlighter-rouge">svc.yml</code> template.</li>
  <li>New environment variables.</li>
  <li>Custom logic implemented by the service developer (if any).</li>
</ul>

<p>In addition, the Scheduler now has a fourth piece:</p>
<ul>
  <li>Preexisting state in ZooKeeper</li>
</ul>

<p>Scheduler reconfiguration is slightly different from initial deployment because the Scheduler is now comparing its current state to a non-empty prior state and determining what needs to be changed.</p>

<ol>
  <li>After the Scheduler has rendered its <code class="highlighter-rouge">svc.yml</code> against the new environment variables, it has two Service Specs, reflecting two different configurations.
    <ol>
      <li>The Service Spec that was just rendered, reflecting the configuration change.</li>
      <li>The prior Service Spec (or “Target Configuration”) that was previously stored in ZooKeeper.</li>
    </ol>
  </li>
  <li>The Scheduler automatically compares the changes between the old and new Service Specs.
    <ol>
      <li><strong>Change validation</strong>: Certain changes, such as editing volumes and scale-down, are not currently supported because they are complicated and dangerous to get wrong.
        <ul>
          <li>If an invalid change is detected, the Scheduler will send an error message and refuse to proceed until the user has reverted the change by relaunching the Scheduler app in Marathon with the prior config.</li>
          <li>If the changes are valid, the new configuration is stored in ZooKeeper as the new Target Configuration and the change deployment proceeds as described below.</li>
        </ul>
      </li>
      <li><strong>Change deployment</strong>: The Scheduler produces a <code class="highlighter-rouge">diff</code> between the current state and some future state, including all of the Mesos calls (reserve, unreserve, launch, destroy, etc.) needed to get there. For example, if the number of tasks has been increased, then the Scheduler will launch the correct number of new tasks. If a task configuration setting has been changed, the Scheduler will deploy that change to the relevant affected tasks by relaunching them. Tasks that aren’t affected by the configuration change will be left as-is.</li>
      <li><strong>Custom update logic</strong>: Some services may have defined a <a href="#custom-update-plan">custom <code class="highlighter-rouge">update</code> Plan</a> in its <code class="highlighter-rouge">svc.yml</code>, in cases where different logic is needed for an update/upgrade than is needed for the initial deployment. When a custom <code class="highlighter-rouge">update</code> plan is defined, the Scheduler will automatically use this Plan, instead of the default <code class="highlighter-rouge">deploy</code> Plan, when rolling out an update to the service.</li>
    </ol>
  </li>
</ol>

<h3 id="uninstall">Uninstall</h3>

<p>This is the flow for uninstalling beta-hdfs.</p>

<h4 id="steps-handled-by-the-cluster">Steps handled by the cluster</h4>

<ol>
  <li>The user uses the DC/OS CLI’s <code class="highlighter-rouge">dcos package uninstall</code> command to uninstall the service.</li>
  <li>The DC/OS package manager instructs Marathon to kill the current Scheduler and to launch a new Scheduler with the environment variable <code class="highlighter-rouge">SDK_UNINSTALL</code> set to “true”.</li>
</ol>

<h4 id="steps-handled-by-the-scheduler-2">Steps handled by the Scheduler</h4>

<p>When started in uninstall mode, the Scheduler performs the following actions:</p>
<ul>
  <li>Any Mesos resource reservations are unreserved.
    <ul>
      <li><strong>Warning</strong>: Any data stored in reserved disk resources will be irretrievably lost.</li>
    </ul>
  </li>
  <li>Preexisting state in ZooKeeper is deleted.</li>
</ul>

<h2 id="offer-cycle">Offer Cycle</h2>

<p>The Offer Cycle is a core Mesos concept and often a source of confusion when running services on Mesos.</p>

<p>Mesos will periodically notify subscribed Schedulers of resources in the cluster. Schedulers are expected to either accept the offered resources or decline them. In this structure, Schedulers never have a complete picture of the cluster, they only know about what’s being explicitly offered to them at any given time. This allows Mesos the option of only advertising certain resources to specific Schedulers, without requiring any changes on the Scheduler’s end, but it also means that the Scheduler cannot deterministically know whether it’s seen everything that’s available in the cluster.</p>

<p>beta-hdfs performs the following operations as Offers are received from Mesos:</p>

<ol>
  <li><strong>Task Reconciliation</strong>: Mesos is the source of truth for what is running on the cluster. Task Reconciliation allows Mesos to convey the status of all tasks being managed by the service. The Scheduler will request a Task Reconciliation during initial startup, and Mesos will then send the current status of that Scheduler’s tasks. This allows the Scheduler to catch up with any potential status changes to its tasks that occurred after the Scheduler was last running. A common pattern in Mesos is to jealously guard most of what it knows about tasks, so this only contains status information, not general task information. The Scheduler keeps its own copy of what it knows about tasks in ZooKeeper. During an initial deployment this process is very fast as no tasks have been launched yet.</li>
  <li><strong>Offer Acceptance</strong>: Once the Scheduler has finished Task Reconciliation, it will start evaluating the resource offers it receives to determine if any match the requirements of the next task(s) to be launched. At this point, users on small clusters may find that the Scheduler isn’t launching tasks. This is generally because the Scheduler isn’t able to find offered machines with enough room to fit the tasks. To fix this, add more/bigger machines to the cluster, or reduce the requirements of the service.</li>
  <li><strong>Resource Cleanup</strong>: The Offers provided by Mesos include reservation information if those resources were previously reserved by the Scheduler. The Scheduler will automatically request that any unrecognized but reserved resources be automatically unreserved. This can come up in a few situations, for example, if an agent machine went away for several days and then came back, its resources may still be considered reserved by Mesos as reserved by the service, while the Scheduler has already moved on and doesn’t know about it anymore. At this point, the Scheduler will automatically clean up those resources.</li>
</ol>

<p>beta-hdfs will automatically notify Mesos to stop sending offers, or “suspend” offers, when the Scheduler doesn’t have any work to do. For example, once a service deployment has completed, the Scheduler will request that offers be suspended. If the Scheduler is later notified that a task has exited via a status update, the Scheduler will resume offers in order to redeploy that task back where it was. This is done by waiting for the offer that matches that task’s reservation, and then launching the task against those resources once more.</p>

<h2 id="pods">Pods</h2>

<p>A Task generally maps to a single process within the service. A Pod is a collection of colocated Tasks that share an environment. All Tasks in a Pod will come up and go down together. Therefore, most maintenance operations against the service are at <a href="#pod-operations">Pod granularity</a> rather than Task granularity.</p>

<h2 id="plans">Plans</h2>

<p>The Scheduler organizes its work into a list of Plans. Every SDK Scheduler has at least a Deployment Plan and a <a href="#recovery-plan">Recovery Plan</a>, but other Plans may also be added for things like custom Backup and Restore operations. The Deployment Plan is in charge of performing an initial deployment of the service. It is also used for rolling out configuration changes to the service (or in more abstract terms, handling the transition needed to get the service from some state to another state), unless the service developer provided a <a href="#custom-update-plan">custom <code class="highlighter-rouge">update</code> Plan</a>. The Recovery Plan is in charge of relaunching any exited tasks that should always be running.</p>

<p>Plans have a fixed three-level hierarchy. Plans contain Phases, and Phases contain Steps.</p>

<p>For example, let’s imagine a service with two <code class="highlighter-rouge">index</code> nodes and three <code class="highlighter-rouge">data</code> nodes. The Plan structure for a Scheduler in this configuration could look like this:</p>

<ul>
  <li>Deployment Plan (<code class="highlighter-rouge">deploy</code>)
    <ul>
      <li>Index Node Phase
        <ul>
          <li>Index Node 0 Step</li>
          <li>Index Node 1 Step</li>
        </ul>
      </li>
      <li>Data Node Phase
        <ul>
          <li>Data Node 0 Step</li>
          <li>Data Node 1 Step</li>
          <li>Data Node 2 Step</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Custom Update Plan (<code class="highlighter-rouge">update</code>)
    <ul>
      <li><em>(custom logic, if any, for rolling out a config update or software upgrade)</em></li>
    </ul>
  </li>
  <li>Recovery Plan (<code class="highlighter-rouge">recovery</code>)
    <ul>
      <li><em>(phases and steps are autogenerated as failures occur)</em></li>
    </ul>
  </li>
  <li>Index Backup Plan
    <ul>
      <li>Run Reindex Phase
        <ul>
          <li>Index Node 0 Step</li>
          <li>Index Node 1 Step</li>
        </ul>
      </li>
      <li>Upload Data Phase
        <ul>
          <li>Index Node 0 Step</li>
          <li>Index Node 1 Step</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Data Backup Plan
    <ul>
      <li>Data Backup Phase
        <ul>
          <li>Data Node 0 Step</li>
          <li>Data Node 1 Step</li>
          <li>Data Node 2 Step</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>As you can see, in addition to the default Deployment and Recovery Plans, this Scheduler also has a custom Update Plan which provides custom logic for rolling out a change to the service. If a custom plan is not defined then the Deployment Plan is used for this scenario. In addition, the service defines auxiliary Plans that support other custom behavior, specifically one Plan that handles backing up Index nodes, and another for that backs up Data nodes. In practice, there would likely also be Plans for restoring these backups. These auxiliary Plans could all be invoked manually by an operator, and may include additional parameters such as credentials or a backup location. Those are omitted here for brevity.</p>

<p>In short, Plans are the SDK’s abstraction for a sequence of tasks to be performed by the Scheduler. By default, these include deploying and maintaining the cluster, but additional maintenance operations may also be fit into this structure.</p>

<h3 id="custom-update-plan">Custom Update Plan</h3>

<p>By default, the service will use the Deployment Plan when rolling out a configuration change or software upgrade, but some services may need custom logic in this scenario, in which case the service developer may have defined a custom plan named <code class="highlighter-rouge">update</code>.</p>

<h3 id="recovery-plan">Recovery Plan</h3>

<p>The other default Plan is the Recovery Plan, which handles bringing back failed tasks. The Recovery Plan listens for offers that can be used to bring back those tasks and then relaunches tasks against those offers.</p>

<p>The Scheduler learns whether a task has failed by receiving Task Status updates from Mesos. Task Status updates can be sent during startup to let the scheduler know when a task has started running, to know when the task has exited successfully, or to know when the cluster has lost contact with the machine hosting that task.</p>

<p>When it receives a Task Status update, the Scheduler decides whether a given update indicates a task that needs to be relaunched. When a task must be relaunched, the Scheduler will wait on the Offer cycle.</p>

<h4 id="permanent-and-temporary-recovery">Permanent and temporary recovery</h4>

<p>There are two types of recovery, permanent and temporary. The difference is mainly whether the task being recovered should stay on the same machine, and the side effects that result from that.</p>

<ul>
  <li><strong>Temporary</strong> recovery:
    <ul>
      <li>Temporary recovery is triggered when there is a hiccup in the task or the host machine.</li>
      <li>Recovery involves relaunching the task on the same machine as before.</li>
      <li>Recovery occurs automatically.</li>
      <li>Any data in the task’s persistent volumes survives the outage.</li>
      <li>May be manually triggered by a <code class="highlighter-rouge">pod restart</code> command.</li>
    </ul>
  </li>
  <li><strong>Permanent</strong> recovery:
    <ul>
      <li>Permanent recovery can be requested when the host machine fails permanently or when the host machine is scheduled for downtime.</li>
      <li>Recovery involves discarding any persistent volumes that the pod once had on the host machine.</li>
      <li>Recovery only occurs in response to a manual <code class="highlighter-rouge">pod replace</code> command (or operators may build their own tooling to invoke the replace command).</li>
    </ul>
  </li>
</ul>

<p>Triggering a permanent recovery is a destructive operation, as it discards any prior persistent volumes for the pod being recovered. This is desirable when the operator knows that the previous machine isn’t coming back. For safety’s sake, permanent recovery is currently not automatically triggered by the SDK itself.</p>

<h2 id="persistent-volumes">Persistent Volumes</h2>

<p>The SDK was created to help simplify the complexity of dealing with persistent volumes. SDK services currently treat volumes as tied to specific agent machines, as one might have in a datacenter with local drives in each system. While EBS or SAN volumes, for instance, can be re-mounted and reused across machines, this isn’t yet supported in the SDK.</p>

<p>Volumes are advertised as resources by Mesos, and Mesos offers multiple types of persistent volumes. The SDK supports two of these types: MOUNT volumes and ROOT volumes.</p>

<ul>
  <li><strong>ROOT</strong> volumes:
    <ul>
      <li>Use a shared filesystem tree.</li>
      <li>Share I/O with anything else on that filesystem.</li>
      <li>Are supported by default in new deployments and do not require additional cluster-level configuration.</li>
      <li>Are allocated exactly the amount of disk space that was requested.</li>
    </ul>
  </li>
  <li><strong>MOUNT</strong> volumes:
    <ul>
      <li>Use a dedicated partition.</li>
      <li>Have dedicated I/O for the partition.</li>
      <li>Require <a href="https://docs.mesosphere.com/1.9/storage/mount-disk-resources/">additional configuration</a> when setting up the DC/OS cluster.</li>
      <li>Are allocated the entire partition, so allocated space can far exceed what was originally requested. MOUNT volumes cannot be further subdivided between services.</li>
    </ul>
  </li>
</ul>

<p>The fact that MOUNT volumes cannot be subdivided between services means that if multiple services are deployed with MOUNT volumes, they can quickly be unable to densely colocate within the cluster unless many MOUNT volumes are created on each agent. Let’s look at the following deployment scenario across three DC/OS agent machines, each with two enabled MOUNT volumes labeled A and B:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Agent 1: A B
Agent 2: A B
Agent 3: A B
</code></pre></div></div>

<p>Now we install a service X with two nodes that each use one mount volume. The service consumes volume A on agents 1 and 3:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Agent 1: X B
Agent 2: A B
Agent 3: X B
</code></pre></div></div>

<p>Now a service Y is installed with two nodes that each use two mount volumes. The service consumes volume A and B on agent 2, but then is stuck without being able to deploy anything else:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Agent 1: X B
Agent 2: Y Y
Agent 3: X B
</code></pre></div></div>

<p>Configuring <code class="highlighter-rouge">ROOT</code> vs <code class="highlighter-rouge">MOUNT</code> volumes may depend on the service. Some services will support customizing this setting when it is relevant, while others may assume one or the other.</p>

<h2 id="virtual-networks">Virtual networks</h2>

<p>The SDK allows pods to join virtual networks, with the <code class="highlighter-rouge">dcos</code> virtual network available by defualt. You can specify that a pod should join the virtual network by using the <code class="highlighter-rouge">networks</code> keyword in your YAML definition. Refer to the <a href="../developer-guide/">Developer Guide</a> for more information about how to define virtual networks in your service.</p>

<p>When a pod is on a virtual network such as the <code class="highlighter-rouge">dcos</code>:</p>
<ul>
  <li>Every pod gets its own IP address and its own array of ports.</li>
  <li>Pods do not use the ports on the host machine.</li>
  <li>Pod IP addresses can be resolved with the DNS: <code class="highlighter-rouge">&lt;task_name&gt;.&lt;service_name&gt;.autoip.dcos.thisdcos.directory</code>.</li>
  <li>You can also pass labels while invoking CNI plugins. Refer to the <a href="../developer-guide/">Developer Guide</a> for more information about adding CNI labels.</li>
</ul>

<h2 id="secrets">Secrets</h2>

<p>Enterprise DC/OS provides a secrets store to enable access to sensitive data such as database passwords, private keys, and API tokens. DC/OS manages secure transportation of secret data, access control and authorization, and secure storage of secret content.</p>

<p>The content of a secret is copied and made available within the pod. The SDK allows secrets to be exposed to pods as a file and/or as an environment variable. Refer to the <a href="../developer-guide/">Developer Guide</a> for more information about how DC/OS secrets are integrated into SDK-based services. If the content of the secret is changed, the relevant pod needs to be restarted so that it can get updated content from the secret store.</p>

<p><strong>Note:</strong> Secrets are available only in Enterprise DC/OS 1.10 onwards. <a href="https://docs.mesosphere.com/1.10/security/secrets/">Learn more about the secrets store</a>.</p>

<h3 id="authorization-for-secrets">Authorization for Secrets</h3>

<p>The path of a secret defines which service IDs can have access to it. You can think of secret paths as namespaces. <em>Only</em> services that are under the same namespace can read the content of the secret.</p>

<table>
  <thead>
    <tr>
      <th>Secret</th>
      <th>Service ID</th>
      <th>Can service access secret?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="highlighter-rouge">Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/user</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/dev1/user</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/user</code></td>
      <td>No</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/user/dev1</code></td>
      <td>No</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/secret-svc</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/secret-svc/dev1</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/secret-svc/instance2/dev2</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/Secret_Path1</code></td>
      <td><code class="highlighter-rouge">/secret-svc/a/b/c/dev3</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/instance1/Secret_Path2</code></td>
      <td><code class="highlighter-rouge">/secret-svc/dev1</code></td>
      <td>No</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/instance1/Secret_Path2</code></td>
      <td><code class="highlighter-rouge">/secret-svc/instance2/dev3</code></td>
      <td>No</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/instance1/Secret_Path2</code></td>
      <td><code class="highlighter-rouge">/secret-svc/instance1</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/instance1/Secret_Path2</code></td>
      <td><code class="highlighter-rouge">/secret-svc/instance1/dev3</code></td>
      <td>Yes</td>
    </tr>
    <tr>
      <td><code class="highlighter-rouge">secret-svc/instance1/Secret_Path2</code></td>
      <td><code class="highlighter-rouge">/secret-svc/instance1/someDir/dev3</code></td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>

<p><strong>Note:</strong> Absolute paths (paths with a leading slash) to secrets are not supported. The file path for a secret must be relative to the sandbox.</p>

<h3 id="binary-secrets">Binary Secrets</h3>

<p>You can store binary files, like a Kerberos keytab, in the DC/OS secrets store. In DC/OS 1.11+ you can create secrets from binary files directly, while in DC/OS 1.10 or lower, files must be base64-encoded as specified in RFC 4648 prior to being stored as secrets.</p>

<h4 id="dcos-111">DC/OS 1.11+</h4>

<p>To create a secret called <code class="highlighter-rouge">mysecret</code> with the binary contents of <code class="highlighter-rouge">kerb5.keytab</code> run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos security secrets create <span class="nt">--file</span> kerb5.keytab mysecret
</code></pre></div></div>

<h4 id="dcos-110-or-lower">DC/OS 1.10 or lower</h4>

<p>To create a secret called <code class="highlighter-rouge">mysecret</code> with the binary contents of <code class="highlighter-rouge">kerb5.keytab</code>, first encode it using the <code class="highlighter-rouge">base64</code> command line utility. The following example uses BSD <code class="highlighter-rouge">base64</code> (default on macOS).</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">base64</span> <span class="nt">--input</span> krb5.keytab <span class="o">&gt;</span> kerb5.keytab.base64-encoded
</code></pre></div></div>

<p>Alternatively, GNU <code class="highlighter-rouge">base64</code> (the default on Linux) inserts line-feeds in the encoded data by default. Disable line-wrapping with the <code class="highlighter-rouge">-w 0</code> argument.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">base64</span> <span class="nt">-w</span> 0 krb5.keytab <span class="o">&gt;</span> kerb5.keytab.base64-encoded
</code></pre></div></div>

<p>Now that the file is encoded it can be stored as a secret.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dcos security secrets create <span class="nt">--value-file</span> kerb5.keytab.base64-encoded some/path/__dcos_base64__mysecret
</code></pre></div></div>

<p><strong>Note:</strong> The secret name <strong>must</strong> be prefixed with <code class="highlighter-rouge">__dcos_base64__</code>.</p>

<p>When the <code class="highlighter-rouge">some/path/__dcos_base64__mysecret</code> secret is <a href="../developer-guide/#secrets">referenced in your service definition</a>, its base64-decoded contents will be made available as a <a href="http://mesos.apache.org/documentation/latest/secrets/#file-based-secrets">temporary file</a> in your service task containers. <strong>Note:</strong> Make sure to only refer to binary secrets as files since holding binary content in environment variables is discouraged.</p>

<h2 id="placement-constraints">Placement Constraints</h2>

<p>Placement constraints allow you to customize where a service is deployed in the DC/OS cluster. Depending on the service, some or all components may be configurable using <a href="http://mesosphere.github.io/marathon/docs/constraints.html">Marathon operators (reference)</a> with this syntax: <code class="highlighter-rouge">field:OPERATOR[:parameter]</code>. For example, if the reference lists <code class="highlighter-rouge">[["hostname", "UNIQUE"]]</code>, you should  use <code class="highlighter-rouge">hostname:UNIQUE</code>.</p>

<p>A common task is to specify a list of whitelisted systems to deploy to. To achieve this, use the following syntax for the placement constraint:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hostname:LIKE:10.0.0.159|10.0.1.202|10.0.3.3
</code></pre></div></div>

<p>You must include spare capacity in this list, so that if one of the whitelisted systems goes down, there is still enough room to repair your service (via <a href="#replace-a-pod"><code class="highlighter-rouge">pod replace</code></a>) without requiring that system.</p>

<h3 id="regions-and-zones">Regions and Zones</h3>

<p>Placement constraints can be applied to zones by referring to the <code class="highlighter-rouge">@zone</code> key. For example, one could spread pods across a minimum of 3 different zones by specifying the constraint:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[["@zone", "GROUP_BY", "3"]]
</code></pre></div></div>

<p>When the region awareness feature is enabled (currently in beta), the <code class="highlighter-rouge">@region</code> key can also be referenced for defining placement constraints. Any placement constraints that do not reference the <code class="highlighter-rouge">@region</code> key are constrained to the local region.</p>

<h4 id="rack-aware-services">Rack aware services</h4>

<p>Many rack aware services do not support reliable migration between rack-aware and non-rack-aware operation.  These services can choose to restrict the set of placement constraint transitions which are valid through use of the <code class="highlighter-rouge">ZoneValidator</code>.  The allowed placement constraint transitions when using the <code class="highlighter-rouge">ZoneValidator</code> are as follows:</p>

<h5 id="placement-constraint-references-zones">Placement Constraint References Zones</h5>

<table>
  <thead>
    <tr>
      <th>Original Constraint</th>
      <th>New Constraint</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>None</td>
      <td>False</td>
    </tr>
    <tr>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h3 id="updating-placement-constraints">Updating placement constraints</h3>

<p>Clusters change, and as such so should your placement constraints. We recommend using the following procedure to do this:</p>
<ul>
  <li>Update the placement constraint definition at the Scheduler.</li>
  <li>For each pod, <em>one at a time</em>, perform a <code class="highlighter-rouge">pod replace</code> for any pods that need to be moved to reflect the change.</li>
</ul>

<p>For example, let’s say we have the following deployment of our imaginary <code class="highlighter-rouge">data</code> nodes, with manual IPs defined for placing the nodes in the cluster:</p>

<ul>
  <li>Placement constraint of: <code class="highlighter-rouge">hostname:LIKE:10.0.10.3|10.0.10.8|10.0.10.26|10.0.10.28|10.0.10.84</code></li>
  <li>Tasks:
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>10.0.10.3: data-0
10.0.10.8: data-1
10.0.10.26: data-2
10.0.10.28: [empty]
10.0.10.84: [empty]
</code></pre></div>    </div>
  </li>
</ul>

<p>Given the above configuration, let’s assume <code class="highlighter-rouge">10.0.10.8</code> is being decommissioned and our service should be moved off of it. Steps:</p>

<ol>
  <li>Remove the decommissioned IP and add a new IP to the placement rule whitelist, by configuring the Scheduler environment with a new <code class="highlighter-rouge">DATA_NODE_PLACEMENT</code> setting:
    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hostname:LIKE:10.0.10.3|10.0.10.26|10.0.10.28|10.0.10.84|10.0.10.123
</code></pre></div>    </div>
  </li>
  <li>Wait for the Scheduler to restart with the new placement constraint setting.</li>
  <li>Trigger a redeployment of <code class="highlighter-rouge">data-1</code> from the decommissioned node to a new machine within the new whitelist: <code class="highlighter-rouge">dcos myservice node replace data-1</code></li>
  <li>Wait for <code class="highlighter-rouge">data-1</code> to be up and healthy before continuing with any other replacement operations.</li>
</ol>

<p>The ability to configure placement constraints is defined on a per-service basis. Some services may offer very granular settings, while others may not offer them at all. You’ll need to consult the documentation for the service in question, but in theory they should all understand the same set of <a href="http://mesosphere.github.io/marathon/docs/constraints.html">Marathon operators</a>.</p>

<h2 id="integration-with-dcos-access-controls">Integration with DC/OS access controls</h2>

<p>In DC/OS 1.10 and above, you can integrate your SDK-based service with DC/OS ACLs to grant users and groups access to only certain services. You do this by installing your service into a folder, and then restricting access to some number of folders. Folders also allow you to namespace services. For instance, <code class="highlighter-rouge">staging/kafka</code> and <code class="highlighter-rouge">production/kafka</code>.</p>

<p>Steps:</p>

<ol>
  <li>In the DC/OS GUI, create a group, then add a user to the group. Or, just create a user. Click <strong>Organization</strong> &gt; <strong>Groups</strong> &gt; <strong>+</strong> or <strong>Organization</strong> &gt; <strong>Users</strong> &gt; <strong>+</strong>. If you create a group, you must also create a user and add them to the group.</li>
  <li>
    <p>Give the user permissions for the folder where you will install your service. In this example, we are creating a user called <code class="highlighter-rouge">developer</code>, who will have access to the <code class="highlighter-rouge">/testing</code> folder.
Select the group or user you created. Select <strong>ADD PERMISSION</strong> and then toggle to <strong>INSERT PERMISSION STRING</strong>. Add each of the following permissions to your user or group, and then click <strong>ADD PERMISSIONS</strong>.</p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dcos:adminrouter:service:marathon full
dcos:service:marathon:marathon:services:/testing full
dcos:adminrouter:ops:mesos full
dcos:adminrouter:ops:slave full
</code></pre></div>    </div>
  </li>
  <li>Install a service (in this example, Kafka) into a folder called <code class="highlighter-rouge">test</code>. Go to <strong>Catalog</strong>, then search for <strong>beta-kafka</strong>.</li>
  <li>
    <p>Click <strong>CONFIGURE</strong> and change the service name to <code class="highlighter-rouge">/testing/kafka</code>, then deploy.</p>

    <p>The slashes in your service name are interpreted as folders. You are deploying Kafka in the <code class="highlighter-rouge">/testing</code> folder. Any user with access to the <code class="highlighter-rouge">/testing</code> folder will have access to the service.</p>
  </li>
</ol>

<p><strong>Important:</strong></p>
<ul>
  <li>Services cannot be renamed. Because the location of the service is specified in the name, you cannot move services between folders.</li>
  <li>DC/OS 1.9 and earlier does not accept slashes in service names. You may be able to create the service, but you will encounter unexpected problems.</li>
</ul>

<h3 id="interacting-with-your-foldered-service">Interacting with your foldered service</h3>

<ul>
  <li>Interact with your foldered service via the DC/OS CLI with this flag: <code class="highlighter-rouge">--name=/path/to/myservice</code>.</li>
  <li>To interact with your foldered service over the web directly, use <code class="highlighter-rouge">http://&lt;dcos-url&gt;/service/path/to/myservice</code>. E.g., <code class="highlighter-rouge">http://&lt;dcos-url&gt;/service/testing/kafka/v1/endpoints</code>.</li>
</ul>


</div>
</div>
</body>

</html>
