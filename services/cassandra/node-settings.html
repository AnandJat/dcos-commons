<p>Adjust the following settings to customize the amount of resources allocated to each  node. DC/OS Apache Cassandra’s <a href="http://cassandra.apache.org/doc/latest/operating/hardware.html">system requirements</a> must be taken into consideration when adjusting these values. Reducing these values below those requirements may result in adverse performance and/or failures while using the service.</p>

<p>Each of the following settings can be customized under the <strong>node</strong> configuration section.</p>

<h1 id="node-count">Node Count</h1>

<p>Customize the <code class="highlighter-rouge">Node Count</code> setting (default 3) under the <strong>node</strong> configuration section. Consult the Apache Cassandra documentation for minimum node count requirements.</p>

<ul>
  <li><strong>In DC/OS CLI options.json</strong>: <code class="highlighter-rouge">count</code>: integer (default: <code class="highlighter-rouge">3</code>)</li>
  <li><strong>DC/OS web interface</strong>: <code class="highlighter-rouge">NODES</code>: <code class="highlighter-rouge">integer</code></li>
</ul>

<h1 id="cpu">CPU</h1>

<p>You can customize the amount of CPU allocated to each node. A value of <code class="highlighter-rouge">1.0</code> equates to one full CPU core on a machine. Change this value by editing the <strong>cpus</strong> value under the <strong>node</strong> configuration section. Turning this too low will result in throttled tasks.</p>

<ul>
  <li><strong>In DC/OS CLI options.json</strong>: <code class="highlighter-rouge">cpus</code>: number (default: <code class="highlighter-rouge">0.5</code>)</li>
  <li><strong>DC/OS web interface</strong>: <code class="highlighter-rouge">CASSANDRA_CPUS</code>: <code class="highlighter-rouge">number</code></li>
</ul>

<h1 id="memory">Memory</h1>

<p>You can customize the amount of RAM allocated to each node. Change this value by editing the <strong>mem</strong> value (in MB) under the <strong>node</strong> configuration section. Turning this too low will result in out of memory errors. The <code class="highlighter-rouge">heap.size</code> setting must also be less than this value to prevent out of memory errors resulting from the Java Virtual Machine attempting to allocate more memory than is available to the Cassandra process.</p>

<ul>
  <li><strong>In DC/OS CLI options.json</strong>: <code class="highlighter-rouge">mem</code>: integer (default: <code class="highlighter-rouge">10240</code>)</li>
  <li><strong>DC/OS web interface</strong>: <code class="highlighter-rouge">CASSANDRA_MEMORY_MB</code>: <code class="highlighter-rouge">integer</code></li>
</ul>

<h1 id="jmx-port">JMX Port</h1>

<p>You can customize the port that Apache Cassandra listens on for JMX requests, such as those issued by <code class="highlighter-rouge">nodetool</code>.</p>

<ul>
  <li><strong>In DC/OS CLI options.json</strong>: <code class="highlighter-rouge">jmx_port</code>: integer (default: <code class="highlighter-rouge">7199</code>)</li>
  <li><strong>DC/OS web interface</strong>: <code class="highlighter-rouge">TASKCFG_ALL_JMX_PORT</code>: <code class="highlighter-rouge">integer</code></li>
</ul>

<h1 id="storage-port">Storage Port</h1>

<p>You can customize the port that Apache Cassandra listens on for inter-node communication.</p>

<ul>
  <li><strong>In DC/OS CLI options.json</strong>: <code class="highlighter-rouge">storage_port</code>: integer (default: <code class="highlighter-rouge">7000</code>)</li>
  <li><strong>DC/OS web interface</strong>: <code class="highlighter-rouge">TASKCFG_ALL_CASSANDRA_STORAGE_PORT</code>: <code class="highlighter-rouge">integer</code></li>
</ul>

<h1 id="ssl-storage-port">SSL Storage Port</h1>

<p>You can customize the port that Apache Cassandra listens on for inter-node communication over SSL.</p>

<ul>
  <li><strong>In DC/OS CLI options.json</strong>: <code class="highlighter-rouge">ssl_storage_port</code>: integer (default: <code class="highlighter-rouge">7001</code>)</li>
  <li><strong>DC/OS web interface</strong>: <code class="highlighter-rouge">TASKCFG_ALL_CASSANDRA_SSL_STORAGE_PORT</code>: <code class="highlighter-rouge">integer</code></li>
</ul>

<h1 id="native-transport-port">Native Transport Port</h1>

<p>You can customize the port that Apache Cassandra listens on for CQL queries.</p>

<ul>
  <li><strong>In DC/OS CLI options.json</strong>: <code class="highlighter-rouge">native_transport_port</code>: integer (default: <code class="highlighter-rouge">9042</code>)</li>
  <li><strong>DC/OS web interface</strong>: <code class="highlighter-rouge">TASKCFG_ALL_CASSANDRA_NATIVE_TRANSPORT_PORT</code>: <code class="highlighter-rouge">integer</code></li>
</ul>

<h1 id="rpc-port">RPC Port</h1>

<p>You can customize the port that Apache Cassandra listens on for Thrift RPC requests.</p>

<ul>
  <li><strong>In DC/OS CLI options.json</strong>: <code class="highlighter-rouge">rpc_port</code>: integer (default: <code class="highlighter-rouge">9160</code>)</li>
  <li><strong>DC/OS web interface</strong>: <code class="highlighter-rouge">TASKCFG_ALL_CASSANDRA_RPC_PORT</code>: <code class="highlighter-rouge">integer</code></li>
</ul>

<h1 id="disks">Disks</h1>

<h2 id="volume-type">Volume Type</h2>

<p>The service supports two volume types:</p>
<ul>
  <li><code class="highlighter-rouge">ROOT</code> volumes are effectively an isolated directory on the root volume, sharing IO/spindles with the rest of the host system.</li>
  <li><code class="highlighter-rouge">MOUNT</code> volumes are a dedicated device or partition on a separate volume, with dedicated IO/spindles.</li>
</ul>

<p>Using <code class="highlighter-rouge">MOUNT</code> volumes requires <a href="https://docs.mesosphere.com/1.9/storage/mount-disk-resources/">additional configuration on each DC/OS agent system</a>, so the service currently uses <code class="highlighter-rouge">ROOT</code> volumes by default. To ensure reliable and consistent performance in a production environment, you should configure <code class="highlighter-rouge">MOUNT</code> volumes on the machines that will run the service in your cluster and then configure the following as <code class="highlighter-rouge">MOUNT</code> volumes:</p>

<p>To configure the disk type:</p>
<ul>
  <li><strong>In DC/OS CLI options.json</strong>: <code class="highlighter-rouge">disk_type</code>: string (default: <code class="highlighter-rouge">ROOT</code>)</li>
  <li><strong>DC/OS web interface</strong>: <code class="highlighter-rouge">CASSANDRA_DISK_TYPE</code>: <code class="highlighter-rouge">string</code></li>
</ul>

<h2 id="disk-scheduler">Disk Scheduler</h2>

<p>It is <a href="http://docs.datastax.com/en/landing_page/doc/landing_page/recommendedSettings.html#recommendedSettings__optimizing-ssds">recommended</a> that you pre-configure your storage hosts to use the deadline IO scheduler in production environments.</p>

<h1 id="placement-constraints">Placement Constraints</h1>

<p>Placement constraints allow you to customize where Apache Cassandra nodes are deployed in the DC/OS cluster. Placement constraints support all <a href="http://mesosphere.github.io/marathon/docs/constraints.html">Marathon operators</a>. For example, <code class="highlighter-rouge">[["hostname", "UNIQUE"]]</code> ensures that at most one pod instance is deployed per agent.</p>

<ul>
  <li><strong>In DC/OS CLI options.json</strong>: <code class="highlighter-rouge">placement_constraint</code>: string (default: <code class="highlighter-rouge">[["hostname", "MAX_PER", "1"]]</code>)</li>
  <li><strong>DC/OS web interface</strong>: <code class="highlighter-rouge">PLACEMENT_CONSTRAINT</code>: <code class="highlighter-rouge">string</code></li>
</ul>

<h2 id="regions-and-zones">Regions and Zones</h2>

<p>Placement constraints can be applied to zones by referring to the <code class="highlighter-rouge">@zone</code> key. For example, one could spread pods across a minimum of 3 different zones by specifying the constraint:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>[["@zone", "GROUP_BY", "3"]]
</code></pre>
</div>

<p>When the region awareness feature is enabled (currently in beta), the <code class="highlighter-rouge">@region</code> key can also be referenced for defining placement constraints. Any placement constraints that do not reference the <code class="highlighter-rouge">@region</code> key are constrained to the local region.</p>

<h2 id="rack-aware-placement">Rack-Aware Placement</h2>

<p>Cassandra’s “rack”-based fault domain support may be enabled by specifying a placement constraint that uses the <code class="highlighter-rouge">@zone</code> key. For example, one could spread Cassandra nodes across a minimum of three different zones/racks by specifying the constraint <code class="highlighter-rouge">[["@zone", "GROUP_BY", "3"]]</code>. When a placement constraint specifying <code class="highlighter-rouge">@zone</code> is used, Cassandra nodes will be automatically configured with <code class="highlighter-rouge">rack</code>s that match the names of the zones. If no placement constraint referencing <code class="highlighter-rouge">@zone</code> is configured, all nodes will be configured with a default rack of <code class="highlighter-rouge">rack1</code>.</p>

<h1 id="virtual-networks">Virtual networks</h1>

<p>Cassandra supports deployment on virtual networks on DC/OS (including the <code class="highlighter-rouge">dcos</code> overlay network) allowing each node to have its own IP address and not use the ports resources on the agent. This can be specified by passing the following configuration during installation:</p>
<div class="language-json highlighter-rouge"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nt">"service"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nt">"virtual_network_enabled"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
</div>
<p>By default two nodes will not be placed on the same agent, however multiple Cassandra clusters can share an agent. As mentioned in the <a href="https://mesosphere.github.io/dcos-commons/developer-guide.html">developer guide</a> once the service is deployed on a virtual network, it cannot be updated to use the host network.</p>
